[{"path":"index.html","id":"overview","chapter":"Overview","heading":"Overview","text":"Authors: Phil McAleer, Carolina E. Kuepper-Tetzel, & Helena M. PatersonAim: course covers data skills R Markdown, data wrangling tidyverse, data visualisation ggplot2. also introduces statistical concepts probabilities, Null Hypothesis Significance Testing (NHST), alpha, power, effect size, sample size. common statistical analyses covered book t-test, correlations, ANOVAs, Regressions.Note: book currently updated means chapters published rolling basis.Contact: book living document regularly checked updated improvements. issues using book queries, please contact Carolina E. Kuepper-Tetzel.R Version: book written R version 4.1.0 (2021-05-18)Randomising Seed: chapters use level randomisation, remembered, seed set 1409.\nbook help learn whole host skills methods based around psychologist. completed Data Skills book PsyTeachR series (https://psyteachr.github.io/) first chapters familiar , additions. deliberate order refresh knowledge skills moving advanced topics. First, remind work R Markdown, recapping main functions use visualisation data wrangling. build understanding probability going using refreshed skills analyse variety different experiments. main idea book reproducible data analysis approach.book requires higher level self-directed learning first book; part learning trying things recognising need help. get stuck, google problem like see helps.working book remember learning software. teach R independent statistical knowledge content. Rather, teach data analytical skills knowledge within R. goal continuously improve data analysis skills!can !","code":""},{"path":"starting-with-r-markdown.html","id":"starting-with-r-markdown","chapter":"1 Starting with R Markdown","heading":"1 Starting with R Markdown","text":"","code":""},{"path":"starting-with-r-markdown.html","id":"overview-1","chapter":"1 Starting with R Markdown","heading":"1.1 Overview","text":"key goal researcher carry experiment tell others . One main ways Psychologists publication journal articles. numerous ways people combine different software create journal article, recent innovation field want know creating reports articles R Markdown. like, can see example research team school recent PLOS article. link within article methods section (one - https://osf.io/eb9dq/) allows see one file creates whole manuscript. Obviously writing full journal articles just yet, use R Markdown throughout lab series assignments. also use subjects write reports, make portfolio hints, tips, study aids suggest throughout labs.Today, start showing skills using R Markdown efficiently.chapter learn:R Markdown?create R Markdown file knit .add code edit rules R Markdown file.format text.","code":""},{"path":"starting-with-r-markdown.html","id":"what-is-r-markdown","chapter":"1 Starting with R Markdown","heading":"1.1.1 What is R Markdown?","text":"R Markdown (abbreviated Rmd) great way create dynamic documents embedded chunks code. documents self-contained fully reproducible makes easy share. information R Markdown, feel free look main webpage sometime: R Markdown Webpage. key advantage R Markdown allows write code document, along regular text, knit using package knitr() create document either webpage (HTML), PDF, Word document (.docx).\nThroughout labs see little tabs give information, answers quick questions, helpful hints, solutions tasks, suggestions information want note somewhere. read find get less course progresses, might help stuck something.\n\nKnit say want turn R Markdown file either webpage, PDF, Word document. Often labs hear someone say, \"tried knitting ?\" \"happens knit ?\". simply means happens try turning file pdf webpage.\n\npractical data assignments, one check run submitting knit code html (webpage) file see can open file browser. check code correct. however confirm code runs critical issues stop code running. valuable check.\n","code":""},{"path":"starting-with-r-markdown.html","id":"advantages-of-using-r-markdown","chapter":"1 Starting with R Markdown","heading":"1.1.2 Advantages of using R Markdown","text":"output one file includes figures, text, citations. additional files needed easy keep work one place.output one file includes figures, text, citations. additional files needed easy keep work one place.R code can put directly R Markdown report, necessary keep writing (e.g., Word document) analysis (e.g., R script) separate.R code can put directly R Markdown report, necessary keep writing (e.g., Word document) analysis (e.g., R script) separate.Including R code directly lets others see analysis - good thing science! reproducible transparent, key components Open Science!Including R code directly lets others see analysis - good thing science! reproducible transparent, key components Open Science!write report plain text, non software-specific format easy share, necessary learn new coding language HTML, can create various outputs depending need.write report plain text, non software-specific format easy share, necessary learn new coding language HTML, can create various outputs depending need.","code":""},{"path":"starting-with-r-markdown.html","id":"creating-an-r-markdown-.rmd-file","chapter":"1 Starting with R Markdown","heading":"1.1.3 Creating an R Markdown (.Rmd) File","text":"chapter going create R Markdown document. Knowing :help navigate R Markdown.show create homework assignment documents.help create reports using .point unsure something remember think can get help, , google (R markdown cheat sheets internet). example, forget put words bold, simply go Google type \"rmarkdown bold\" doubt get lot useful hints. nothing wrong . Nobody expecting keep every function head; need reminders. find elements stick head better others. remember, Google friend!Quickfire QuestionsWe put questions throughout help test knowledge. type choose correct answer, dashed box change color become solid.following options, creating R Markdown document instead simply using R script? R Markdown can combine report writing analysisR Scripts run codeReproducible Science!\none answer question! R Markdown can combine report writing analysis, providing open access others examine data, create Reproducible Science. incorrect answer? R Scripts fact run R code may remember Level 1 labs. key difference R Scripts really used documentation creating reports easily - R Markdown used ensure code can added information research can reproduced others.\n","code":""},{"path":"starting-with-r-markdown.html","id":"one-last-thing-before-beginning","chapter":"1 Starting with R Markdown","heading":"1.1.4 One last thing before beginning!","text":"Remember: can always go back Data Skills Book Level 1 remind skills want already learned using R RStudio. first chapters book partly overlap learned previously, extend skills knowledge.","code":""},{"path":"starting-with-r-markdown.html","id":"r-markdown-basics","chapter":"1 Starting with R Markdown","heading":"1.2 R Markdown Basics","text":"read Overview chapter, reason behind using R, now going work making reproducible code. laptop, best install R Rstudio use. Appendix find reminder install R Rstudio.","code":""},{"path":"starting-with-r-markdown.html","id":"create-a-new-r-markdown-document","chapter":"1 Starting with R Markdown","heading":"1.2.1 Create a new R Markdown document","text":"Create new R Markdown file (.Rmd) opening Rstudio, top menu, selecting File >> New File >> R Markdown.... now see following dialog box:\nFigure 1.1: Starting R Markdown file\nClick Document left-hand panel give document Title.file call want make sure informative reader.Put name student ID Author field author. now focus making HTML output, make sure selected shown Figure 1.1 hit OK done . now .Rmd file open Rstudio.first thing see R Markdown file header section enclosed top bottom ---. Technically called yaml header, section lists title, author, date output format. layout header precise look like shown Figure 1.2, currently set output HTML.\nFigure 1.2: Rmd yaml header\ndefault file header includes info shown Figure 1.2 many options available. can learn spare time like links \n.html options{_target=\"_blank\"} \n.pdf options.\nWAIT!! spelt name wrong? change ?\n\nlong way close file start . shorter way just correct info header - just remember keep quotes. E.g. \"Si Cologe\" instead \"Untitled\"\n","code":""},{"path":"starting-with-r-markdown.html","id":"code-chunks","chapter":"1 Starting with R Markdown","heading":"1.2.2 Code Chunks","text":"Immediately header information see default setup code chunk shown Figure 1.3. time, lab series, edit information chunk. Instead, add information, text, code, chunks, chunk.\nFigure 1.3: defualt setup code chunk\nRMarkdown can type text want directly document just word document. However, want include code need include one code chunks similar Figure 1.3. Code chunks start line contains three backwards apostrophes ` (called grave accents - often top-left QWERTY keyboards), set curly brackets letter r inside:always need parts create code chunk:three back ticks ` part Rmd file says code inserted document.{r} part says specifically including R code.default setup code chunk provides basic options R Markdown file knits work. , now, best leave particular code chunk alone. Instead show use R Markdown editing code chunks come default chunk.next code chunk file look bit like :Within curly brackets, first line chunk, word cars included letter r. simply name label code chunk really called anything. example, called code chunk cars1 later chunk cars2 show first second chunk relating cars. Whilst always advisable name code chunks, need name . However, put names chunks use name twice cause script crash knit , e.g. use data data; instead maybe use personality-data participant-info whatever makes sense chunk. OK? Different names different chunks! individual.\nRemember knitting just means converting rendering file pdf, webpage, etc. Crashing means error code stopped knitting working finishing. can usually find problem line code error message see.\n\nsecond line code chunk R code written: summary(cars). case, just asking summary() inbuilt dataset cars. R lot inbuilt datasets practice ; cars one .third line closes code chunk, three backwards apostrophes. means whatever contained first third lines code run.\npeople first starting using R Markdown, common issue code working started code chunk correctly, forgotten close bottom three backticks. Remember, three backticks open, three backticks close, chunk bind .\nQuickfire QuestionsFrom following options name, label, default setup code chunk (.e. first code chunk R Markdown file)? includersetupFALSE\nlook default setup code chunk can see code chunk name setup. include=FALSE rule explain little bit.\n","code":"```{r}``````{r cars}\nsummary(cars)```"},{"path":"starting-with-r-markdown.html","id":"knitting-code","chapter":"1 Starting with R Markdown","heading":"1.2.3 Knitting Code","text":"Now good time try knitting file see code chunks . can using Knit button top RStudio screen:\nFigure 1.4: knit button. Clicking knit file.\nclick Knit ask save file .Rmd file. Call file L2Psych_Ch1_RMarkdownBasics.Rmd save folder keep information lab. working Psychology labs University Library need save location drive space full access can save files . best one campus M: drive. using device anywhere can save file work. However, good folder structure help navigate labs better.\nbeneficial create folder M: drive contain data skills work rest Level 2. Maybe something like Psychology_Level2_DataSkills_Work folders within lab, e.g Chapter1. clearer structure folders easier find use files ! important one thing keep telling LOOK BACK (politely) previously .\n\nCouple tips:\n\nAvoid spaces file names folder names. can make life really complicated bad habit start . Use underscores words filenames folder names.\n\nNever call folder \"R\". crash R potentially lead reinstall R Rstudio. Rstudio opens looks folder called R expects contain software libraries. now looking different folder name, things go wrong.\n\nsaving file, webpage appear. first thing notice lines code chunks disappeared: ```{r} closing ``` code chunk gone. Whenever knit R Markdown file lines disappear leaving code within. also notice output code also now showing webpage. next section show control showing output code, , adding rules.\nFigure 1.5: knitted summary output\n","code":""},{"path":"starting-with-r-markdown.html","id":"adding-code-chunk-rules-and-options","chapter":"1 Starting with R Markdown","heading":"1.2.4 Adding Code Chunk Rules and Options","text":"can often good idea even necessary show data outcome test report, example writing report wanted include table results. code displayed table 10,000 lines long? case might want show output show code. can including rule within first line code chunk - ```{r name, rule = option} line. already seen rule standard default chunk, include rule, number others. look now:First, look hide output show code. , use results = \"hide\" rule:\nFigure 1.6: results Rule\nAdd rule example code chunk, shown , knit file . happens? Note comma separating name chunk rule. now see code data. key thing note code still \"running\", just showing output. example, say code said x <- 2 + 2. results = \"hide\" rule, still running line code, x assigned 4, just see output.\n\nAlternatively, can hide code, show ouput using echo = FALSE rule:\nFigure 1.7: echo Rule\n\ntemplate Rmd file, rule echo set FALSE meaning show figure code. Change rule code echo set TRUE, knit file . happens?\nRemember Level 1 called libraries environment. \"echo = FALSE\" option useful commands like library() just calling package library necessarily want display final report final HTML file. Another example might wanted make plot want include code, just want show plot report.\n\nNext, say want hide code output still run code. can using include rule:\nFigure 1.8: include Rule\nChange rule example code chunk, shown , include = FALSE knit file . happens? Note code still runs. just show anything.Finally, can use eval rule specifies whether want code chunk written evaluated knit RMarkdown file. Evaluated means run carry code. , eval = FALSE rule stop code evaluated. code shown rule stopping output get evaluated eval rule FALSE.\nFigure 1.9: eval Rule\n\nmight useful cases want show code relating programmed stimuli experiment, necessarily want run part R Markdown file.\n\nprobably wee summary :\nTable 1.1: Rules! Rules! Rules!can also mix match rules get code/output display want. takes little getting used first doubt, just ask.\ncan use RStudio's autocomplete (tab button) see different options different rules. example, type include = hit tab button keyboard. see options TRUE FALSE.\n\nAutocomplete also works lot functions quite remember spell well. gg-? gg-{tab button}... Ah yes, ggplot().\nQuickfire QuestionsYou've got large dataset thousands participants' personality happiness scores want analyse present RMarkdown.want show code running analysis show output much display. Note want code run. Type box (e.g. rule = set) set results rule ? want show code running analysis show output much display. Note want code run. Type box (e.g. rule = set) set results rule ? create plot happiness versus neuroticism scores want hide code show output. can ? echo = TRUEinclude = FALSEcode = HIDEecho = FALSEYou create plot happiness versus neuroticism scores want hide code show output. can ? echo = TRUEinclude = FALSEcode = HIDEecho = FALSE\nfirst answer results = \"hide\" want show code run code necessarily show output code.\n\nsecond question, include = FALSE technically hide code, also hides output! echo = FALSE allows still see plot hiding code want hidden. code = HIDE - simple!\n\nRemember, aim questions help memorise codes (one can !); help gain better understanding apply codes come across future.\nTrue False, writing echo = TRUE effect output code chunk echo rule : TRUEFALSE\ncode chunk rules default option. example, echo, include, eval usually default set TRUE. result, set echo rule, .e. specifically set echo = FALSE code chunk, setting echo = TRUE. specifying option give default setting option.\nTrue False, difference setting results = \"hide\" eval = FALSE hide output: TRUEFALSE\nsetting results = \"hide\", code evaluated results produced output hidden. setting eval = FALSE, code evaluated therefore results output produced. need output later part code might use results = \"hide\". need output just want show code example might use eval = FALSE.\n","code":""},{"path":"starting-with-r-markdown.html","id":"adding-inline-code","chapter":"1 Starting with R Markdown","heading":"1.2.5 Adding Inline Code","text":"alternative way add code report called using inline code. inline code use code chunk. Instead code appears inline text. Inline code can inserted using back-tick, letter r, followed space, code want include, finally another back-tick. example, writing `r 2 + 2` return answer 4 knit file instead showing code. Remember, inside code chunk, line text, e.g.:\n\"ran `r 2+2` people\".\n\nknitted becomes:\n\"ran 4 people\".inline coding really useful want calculations within text insert values text, say dataframe, make informative sentence. look complex examples later labs really useful tool writing manuscripts R Markdown comfortable get .Quickfire QuestionsYou need TwoOneThree back tick(s) insert code chunksYou need TwoOneThree back tick(s) insert code chunksWhy inline code, `{r} 6 * 8` , going show calculated answer knit file? Try editing code line Rmarkdown knitting get work. need space back tick codeInline code complete calcuationsCurly brackets around r needed code chunksWhy inline code, `{r} 6 * 8` , going show calculated answer knit file? Try editing code line Rmarkdown knitting get work. need space back tick codeInline code complete calcuationsCurly brackets around r needed code chunks\n\ncode chunks start end three back-ticks.\n\n\ncode chunks start end three back-ticks.\n\n\nInline coding use curly brackets around r.\n\n\nInline coding use curly brackets around r.\n\n\nneed inline coding back-tick, r, space, code, final back-tick.\n\n\nneed inline coding back-tick, r, space, code, final back-tick.\n","code":""},{"path":"starting-with-r-markdown.html","id":"formatting-the-r-markdown-file","chapter":"1 Starting with R Markdown","heading":"1.2.6 Formatting the R Markdown File","text":"last thing want show preclass activity format text.writing code chunks can format document lots different ways just like Word document (expensive license-based software). R Markdown cheatsheet provides lots information show couple things might want try .can make text bold including two ** (two asterisks) start end text want present bold font. example:\n\n\"ran **4 people**.\n\nknitted becomes:\n\n\"ran 4 people\".\nNow write text Rmd file put bold. Knit file check worked.also try using italics putting single * (asterisk) start end word sentence. Try now. example help.\n\n\"ran *4 people*.\n\nknitted becomes:\n\n\"ran 4 people\".\nNote: italics can difficult read many people tried avoid using book. find italics, necessary, please let us know claim reward packet minstrels. Yes, whole packet!Finally, might want add headings sub-headings file. example, maybe writing Psychology journal article want put header Introduction, Methods, Results, Discussion sections. using # (hashtag) symbol shown Figure 1.10.\nFigure 1.10: Inputting different Header levels using #s\nNow, type four main sections found Psychology journal article R Markdown file, typing one separate line. mentioned . Knit file. look like?Now add different number #'s heading, space heading hashtag (e.g. # Introduction) knit file . notice different number hashtags?Quickfire QuestionsIf * puts words italics, ** puts words bold, type box might put (technically ) word put italics bold? * puts words italics, ** puts words bold, type box might put (technically ) word put italics bold? True False: '#'s include, smaller header : TRUEFALSETrue False: '#'s include, smaller header : TRUEFALSEFrom options, common order headings found Psychology Journal : Discussion, Introduction, Methods, ResultsDiscussion, Results, Methods, IntroductionIntroduction, Methods, Results, DiscussionIntroduction, Results, Methods, DiscussionFrom options, common order headings found Psychology Journal : Discussion, Introduction, Methods, ResultsDiscussion, Results, Methods, IntroductionIntroduction, Methods, Results, DiscussionIntroduction, Results, Methods, Discussion\n* start end word puts italics (e.g. italics) ** puts bold (e.g. bold), putting three *** start end put italics bold (e.g. italics-bold).\n\ntrue #'s use, smaller heading . Word document writers use different headings well. , # gives biggest heading, gets smaller smaller every extra #.\n\nFinally, Psychology, vast majority journal articles written format : Introduction, Methods, Results, Discussion. format always hold journals ask authors use different format, depending much emphasis journal (erroneously) likes put results hypothesis methods. however teach order stated . question approach always important, , results! course know learning Registered Reports labs lectures.\n","code":""},{"path":"starting-with-r-markdown.html","id":"r-markdown-application","chapter":"1 Starting with R Markdown","heading":"1.3 R Markdown Application","text":"","code":""},{"path":"starting-with-r-markdown.html","id":"r-markdown-and-the-experimental-design-portfolio","chapter":"1 Starting with R Markdown","heading":"1.3.1 R Markdown and The Experimental Design Portfolio","text":"going create R Markdown scratch. also start create Experimental Design Analysis Portfolio R Markdown. aim portfolio consolidate learning experimental design analysis, allowing reflect back learning progressed. add whenever think \"Oh good tip!\" \"something want remember!\". chapter way consolidate knowledge. portfolio assessed marked anyway. learning aid help develop understanding research methods analysis Psychology.Across following nine tasks, help structure format R Markdown files; can apply learn portfolio time. begin!\nThroughout book see Portfolio Points. just points suggest add portfolio. Ultimately, keep portfolio, examples kind things recommend include:\n\nKey points classic experiments\n\nmain goal, outcome, authors, year\n\n\ntop tip write short summary every paper read, including authors' names help consolidate information\n\n\nmain goal, outcome, authors, year\n\ntop tip write short summary every paper read, including authors' names help consolidate information\n\nAspects Reports' designs analyses\n\ndecisions made ; compare studies.\n\n\ndecisions made ; compare studies.\n\nGlossary points R code functions\n\ncodes find challenging understand function \n\n\ncodes might use frequently future activities\n\n\ndeveloping glossary can send us items include get involved . still development can see https://psyteachr.github.io/glossary/.\n\n\ncodes find challenging understand function \n\ncodes might use frequently future activities\n\ndeveloping glossary can send us items include get involved . still development can see https://psyteachr.github.io/glossary/.\n\nReflection Points learned week.\n","code":""},{"path":"starting-with-r-markdown.html","id":"the-ponzo-illusion-and-age","chapter":"1 Starting with R Markdown","heading":"1.3.2 The Ponzo Illusion and Age","text":"activities chapter make use open dataset.\nopen dataset made available everyone see stored internet researchers use. previous section, saw example start PLOS One article. Many journals now ask researchers make data available post somewhere accessible like Open Science Framework.\n\nInterestingly, art making data available standard classic older articles. data using today comes 1967. Sometime recent times, data started made unavailable - closed. believe data made available encourage coming years. Transparent science Open Science!\n\ndata use today paper looking Ponzo illusion Age:Leibowitz, H. W. & Judisch, J. M. (1967). Relation Age Magnitude Ponzo Illusion. American Journal Psychology, 80(1), 105-109. can accessed campus (University Glasgow) link. campus can sign read University Glasgow library student Glasgow.basics Ponzo illusion (Wikipedia page) two lines size viewed different length based surrounding information - like sleepers traintrack. See Figure 1 Leibowitz Judisch (1967) example (P106). authors showed people two vertical lines surrounded differing horizontal lines running angles behind main vertical lines. authors varied size one vertical lines (left line) asked participants judge two vertical lines bigger longer; left line (variable) right one (standard). paper also tested illusion influenced age. info, see paper. Operationalising dependent variable, Leibowitz & Judisch measured size left line considered size standard line right. data using can seen page 107, includes:Group participants assigned according age, group made 10 participants sexThe Sex GroupThe Mean Age GroupThe Mean Length left vertical line","code":""},{"path":"starting-with-r-markdown.html","id":"Ch1InClassQueT1","chapter":"1 Starting with R Markdown","heading":"1.3.3 Task 1: Setting up Your R Markdown Portfolio","text":"overall goal make reproducible \"report\" summarising data Leibowitz Judisch (1967) paper. begin!Create new R Markdown document.Give title, e.g. Psychology Research Methods PortfolioEnter GUID name authorSet output HTML.\nThroughout labs see Helpful Hints. Usually solutions nearby end chapter prevent temptation.\n\nsetting Rmd file, followed steps correctly, probably see new R Markdown file header containing title, author, date output information shown previous section.\n\nsee document header, probably created R Script instead. Refer back R Markdown Basics activity try . Look list File options top menu.\n\ncan now remove parts generic R Markdown code need; anything setup code chunk can removed (see Figure 1.3). anything line 11 can removed. Leave first code chunk however - lines 8 10 - lines make R Markdown show code chunks unless otherwise specified - note echo =  TRUE.\nWrite reminder somewhere portfolio code chunk . Writing notes somewhere accessible mean can find easily.\n","code":""},{"path":"starting-with-r-markdown.html","id":"Ch1InClassQueT2","chapter":"1 Starting with R Markdown","heading":"1.3.4 Task 2: Give your Report a Heading","text":"going start portfolio creating brief report Leibowitz Judisch (1967), give heading.setup code chunk, give report heading, e.g. Lab 1 - Magnitude Ponzo Illusion varies function Age.Using hashtags, give heading Header 1 size.\nRemember fewer number hashtags larger heading size.\n","code":""},{"path":"starting-with-r-markdown.html","id":"Ch1InClassQueT3","chapter":"1 Starting with R Markdown","heading":"1.3.5 Task 3: Creating a Code Chunk","text":"going need data soon best bring start code.Set working directory: Session >> Set Working Directory >> Choose Directory\nOne common issues see people using Rstudio forget set working directory folder containing data file working . means try knit run code line work Rstudio know data . Remember set working directory start session, using Session >> Set Working Directory >> Choose Directory\n\nAvoid using code set working directory often work machine others therefore fully reproducible without editing script.\nDownload data lab zip file clicking link. Unzip save folder working .Create new code chunk R Markdown script, give code chunk name load_data.Copy paste code code chunk. Spend couple minutes partner reminding code . answer hint .Now, add change echo rule code chunk knit file, code included final document.Knit document now see output looks like. ask save file somewhere. Remember Boyd Orr Lab PCs best done M: drive, given available space.Important: good chance , webpage knitted, see either warnings messages. can suppress using message warning rules within code chunks well. Try now - PreClass Activities R-Markdown cheatsheet help.\nHints:\n\nStep 4 - echo can equal TRUE FALSE.\n\nRemember separate rules code chunk commas. E.g. {r, rule1 = FALSE, rule2 = TRUE}\n\ncode ?\n\nLine 1 loads tidyverse packages associated packages e.g. dplyr, readr ggplot2. used Level 1 Grassroots book - recap lot coming labs.\nLine 2 loads data using read_csv() function stores ponzo_data.\n\nImportant points note:\n\nponzo_data called anything best call something makes clear . rule spaces name. ponzo_data ponzo.data acceptable, different . ponzo data acceptable crash code.\n\nread_csv() actually readr package available loaded tidyverse library(tidyverse). always tell use read_csv() read data csv file. codes load data - one similar one read.csv(). work differently. ever use read_csv() Psychology labs unless otherwise instructed.\n\nremember <- essentially means assign . Assigning ponzo data table ponzo_data can actually can written way around - read_csv(\"PonzoAgeData.csv\") -> ponzo_data - convention usually puts way code.\n","code":"\nlibrary(\"tidyverse\")\nponzo_data <- read_csv(\"PonzoAgeData.csv\")"},{"path":"starting-with-r-markdown.html","id":"Ch1InClassQueT4","chapter":"1 Starting with R Markdown","heading":"1.3.6 Task 4: Writing your Report","text":"start giving brief report information structure full report.Underneath code chunk entered, put new heading called Introduction give Header 2 size.Next, little research Ponzo Illusion write sentence two describing works tells us; include citation support research. link wikipedia page illusion top section might help.Finally, copy text box report finish text putting names two hypotheses behind illusion sentence ordered list style; .e. 1... 2..., etc. two hypotheses Framing hypothesis Perspective hypothesis.\nLists can tricky begin straightforward know key points.\n\nlist begins blank line text. start list without leaving blank line top work.\n\npoint starts asterisk (*) integer full-stop (e.g. 1.)\n\nmust space * 1. writing point.\n\npoint new line.\n\nstagger points list (.e. indent), leave 4 blank spaces (two tabs) put * etc.\nQuickfire QuestionHere couple questions try group remind using citations:writing report, cite:Papers five authors first mention? Author 1, Author 2, Author 3, Author 4, & Author 5Author 1, Author 2, Author 3, Author 4, & Author 5, YearAuthor 1 et al., YearPapers five authors second mention? Author 1, Author 2, Author 3, Author 4, & Author 5Author 1, Author 2, Author 3, Author 4, & Author 5, YearAuthor 1 et al., YearPapers seven authors first mention? Author 1, Author 2, Author 3, Author 4, Author 5, Author 6, & Author 7Author 1, Author 2, Author 3, Author 4, Author 5, Author 6, & Author 7, YearAuthor 1 et al., YearPapers two authors citation? (Author 1 & Author 2)(Author 1 et al., Year)Two papers one paretheses? Order chronologically according year, separated semi-colonOrder alphabetically according first author surname, separated semi-colonTwo papers author? Order chronologically according year, separated semi-colonOrder chronologically according year, separated commaOrder alphabetically adding letter year","code":"\"There are two underlying hypotheses that may explain the Ponzo Illusion. These are: ...\""},{"path":"starting-with-r-markdown.html","id":"Ch1InClassQueT5","chapter":"1 Starting with R Markdown","heading":"1.3.7 Task 5: Making Text Bold or Italicized","text":"Sometimes want add emphasis text.report, format line two underlying hypotheses... bold. Answering question might help remember .Quickfire QuestionBold text italicized text created similarly, create italicized text? * (text)** (text)* (text)** (text)good idea knit file point make sure codes working correctly.","code":""},{"path":"starting-with-r-markdown.html","id":"Ch1InClassQueT6","chapter":"1 Starting with R Markdown","heading":"1.3.8 Task 6: Adding Links to the Data in your Methods","text":"Good practice Report include information got data .Create new heading list two hypotheses call Methods. Set Header 2 size.Methods write new heading called Data set Header 3 size.Underneath Methods heading, copy paste sentence turn citation internet link paper.\"data report obtained within original paper (Lebowitz & Judisch, 1967). \"Now knit document make sure formatting working. Titles bigger normal text list indented numbers start line.\ncan get web address following link paper shown towards beginning lab activity. Include https part.\n\nUse R Markdown cheatsheet see insert links. something square brackets [] circular brackets () next .\n","code":""},{"path":"starting-with-r-markdown.html","id":"Ch1InClassQueT7","chapter":"1 Starting with R Markdown","heading":"1.3.9 Task 7: Adding an Image to your Methods","text":"certain studies, may want add image Methods section, either stimuli, materials, procedure. look R Markdown cheatsheet see adding image similar adding link, difference exclamation mark, !, beforehand. Surprising, know!now just add image illusion taken internet illustrate add images documents.sentence added Task 6, add new heading called Stimuli set Header 3 size.Stimuli heading, insert image following web address:\nRemember good methods section contain necessary information required another researcher replicate experiment exactly! normally split three sections including Participants, Materials, Procedure.\n\nmay sound obvious surprised many Methods sections give enough information replicating study. Articles tend word counts - just like assignments. Authors tended cut words can fit discussion results. Methods sections suffered result. !\n","code":"https://upload.wikimedia.org/wikipedia/en/8/89/Ponzo_Illusion.jpg"},{"path":"starting-with-r-markdown.html","id":"Ch1InClassQueT8","chapter":"1 Starting with R Markdown","heading":"1.3.10 Task 8: Adding a Table to your Results","text":"Another benefit R Markdown can insert tables results directly report without format - though aesthetics want learn format tables eventually. now...Create new heading methods sentence, called Results format Header 2 size.Add new code chunk give name table, include code shown . first part code my_table <- group_by %>% summarise creates table stores my_table. second part code my_table calls table. Calls means display show sense.Add echo rule code included final document ouput table included.Now, knit document see produced. see code, just output table.","code":"\nmy_table <- group_by(ponzo_data, Sex) %>% \n  summarise(NofGroups=n(), mean_length = mean(ComparisonLength))\n\nmy_table"},{"path":"starting-with-r-markdown.html","id":"Ch1InClassQueT9","chapter":"1 Starting with R Markdown","heading":"1.3.11 Task 9: Adding a Figure to your Results","text":"Nearly research reports figure want add one well.Underneath table code chunk, add new code chunk give name plot.Add code chunk set include rule code plot included final report.\nmay notice assigned data table my_table called my_table show . However, figure. just put code figure assign . ?\n\ngreat answer assign assign either, chop change throughout labs show difference tendency assign tables assign figures. Simply often creating figures show therefore assigning calling requires code. Tables hand often stored work later, makes sense assign .\n\nhard fast rule often assign figures just makes quicker . ever assign figure remember call , figure displayed!\n, knit document make sure working correctly. table now ggplot code followed nice scatterplot. Thinking Cap Point think figure answer following question.\"Based distribution data, shown Figure, ...\" age increases, people perceive shorter vertical line length standard vertical lineas age increases, people perceive longer vertical line length standard vertical lingeThere relationship Age Ponzo illusionThis figure tells nothing relationship Age Ponzo illusion\ndot represent Figure, pattern dots?\nlearn improve visualisations progress, now completed bones first report! Compare report one created see match, can found end chapter click download .Rmd file zip folder. Fix anything formatted template.\nreal-world scenario plotting R Markdown can save lot effort. Say carried experiment, made figure results using R Script, wrote report using Microsoft Word. realised forgot include two participants. fix , re-run R script, make new plot, save plot, transfer Word document. However, used R Markdown begin analysis report place, can simply update code within document new figure created exact place old one. Magic!\n\ncode uses ggplot2 package used . main package use plots, figures, visualisations, however like call . can called library , automatically called call tidyverse package. Later, revist ggplot2 detail. now, using make scatterplot (geom_point) Age (Mean_Age) Comparison Length (ComparisonLength), splitting data males females.\nJob Done - Activity Complete!Great work! now created rough layout report. section missing Discussion relate information previous research study showed. Feel free add one time; read short summary end actual paper help get thoughts together. Well done successfully creating R Markdown file!practice newly acquired skills really strengthen , complete exercise .","code":"\nggplot(ponzo_data, \n       aes(x = Mean_Age, y = ComparisonLength, color = Sex)) +\n  geom_point()"},{"path":"starting-with-r-markdown.html","id":"practice-your-skills","chapter":"1 Starting with R Markdown","heading":"1.4 Practice Your Skills","text":"brief exercise practice skills taught chapter. future assignments ask coding interpretation, exercise just want familiarise working .Rmd files.set task can practice 1) downloading assignment files, 2) renaming files, 3) editing .Rmd file, 4) saving edited .Rmd file.Download filesYou first need download file zip folder Moodle open R RStudio. exercise, can also download ZIP file .Simply follow instructions .Rmd document find ZIP file. Enjoy!","code":""},{"path":"starting-with-r-markdown.html","id":"solutions-to-questions","chapter":"1 Starting with R Markdown","heading":"1.5 Solutions to Questions","text":"find solutions questions Activities chapter. look giving questions good try speaking tutor issues.","code":""},{"path":"starting-with-r-markdown.html","id":"task-2-give-your-report-a-heading","chapter":"1 Starting with R Markdown","heading":"1.5.1 Task 2: Give your Report a Heading","text":"used one hashtag give biggest heading size.# Lab 1 - magnitude Ponzo Illusion varies function AgeReturn Task","code":""},{"path":"starting-with-r-markdown.html","id":"task-3-creating-a-code-chunk","chapter":"1 Starting with R Markdown","heading":"1.5.2 Task 3: Creating a Code Chunk","text":"echo rule, warning rule message rule set FALSE. , start code chunk look like:Return Task","code":"```{r load_data, echo = FALSE, warning = FALSE, message = FALSE}```"},{"path":"starting-with-r-markdown.html","id":"task-4-writing-your-report","chapter":"1 Starting with R Markdown","heading":"1.5.3 Task 4: Writing your Report","text":"Task 4 setting title Header 2 style. done via two ## start line - word Introduction case forget space.## IntroductionWorth noting: basic R Scripts, # start line result turning line comment. , R Markdown, # sets header size much like Word document headerFor second part, create ordered list putting 1 followed . space first piece information. 2 . second, . Note lists work empty line list well:Return Task","code":"1. The Perspective Hypothesis\n2. The Framing Hypothesis"},{"path":"starting-with-r-markdown.html","id":"task-5-making-text-bold-or-italicized","chapter":"1 Starting with R Markdown","heading":"1.5.4 Task 5: Making Text Bold or Italicized","text":"turn text bold need put two ** start end word sentence want bold, e.g.Return Task","code":"**make me bold**"},{"path":"starting-with-r-markdown.html","id":"task-6-adding-links-to-the-data-in-your-methods","chapter":"1 Starting with R Markdown","heading":"1.5.5 Task 6: Adding Links to the Data in your Methods","text":"set header Header 2 style use ## start line.set header Header 3 style use ### start line.link created putting words want act link [] link immediately (). example:","code":"[Lebowitz and Judisch (2016)](https://www.jstor.org/stable/1420548?seq=1#page_scan_tab_contents)"},{"path":"starting-with-r-markdown.html","id":"task-7-adding-an-image-to-your-methods","chapter":"1 Starting with R Markdown","heading":"1.5.6 Task 7: Adding an Image to your Methods","text":"set header Header 3 style use ### start line.image created putting words want act name image [] link image immediately (). key thing start exclamation mark !. example:thereforeReturn Task","code":"![name](link)![The Ponzo Illusion](https://upload.wikimedia.org/wikipedia/en/8/89/Ponzo_Illusion.jpg)"},{"path":"starting-with-r-markdown.html","id":"task-8-adding-a-table-to-your-results","chapter":"1 Starting with R Markdown","heading":"1.5.7 Task 8: Adding a Table to your Results","text":"set header Header 2 style use ## start line.set header Header 2 style use ## start line.code chunk heading read follows:code chunk heading read follows:Return Task","code":"```{r table, echo = FALSE}```"},{"path":"starting-with-r-markdown.html","id":"task-9-adding-a-figure-to-your-results","chapter":"1 Starting with R Markdown","heading":"1.5.8 Task 9: Adding a Figure to your Results","text":"code chunk heading read follows:Return Task","code":"```{r plot, include = TRUE}```"},{"path":"starting-with-r-markdown.html","id":"example-of-output-after-completing-all-activities","chapter":"1 Starting with R Markdown","heading":"1.5.9 Example of output after completing all activities","text":"section shows output expected follow inclass activities correctly.Note: Headings comparison appear one size smaller knit Rmd due rendering. worry look bit bigger, headers key part. output match output knitting .Rmd document found .","code":""},{"path":"starting-with-r-markdown.html","id":"the-magnitude-of-the-ponzo-illusion-varies-as-a-function-of-age","chapter":"1 Starting with R Markdown","heading":"The Magnitude of the Ponzo Illusion Varies as a Function of Age","text":"","code":""},{"path":"starting-with-r-markdown.html","id":"introduction","chapter":"1 Starting with R Markdown","heading":"Introduction","text":"Ponzo Illusion ...two underlying hypotheses may explain Ponzo Illusion. : Framing hypothesisThe Perspective hypothesis","code":""},{"path":"starting-with-r-markdown.html","id":"methods","chapter":"1 Starting with R Markdown","heading":"Methods","text":"","code":""},{"path":"starting-with-r-markdown.html","id":"data","chapter":"1 Starting with R Markdown","heading":"Data","text":"data report obtained within original paper, Lebowitz Judisch (2016)","code":""},{"path":"starting-with-r-markdown.html","id":"stimuli","chapter":"1 Starting with R Markdown","heading":"Stimuli","text":"PonzoIllusion","code":""},{"path":"starting-with-r-markdown.html","id":"results","chapter":"1 Starting with R Markdown","heading":"Results","text":"\nFigure 1.11: caption. cover later!\nChapter Complete!","code":"\nggplot(ponzo_data, \n       aes(x = Mean_Age, y = ComparisonLength, color = Sex)) +\n  geom_point()"},{"path":"data-wrangling-a-key-skill.html","id":"data-wrangling-a-key-skill","chapter":"2 Data-Wrangling: A Key Skill","heading":"2 Data-Wrangling: A Key Skill","text":"","code":""},{"path":"data-wrangling-a-key-skill.html","id":"overview-2","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.1 Overview","text":"One key skills researcher's toolbox ability work data. run experiment get lots data various files. instance, uncommon experimental software create new file every participant run participant's file contain numerous columns rows data, important. able wrangle data, manipulate different layouts, extract parts need, summarise , one important skills.next chapters aimed refreshing consolidating skills working data. chapter focuses organizing data using tidyverse package. course activities, recap main functions use , use number real datasets give wide range exposure Psychology , reiterate skills apply across different datasets. skills change, just data!\nstyle programming teach, efficient format/layout data known Tidy Data, data format easily processed tidyverse package. can read type data layout paper: Tidy Data (Wickham, 2014). surprisingly good read.\n\nHowever, data work always formatted efficient way possible. happens first step put Tidy Data format. two fundamental principles defining Tidy Data:\n\nvariable must column.\n\nobservation must row.\n\nTidy Data (Wickham, 2014) adds following principle:\n\ntype observation unit forms table.\n\nGrolemund Wickham (2017) restate third principle :\n\nvalue must cell (.e. grouping two variables together, e.g. time/date one cell).\n\ncell specific row column meet; single data point tibble cell example. Grolemund Wickham (2017) book useful read free, browsing chapter Tidy Data help visualise want arrange data. Try keep principles mind whilst .\n\nquestions answer go along help build skills: use example code guide check answer solutions end chapter. Finally, remember pro-active learning, work together community, get stuck: google trying , use cheatsheets Data Skills R Book. key cheatsheet activity Data Transformation Cheatsheet dplyr.chapter recap :Data-Wrangling Wickham Six one-table verbsAdditional useful functions count, pivot_longer, joinsPiping making efficient codes\nRemember open portfolio created Chapter 1 can add useful information work tasks. Also summarising information give chapter, words, great way learn! read might help time time explain parts .\n\ninstance, remember get help R function RStudio? Console window, can call help function (e.g. ?mutate) view reference page function. example shows get help mutate() function within dplyr, use later labs.\n","code":""},{"path":"data-wrangling-a-key-skill.html","id":"data-wrangling-basics","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.2 Data Wrangling Basics","text":"","code":""},{"path":"data-wrangling-a-key-skill.html","id":"revisiting-the-wickham-six","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.2.1 Revisiting the Wickham Six","text":"main way teach data-wrangling skills using Wickham Six one-table verbs. part tidyverse package introduced first PsyTeachR book, specifically dplyr package contained within tidyverse. six verbs often referred Wickham Six \"one-table\" dplyr verbs perform actions single table data.look basics , try look back exercises Data Skills book see used verbs (functions) previously.Wickham Six :\nuse Wickham Six frequently wrangling data definitely something making notes - just names, work particular nuances spot. Perhaps recreate table add examples.\n","code":""},{"path":"data-wrangling-a-key-skill.html","id":"learning-to-wrangle","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.2.2 Learning to Wrangle","text":"Today going using data paper: Witt et al. (2017). chastity belt perception. main research question asks: ability perform action influence perception? instance, ability hit tennis ball influence fast perceive ball moving? phrase another way, expert tennis players perceive tennis ball moving slower novice tennis players?experiment use tennis players however, used Pong task: \"computerised game participants aim block moving balls various sizes paddles\". bit like classic retro arcade game. Participants tend estimate balls moving faster block smaller paddle opposed bigger paddle. can read paper get details wish hopefully gives enough idea help understand wrangling data. cleaned data little start . begin!Download data zip file link save somewhere access. lab, use M: drive.Download data zip file link save somewhere access. lab, use M: drive.Set working directory folder data. Session >> Set Working Directory >> Choose DirectorySet working directory folder data. Session >> Set Working Directory >> Choose DirectoryOpen new script copy paste two lines load tidyverse library session load data read_csv() function storing tibble called pong_data.Open new script copy paste two lines load tidyverse library session load data read_csv() function storing tibble called pong_data.\ninstall packages Boyd Orr labs; already just need called library().\n\nHowever, using computer previously installed tidyverse package , install first (install.packages(\"tidyverse\")).\n\nalready installed tidyverse, long time ago, might worth running updates packages may old version works differently. easiest way RStudio using menu top - Tools >> Check Package Updates. can update packages individually just run updates. Tends better just update packages many packages linked.\n\nthree common mistakes see :\n\nMake sure spelt data file name exactly shown. Spaces everything. change name .csv file, fix code instead. reason different name file someone else code reproducible. say avoid using spaces filenames create, one created another researcher already , leave work .\n\nRemember uploading data use read_csv underscore, whereas data file dot name, filename.csv.\n\nCheck datafile actually folder set working directory.\nlook pong_data see organized. Type View(pong_data) glimpse(pong_data) Console window (Capital V little g).dataset, see row (observation) represents one trial per participant 288 trials 16 participants. columns (variables) dataset follows:use data master skills Wickham Six verbs, taking verb turn looking briefly. develop skills setting new challenges based ones set. 6 verbs work briefly recap two functions finishing quick look pipes. Try everything let us know anything quite get.\nData research methods stored two-dimensional tables; called data-frames, tables, tibbles. ways storing data discover time, mainly using tibbles (like info, type vignette(\"tibble\") Console window). tibble table data columns rows information, within tibble can get different r glossary(\"data type\", display = \"types data\"), .e. r glossary(\"double\"), r glossary(\"integer\"), r glossary(\"character\").\n\nNote: Double Integer can referred Numeric data, see word time time. clarity, use Double term number decimal (e.g., 3.14) Integer term whole number (e.g., 3).\n","code":"\nlibrary(\"tidyverse\")\npong_data <- read_csv(\"PongBlueRedBack 1-16 Codebook.csv\")"},{"path":"data-wrangling-a-key-skill.html","id":"Ch2PreClassQueT1","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.2.3 select() Function - keep only specific columns","text":"select() function lets us pick variables within dataset want work . example, say pong_data wanted keep columns Participant, JudgedSpeed, PaddleLength, BallSpeed, TrialNumber, HitOrMiss, need BackgroundColor BlockNumber.can two ways:Tell function variables includeTell function variables exclude -ColumnName approach (.e., minus ColumnName)second example, -BackgroundColor means 'BackgroundColor', saying columns except BackgroundColor BlockNumber. minus sign crucial part!\nTask 1: Using select() functionEither inclusion exclusion, select columns Participant, PaddleLength, TrialNumber, BackgroundColor HitOrMiss pong_data.know select() can also used reorder columns?Use select() keep columns Participant, JudgedSpeed, BallSpeed, TrialNumber, HitOrMiss, display alphabetical order, left right.\n\nremembered include dataset pong_data? Pay attention upper/lower case letters spelling!\n\n\nremembered include dataset pong_data? Pay attention upper/lower case letters spelling!\n\n\nThink first entered column names appeared. happens change order enter column names?\n\n\nThink first entered column names appeared. happens change order enter column names?\n","code":"\nselect(pong_data, Participant, JudgedSpeed, PaddleLength, BallSpeed, TrialNumber, HitOrMiss)\nselect(pong_data, -BackgroundColor, -BlockNumber)"},{"path":"data-wrangling-a-key-skill.html","id":"Ch2PreClassQueT2","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.2.4 arrange() Function - sort and arrange columns","text":"arrange() function sorts rows tibble according column tell sort .Arrange data one column, e.g., BallSpeed:Arrange data multiple columns, e.g., BallSpeed (fastest first) BackgroundColor:\ndesc() sort largest smallest, .e., descending order.\n\nCompare output two lines BallSpeed column.\n\ndesc() also work BackgroundColor?\nTask 2: Arranging Data arrange() functionArrange data pong_data two variables: HitOrMiss (putting hits - 1 - first), JudgedSpeed (fast judgement - 1 - first).\n","code":"\narrange(pong_data, BallSpeed)\narrange(pong_data, desc(BallSpeed), BackgroundColor)"},{"path":"data-wrangling-a-key-skill.html","id":"Ch2PreClassQueT3","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.2.5 filter() Function - keep only parts of the data","text":"filter() function lets us parse subset data, meaning keep parts data.example, might want keep red BackgroundColoror keep BallSpeed 4 pixelsor keep trials match red BackgroundColor BallSpeed 4 pixels. trial red background color slower 5 pixels removed.last example can also written follows. Two arguments requirements separated comma equivalent & (ampersand - meaning \"\"):say want keep specific Participant IDs. Say want just data Participants 1, 3, 10, 14 16. write follows.%% called group membership means keep ParticipantsThe c() creates little container items called vector.finally, say wanted keep Participants except Participant 7:can read != (exclamation mark followed equals) 'equal'. Participant != \"7\" means keep Participants values Participant column 7.exclamation mark can sometimes used negate function follows .Task 3: Using filter() FunctionUse filter() extract Participants fast speed judgement, speeds 2, 4, 5, 7, missed ball. Store remaining data variable called pong_fast_miss\nthree parts filter best think individually combine .\n\n\nFilter fast speed judgements (JudgedSpeed)\n\n\nFilter fast speed judgements (JudgedSpeed)\n\n\nFilter speeds 2, 4, 5 7 (BallSpeed)\n\n\nFilter speeds 2, 4, 5 7 (BallSpeed)\n\n\nFilter Misses (HitOrMiss)\n\n\nFilter Misses (HitOrMiss)\n\nthree filters one uses output preceeding one, remember filter functions can take one argument - see example . Also, JudgedSpeed HitOrMiss Integer need == instead just =.\nCommon mistakes filter()filter function useful, used wrongly can give misleading findings. important always check data perform action. say working comparative psychology run study looking cats, dogs, horses perceive emotion. say data stored tibble animal_data column called animals tells type animal participant . Something like :Ok, imagine wanted data just cats:filter(animal_data, animals == \"cat\")Exactly! wanted cats dogs?filter(animal_data, animals == \"cat\", animals == \"dog\")Right? Wrong! actually says \"give everything cat dog\". nothing cat dog, weird - like dat cog! actually want everything either cat dog, stated :filter(animal_data, animals == \"cat\" | animals == \"dog\")vertical line | symbol , just & symbol ., always pay attention want importantly code produces.","code":"\nfilter(pong_data, BackgroundColor == \"red\")\nfilter(pong_data, BallSpeed > 4)\nfilter(pong_data, BackgroundColor == \"red\", BallSpeed > 4)\nfilter(pong_data, BackgroundColor == \"red\" & BallSpeed > 4)\nfilter(pong_data, Participant %in% c(\"1\", \"3\", \"10\", \"14\", \"16\")) \nfilter(pong_data, Participant != \"7\")"},{"path":"data-wrangling-a-key-skill.html","id":"Ch2PreClassQueT4","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.2.6 mutate() Function - add new columns","text":"mutate() function lets us create new variable dataset. example, add new column pong_data background color represented numbers, red represented 1, blue represented 2.look code detail:BackgroundColorNumeric name new column adding tibble.BackgroundColor name original column tibble one take information .1 2 new codings red blue, respectively.mutate() function also handy making calculations across columns data. example, say realise made mistake experiment participant numbers 1 higher every participant, .e. Participant 1 actually numbered Participant 2, etc. something like:Note: \"new column\" name old column, .e. Participant. resulting table, Participant column new values differ values original pong_data table. may seem like overwritten values, reality created copy table altered values, lost anything: original values still pong_data store (assign) action pong_data. save change basically.general, good practice overwrite pong_data new version pong_data, store altered table new tibble, e.g., pong_data_mutated, like :Task 4: Mutating variables mutate()realise another mistake trial numbers wrong. first trial (trial number 1) practice excluded experiment actually started trial 2. Tidy :Creating new tibble called pong_data_filt store data pong_data filtering trials number 1 (TrialNumber column).Now use mutate() function renumber remaining trial numbers, pong_data_filt, starting 1 instead 2. Store output new tibble called pong_data2.\nStep 1:\n\nfilter(TrialNumber equal 1).\n\nremember store output tibble called pong_data_filt\n\nStep 2:\n\nmutate(TrialNumber = TrialNumber minus 1)\n\nexclamation mark, equals\n","code":"\npong_data <- mutate(pong_data, \n                    BackgroundColorNumeric = recode(BackgroundColor, \n                                                    \"red\" = 1, \n                                                    \"blue\" = 2))\nmutate(pong_data, Participant = Participant + 1)\npong_data_mutated <- mutate(pong_data, Participant = Participant + 1)"},{"path":"data-wrangling-a-key-skill.html","id":"Ch2PreClassQueT5","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.2.7 group_by() Function - group parts of data together","text":"group_by() function groups rows dataset according category specify, e.g., animals example , grouping cat data together, dog data together, horse data together.Looking data within pong_data2, say wanted eventually create means, etc., different background color conditions, start grouping trials BackgroundColor, grouping data red background data blue background data:can add numerous grouping variables depending want split data. group Hit Miss (HitOrMiss column) background color (Red Blue). gives four groups (.e, Hit Red, Miss Red, Hit Blue, Miss Blue):Note: Nothing actually appears change data, unlike functions, big operation taken place. Look output console run group_by(pong_data2, BackgroundColor). top output notice 2nd line output tells us grouping criteria many groups now exist: see line Groups: BackgroundColor [2]: grouped BackgroundColor [2] groups - one red one blue.Task 5: Grouping Data group_by()Group data BlockNumber BackgroundColor, order, enter number groups (.e., number) get result : \nprocedure different column names:\n\ngroup_by(pong_data2, HitOrMiss, BackgroundColor)\n\nnumber groups product (.e., multiplication) sum number background colors (red blue) number blocks (12).\ngroup_by() incredibly useful , data organised groups, can apply functions (filter, arrange, mutate,...) groups within data interested , instead entire dataset. instance, common second step group_by might summarise data.Good know: ungroup() functionThe ungroup() function undoes action group_by() function.grouping data together using group_by() function performing task , e.g., filter(), summarise(), can good practice ungroup data performing another function. Forgetting ungroup dataset always affect processing, sometimes can really mess things.just good reminder always check data getting function ) makes sense b) expect.","code":"\ngroup_by(pong_data2, BackgroundColor)\ngroup_by(pong_data2, HitOrMiss, BackgroundColor)"},{"path":"data-wrangling-a-key-skill.html","id":"Ch2PreClassQueT6","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.2.8 summarise() Function - do some calculations on the data","text":"summarise() function lets calculate descriptive statistics data. example, say want count number hits different paddle lengths number hits background color red blue.First group data accordingly, storing pong_data2_groupThen summarise , storing answer total_hitsFinally, fun can filter just red, small paddle hits summarised data.leave us :Table 2.1: Summarising group_by() summarise()Tip: name column within pong_data2_hits_red_small summarised data total_hits; called creating pong_data2_hits. called anything wanted, always try use something sensible. Make sure call variables something (anyone looking code) understand recognize later (.e., variable1, variable2, variable3. etc.), avoid spaces (use_underscores_never_spaces).summarise() range internal functions make life really easy, e.g., mean(), median(), n(), sum(), max, min, etc. common ones shown , see dplyr cheatsheets examples.Task 6: Summarising Data summarise()Use lines code calculate mean number hits made small paddle (50) red color background. Enter value box two decimal places (e.g., 0.12): Quickfire QuestionsWhich Wickham Six use sort columns smallest largest: selectfiltermutatearrangegroup_bysummariseWhich Wickham Six use sort columns smallest largest: selectfiltermutatearrangegroup_bysummariseWhich Wickham Six use calculate mean column: selectfiltermutatearrangegroup_bysummariseWhich Wickham Six use calculate mean column: selectfiltermutatearrangegroup_bysummariseWhich Wickham Six use remove certain observations - e.g. remove males: selectfiltermutatearrangegroup_bysummariseWhich Wickham Six use remove certain observations - e.g. remove males: selectfiltermutatearrangegroup_bysummarise","code":"\npong_data2_group <- group_by(pong_data2, BackgroundColor, PaddleLength)\npong_data2_hits <- summarise(pong_data2_group, total_hits = sum(HitOrMiss))\npong_data2_hits_red_small <- filter(pong_data2_hits, BackgroundColor == \"red\", PaddleLength == 50)## `summarise()` has grouped output by 'BackgroundColor'. You can override using the `.groups` argument.\n## `summarise()` has grouped output by 'BackgroundColor'. You can override using the `.groups` argument."},{"path":"data-wrangling-a-key-skill.html","id":"other-useful-functions-bind_rows-and-count","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.2.9 Other Useful Functions: bind_rows() and count()","text":"Wickham Six verbs let lot things data however thousands functions disposal. want something data sure using functions, Google search alternative function - chances someone else problem help guide.Two useful functions bind_rows() function count() function. briefly show .Binding columns bind_rows()bind_rows() function useful want combine two tibbles together one larger tibble column structure, .e. exactly columns want combine attaching one bottom :Say tibble data ball speeds 1 2:another tibble data ball speeds 6 7:Now combine tibbles together one big tibble containing extreme ball speeds:Count count() functionThe count() function shortcut can sometimes used count number rows groups data, without use group_by() summarise() functions. tally basically. sum values. just counts many observations .example, Task 6 combined group_by() summarise() calculate many hits based background color paddle length. Alternatively, done:results , just count() version get information, including misses, just counting rows. summarise() method got hits effect summed. two different methods give similar answers.","code":"\nslow_ball<- filter(pong_data2, BallSpeed < 3) \nfast_ball <- filter(pong_data2, BallSpeed >= 6) \nextreme_balls <- bind_rows(slow_ball, fast_ball) \ncount(pong_data2, BackgroundColor, PaddleLength, HitOrMiss)"},{"path":"data-wrangling-a-key-skill.html","id":"pipes---make-your-code-efficient","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.2.10 Pipes (%>%) - make your code efficient","text":"now noticed thattidyverse functions generally take following grammatical structure (called syntax): function_name(dataset, arg1, arg2,..., argN) dataset entire tibble data using argument (arg) operation particular column variable, column name want work . example:examples follow structure function_name(dataset, arg1, arg2, ....)first example, filtering (function) whole pong_data2 dataset particular paddle length, particular speeds (arguments). second, grouping BallSpeed Participant. Note order arguments specific performs argument1 argument2, etc. Changing order arguments may give different output. order work important, called pipeline. example, pipeline used find many hits small paddle length red background.First group data accordingly, storing pong_data2_groupThen summarise , storing answer total_hitsAnd finally filter just red, small paddle hitsPipelines allow us quickly reproducibly perform action take much longer manually. However, can make code even efficient, using less code, stringing sequence functions together using 'pipes', written %>%. Changing code one using pipes give us:chunks show exactly procedure, adding pipes can make code easier read understand piping.Compare code without pipe:function_name(dataset, arg1, arg2,...,argN)o code pipe:dataset %>% function_name(arg1, arg2,...,argN)premise can pipe (%>%) functions input function output previous function. Alternatively, can use pipe put data first function, shown directly .can think pipe (%>%) saying '' 'goes ', e.g., data goes function function function.One last point pipes can written single line code much easier see pipe function takes line. Every time add function pipeline, remember add %>% first note using separate lines function, %>% must appear end line start next line. Compare two examples . first work, second second puts pipes end line need !Example 1: work pipes (%>%) wrong place.Example 2: work pipes (%>%) correct place.\npiping becomes useful string series functions together, rather using separate steps save data time new tibble name getting confused. non-piped version create new tibble time, example, data, data_filtered, data_arranged, data_grouped, data_summarised just get final one actually want, data_summarised. creates lot tibbles environment can make everything unclear eventually slow computer. piped version however uses one tibble name, saving space environment, clear easy read. pipes, skip unnecessary steps avoid cluttering environment.\nQuickfire QuestionsWhat line code say? data %>% filter() %>% group_by() %>% summarise(): take data group filter summarise ittake data filter group summarise ittake data summarise filter group ittake data group summarise filter ","code":"\nfilter(pong_data2, PaddleLength == \"50\", BallSpeed > 4)\ngroup_by(pong_data2, BallSpeed, Participant)\npong_data2_group <- group_by(pong_data, BackgroundColor, PaddleLength)\npong_data2_hits <- summarise(pong_data2_group, total_hits = sum(HitOrMiss))\npong_data2_hits_red_small <- filter(pong_data2_hits, BackgroundColor == \"red\", PaddleLength == 50)\npong_data_hits_red_small <- pong_data2 %>% \n  group_by(BackgroundColor, PaddleLength) %>% \n  summarise(total_hits = sum(HitOrMiss)) %>%\n  filter(BackgroundColor == \"red\", PaddleLength == 50)data_arrange <- pong_data2 \n                %>% filter(PaddleLength == \"50\")\n                %>% arrange(BallSpeed) \ndata_arrange <- pong_data2 %>%\n                filter(PaddleLength == \"50\") %>%\n                arrange(BallSpeed) "},{"path":"data-wrangling-a-key-skill.html","id":"data-wrangling-application","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.3 Data Wrangling Application","text":"looked series functions known Wickham six one-table filter, arrange, group_by, select, mutate summarise. Now focus working data across two tables using functions come across Data Skills book. two main functions add Wickham six pivot_longer() inner_join().pivot_longer() allows us transform table wide format long format.\nuse Tidy Data really efficient works well tidyverse. However, people used use data structured long format wide format.\n\nLong format row single observation, typically single trial experiment response single item questionnaire. multiple trials per participant, multiple rows participant. identify participants, need variable kind participant id, can simple distinct integer value participant. addition participant identifier, measurements taken observation (e.g., response time) experimental condition observation taken .\n\nwide format data, row corresponds single participant, multiple observations participant spread across columns. instance, survey data, separate column survey question.\n\nTidy mix approaches functions tidyverse assume tidy format, typically first thing need get data, particularly wide-format data, reshape wrangling. teach really important skills.\ninner_join() allows us combine two tables together based common columns.Analysing Autism Spectrum Quotient (AQ)continue building data wrangling skills recap skills Data Skills book tidying data Autism Spectrum Quotient (AQ) questionnaire. completed Data Skills book may familiar AQ10; non-diagnostic short form AQ 10 questions per participant. discrete scale higher participant scores AQ10 autistic-like traits said display. Anyone scoring 7 recommended diagnosis. can see example AQ10 link: AQ10 Example.four data files work :responses.csv containing AQ survey responses 10 questions 66 participantsqformats.csv containing information question coded, .e. forward reverse codedscoring.csv containing information many points specific response get; depending whether forward reverse codedpinfo.csv containing participant information Age, Sex importantly ID number.Click download files zip file. Now unzip files folder access .\ncsv stands 'comma separated values' basic format storing data plain text file. really just stores numbers text separated commas nothing else. great thing basic can read many different systems non-proprietary, .e., need purchase commercial software open .\nNow set working directory folder saved .csv files. dropdown menus top toolbar: Session >> Set Working Directory >> Choose Directory find folder .csv files.Today work RScript instead .Rmd, want turn R Markdown report add elements Portfolio please feel free.Thinking Cap PointNow good time make sure using RStudio effectively know window .TRUE FALSE, Console best practice Script window saving: TRUEFALSETRUE FALSE, Environment holds data objects loaded created: TRUEFALSETRUE FALSE, clicking name table Environment window open Script window: TRUEFALSE\nanswer True.\n\n\nScript window write code comments going save send people. Console practice stuff - nothing saved ; like sandbox just gets wiped away.\n\n\nScript window write code comments going save send people. Console practice stuff - nothing saved ; like sandbox just gets wiped away.\n\n\ndata load create held Environment (Global Environment) window variable name gave .\n\n\ndata load create held Environment (Global Environment) window variable name gave .\n\n\nclicking name table Environment window open Script window can look make sure expect. works tables types data. learn difference go along!\n\n\nclicking name table Environment window open Script window can look make sure expect. works tables types data. learn difference go along!\n","code":""},{"path":"data-wrangling-a-key-skill.html","id":"task-1-open-a-script","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.3.1 Task 1: Open a Script","text":"Start new RScript save folder .csv files, calling RScript something informative like AQ_DataWrangling.R.Make sure environment completely empty mix one analysis . can run following code line console clear environment clicking little brush environment window.\nRemember using script can write notes remind line code . Just put hashtag start line R ignore line. clear using Script versus R Markdown file. Script, # means line ignored, Markdown # sets line header!.\n\nrun line script, simplest way click anywhere line either press Run top script window press CTRL+Enter keyboard (mac equivalent).\n","code":"\nrm(list = ls()) "},{"path":"data-wrangling-a-key-skill.html","id":"Ch2InClassQueT2","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.3.2 Task 2: Bring in Your Library","text":"Add line code brings tidyverse package working environment run .\nCombine function library() package tidyverse remember solutions end chapter.\n\nlab machines Psychology necessary packages already machines, just need called library. however using machine install packages first ().\n\ninstall packages Psychology machines! ?\n\nalready installed can cause package stop working student tries install package machines.\n\nalready installed bit like using apps phone. Install putting app onto phone, library just opening app. already downloaded app (package) just need open (library()) use !\n","code":""},{"path":"data-wrangling-a-key-skill.html","id":"Ch2InClassQueT3","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.3.3 Task 3: Load in the Data","text":"Now load .csv datafiles using read_csv() function save tibbles environment. example, load data responses.csv save tibble responses type:Add following lines code script complete load four .csv datafiles. Use code example name tibble original filename (minus .csv part), , e.g. responses.csv gets saved responses. Remember run lines data loaded stored environment.\nwork data functions find functions similar names, give different results. One read function csv. Make sure always use read_csv() function load csv files. Nothing else. part readr package automatically brought tidyverse.\n\nsimilarly named function called read.csv(). use function. always expect use read_csv(). Although similar name work way create differences data.\n","code":"\nresponses <- read_csv(\"responses.csv\") responses <-  read_csv()    # survey responses\nqformats <-                 # question formats\nscoring <-                  # scoring info\npinfo <-                    # participant information"},{"path":"data-wrangling-a-key-skill.html","id":"Ch2InClassQueT4","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.3.4 Task 4: Review Your Data.","text":"Now data loaded always best look data get idea layout. showed one way , clicking name environment, can also use glimpse() View() functions Console window. Put name data brackets see arranged. add script though - just one-offs testing.look data responses see think Tidy answer following question: data responses TidyLongWide format\nreponses tibble far tidy; row represents multiple observations participant, .e., row shows responses multiple questions - wide format.\n","code":""},{"path":"data-wrangling-a-key-skill.html","id":"Ch2InClassQueT5","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.3.5 Task 5: Gathering Data with pivot_longer().","text":"order make easier us get AQ score participant, need change layout responses tibble wide format long format using pivot_longer() function.Copy code line script run .look code detail:first argument given pivot_longer() function tibble holds data want wrangle, responses.\nRemember written pipe well, e.g. rlong <- responses %>% pivot_longer(...)\nRemember written pipe well, e.g. rlong <- responses %>% pivot_longer(...)second argument names specific columns original tibble want gather together, Q1:Q10 meaning columns Q1 Q10.\nactually need write cols = makes things clearer.\n\"Gathering\" columns based position tibble. order columns tibble Q1 Q10, code gather two columns. , tibble, order, Q1, Q2, Q3, ... Q10, therefore code gathers columns Q1 Q10.\nColumn names put quotes exist already tibble responses.\nactually need write cols = makes things clearer.\"Gathering\" columns based position tibble. order columns tibble Q1 Q10, code gather two columns. , tibble, order, Q1, Q2, Q3, ... Q10, therefore code gathers columns Q1 Q10.Column names put quotes exist already tibble responses.third fourth arguments names new columns creating;\nfirst store question numbers, Question. .e. put question names (names_to = ...) column called \"Question\".\nsecond store values/responses, Response. .e. put values/responses questions (values_to = ...) column called \"Response\".\nnew column names put quotes already exist tibble. always case, case function.\nNote names anything using names code makes sense.\nLastly, need write names_to = ... values_to = ... otherwise columns created correctly.\nfirst store question numbers, Question. .e. put question names (names_to = ...) column called \"Question\".second store values/responses, Response. .e. put values/responses questions (values_to = ...) column called \"Response\".new column names put quotes already exist tibble. always case, case function.Note names anything using names code makes sense.Lastly, need write names_to = ... values_to = ... otherwise columns created correctly.case wondering, wanted go back way ungather data just gathered, use pivot_wider() function: e.g. rwide <- rlong %>% pivot_wider(names_from = Question, values_from = Response). want add code.Quickfire QuestionsLet's see understand pivot_longer(). Say wanted gather first three columns responses (Q1, Q2, Q3), put question numbers column called Jam, responses column called Strawberry, store everything tibble called sandwich. Fill box write: \nsandwich <- pivot_longer(responses, cols = Q1:Q3, names_to = \"Jam\", values_to = \"Strawberry\")\n\npivot_longer() wants data first, columns gather, name new column store gathered column names , finally name new column store values .\n","code":"\nrlong <- pivot_longer(responses,\n                      cols = Q1:Q10,\n                      names_to = \"Question\",\n                      values_to = \"Response\")"},{"path":"data-wrangling-a-key-skill.html","id":"Ch2InClassQueT6","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.3.6 Task 6: Combining Data.","text":"now responses data tidy format, closer getting AQ score person. However, still need add information :show question reverse forward scored - found qformatsshow number points give specific response - found scoring.typical analysis situation different information different tables need join together. pieces information contained qformats scoring, respectively, want join data rlong create one informative tidy table info.can sort join function inner_join(); function combine information two tibbles using column (columns) common tibbles.Copy line code run . piece code combines rows tibble rlong rows tibble qformats, based common column \"Question\".Now look rlong2. matched question scoring format, forward reverse.\nlot questionnaires questions Forward scored questions Reverse scored. mean? Imagine situation options replying question : 1 - extremely agree, 2 - agree, 3 - neutral, 4 - disagree, 5 - extremely disagree. forward-scoring question get 1 point extremely agree, 2 agree, 3 neutral, etc. reverse scoring question, get 5 extremely agree, 4 agree, 3 neutral, etc.\n\nreasoning behind shift sometimes agreeing disagreeing might favourable depending question worded. Secondly, sometimes questions used just catch people - imagine two similar questions one reverse meaning . scenario, people respond opposites. respond might paying attention.\nNow need combine information table, rlong2, scoring table know many points attribute question based answer participant gave, whether question forward reverse coded. , use inner_join() function, time common columns found rlong2 scoring QFormat Response. combine two columns just write sequence shown . Note: one common column two tibbles joining, combine columns avoid repeat columns new tibble. forget , new tibble names column_name.x column_name.y. cause confusion avoid combining common columns.Copy line code run . code combine rows rlong2 scoring based columns, QFormat Response.","code":"\nrlong2 <- inner_join(rlong, qformats, \"Question\")\nrscores <- inner_join(rlong2, scoring, c(\"QFormat\", \"Response\"))"},{"path":"data-wrangling-a-key-skill.html","id":"Ch2InClassQueT7","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.3.7 Task 7: Calculating the AQ Scores.","text":"now created rscores information participant responded question question coded scored, within one tibble. need now sum scores participant get AQ score.Based learning previous section, copy line code complete obtain individual aq_scores participant.Save script run start make sure works!\nparticipant grouped Id.\n\nsummed value Score might get full AQ Score particpipant.\n\nYep, well spotted. Pipes friend. Think saying '' 'goes '. example take rscores group something summarise AQ scores based ...\n\ncases, pipe serves purpose putting input function taking output one function treating input another function.\n\nexample first pipe takes rscores input group_by, second pipe takes output group_by puts input summarise. See can almost read chain actions steps.\nQuickfire QuestionsThe whole purpose chapter calculate AQ scores individual participants. Try answer following questions. Try using code possible help based knowledge chapter. Remember cheatsheets well. Look dplyr one!options, choose correct citation AQ 10 question questionnaire: Allison, Auyeung, Baron-Cohen, (2011)Allison, Auyeung, Baron-Cohen, (2012)Allison Baron-Cohen, (2012)Auyeung, Allison, Baron-Cohen, (2012)options, choose correct citation AQ 10 question questionnaire: Allison, Auyeung, Baron-Cohen, (2011)Allison, Auyeung, Baron-Cohen, (2012)Allison Baron-Cohen, (2012)Auyeung, Allison, Baron-Cohen, (2012)Complete sentence, higher AQ score...less autistic-like traits displayedhas relation autistic-like traitsthe autistic-like traits displayedComplete sentence, higher AQ score...less autistic-like traits displayedhas relation autistic-like traitsthe autistic-like traits displayedType AQ score (just number) Participant ID . 87: Type AQ score (just number) Participant ID . 87: Type many participants AQ score 3 (just number): Type many participants AQ score 3 (just number): cut-AQ10 usually said around 6 meaning anyone score 6 referred diagnostic assessment. Type many participants refer sample: cut-AQ10 usually said around 6 meaning anyone score 6 referred diagnostic assessment. Type many participants refer sample: \n\nlink can see appropriate citation AQ10 (Allison, Auyeung, Baron-Cohen, (2012))\n\n\nlink can see appropriate citation AQ10 (Allison, Auyeung, Baron-Cohen, (2012))\n\n\nmentioned, higher score AQ10 autistic-like traits participant said show.\n\n\nmentioned, higher score AQ10 autistic-like traits participant said show.\n\n\ncode filter(aq_scores, Id == 87), give tibble 1x2 showing ID number score. just wanted score use pull() shown yet works follows: filter(aq_scores, Id == 87) %>% pull(AQ). answer AQ score 2.\n\n\ncode filter(aq_scores, Id == 87), give tibble 1x2 showing ID number score. just wanted score use pull() shown yet works follows: filter(aq_scores, Id == 87) %>% pull(AQ). answer AQ score 2.\n\n\nchanging argument filter. filter(aq_scores, AQ == 3) %>% count(). answer 13. Remember can counting code makes reproducible every time.\n\n\nchanging argument filter. filter(aq_scores, AQ == 3) %>% count(). answer 13. Remember can counting code makes reproducible every time.\n\n\nfilter(aq_scores, AQ > 6) %>% count() filter(aq_scores, AQ >= 7) %>% count(). answer 6.\n\n\nfilter(aq_scores, AQ > 6) %>% count() filter(aq_scores, AQ >= 7) %>% count(). answer 6.\n","code":"\naq_scores <- rscores %>% \n             group_by() %>% # how will you group individual participants?\n             summarise(AQ = sum()) # which column will you sum to obtain AQ scores?"},{"path":"data-wrangling-a-key-skill.html","id":"Ch2InClassQueT8","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.3.8 Task 8: Practice using pipes","text":"now complete code load data, convert Tidy, combine tables calculate AQ score participant. , look , code efficient using pipes.Go back code rewrite using pipes %>% efficient possible.\npoint first argument function name variable created line, good chance used pipe! bits code piped together one chain:\n\nrlong <- pivot_longer(responses, cols = Q1:Q10, names_to = \"Question\", values_to = \"Response\")\n\nrlong2 <- inner_join(rlong, qformats, \"Question\")\n\nrscores <- inner_join(rlong2, scoring, c(\"QFormat\", \"Response\"))\n\naq_scores <- rscores %>% group_by(Id) %>% summarise(AQ = sum(Score))\n","code":""},{"path":"data-wrangling-a-key-skill.html","id":"practice-your-skills-1","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.4 Practice Your Skills","text":"order complete tasks need download data .csv files .Rmd file, need edit, titled Ch2_PracticeSkills_Template.Rmd. can downloaded within zip file link. downloaded unzipped, create new folder use working directory; put data files .Rmd file folder set working directory folder drop-menus top. Download Exercises .zip file .Now open .Rmd file within RStudio. see code chunk task. Follow instructions edit code chunk. often entering code based covered point.chapter recapped data-wrangling using Wickham 6 verbs, looked additional functions pivot_longer() inner_join(), piping chains code efficiency using %>%. need skills complete following exercises, make sure worked chapter attempting exercise. Two useful online resources :Hadley Wickham's R Data Science book @ http://r4ds..co.nz RStudio's dplyr cheatsheet @ Rstudio.comPsyTeachR Data Skills book","code":""},{"path":"data-wrangling-a-key-skill.html","id":"the-ageing-brain","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.4.1 The Ageing Brain","text":"key topic current psychological research, one forms main focus research School, human ageing. research use brain imaging techniques understand changes brain function structure relate changes perception behaviour. typical 'ageing' experiment compare measure (number measures) performance cognitive perceptual task younger older adults (.e., -subjects design experiment).However, order make sure studying 'healthy' ageing, first 'screen' older participants symptoms age-related dementia (Alzheimer's Disease), cognitive function can significantly impaired. using range cognitive tests. studies also test participants' sensory acuity (ability perceive something), function age (particularly eyesight hearing).data downloaded exercise example screening data taken research investigating ageing brain processes different types sounds. tests used study detailed . Please note links provide information examples tests completed assignment wish; read complete exercises.Montreal Cognitive Assessment (MoCA) : test specifically devised stand-alone screening tool mild cognitive impairment. Assesses visuospatial skills, memory, language, attention, orientation, abstraction skills. Example hereMontreal Cognitive Assessment (MoCA) : test specifically devised stand-alone screening tool mild cognitive impairment. Assesses visuospatial skills, memory, language, attention, orientation, abstraction skills. Example hereWorking Memory Digit Span Test (D-SPAN): measures capacity participants' short-term (working) memory.Working Memory Digit Span Test (D-SPAN): measures capacity participants' short-term (working) memory.D2 Test Attention: measures participants' selective sustained concentration visual scanning speed.D2 Test Attention: measures participants' selective sustained concentration visual scanning speed.Better Hearing Institute Quick Hearing Check: self-report questionnaire measures participants' subjective experience hearing abilities.Better Hearing Institute Quick Hearing Check: self-report questionnaire measures participants' subjective experience hearing abilities.Data FilesYou just downloaded three .csv files containing data need. list .csv file names description variables contains:p_screen.csv contains particpants demographic information including:\nID Participant Id number - confidentiality (names identifying info)\nAGE years\nSEX M male, F female\nHANDEDNESS L left-handed, R right-handed\nEDUCATION years\nMUSICAL whether musical abilties/experience (YES )\nFLANG speak foreign languages (YES )\nMOCA Montreal Cognitive Assessment score\nD-SPAN Working Memory Digit Span test score\nD2 D2 Test Attention score\nID Participant Id number - confidentiality (names identifying info)AGE yearsSEX M male, F femaleHANDEDNESS L left-handed, R right-handedEDUCATION yearsMUSICAL whether musical abilties/experience (YES )FLANG speak foreign languages (YES )MOCA Montreal Cognitive Assessment scoreD-SPAN Working Memory Digit Span test scoreD2 D2 Test Attention scoreQHC_responses.csv contains participants' responses question \"Better Hearing Institute Quick Hearing Check (QHC)\" questionnaire.\nColumn 1 represents participants' ID (matching p_screen.csv).\ncolumn thereafter represents 15 questions questionnaire.\nrow represents participant response question.\nColumn 1 represents participants' ID (matching p_screen.csv).column thereafter represents 15 questions questionnaire.row represents participant response question.QHC_scoring.csv contains scoring key question QHC, columns:\nRESPONSE types responses participants give (STRONGLY DISAGREE, SLIGHTLY DISAGREE, NEUTRAL, SLIGHTLY AGREE, STRONGLY AGREE)\nSCORE points awarded response type (0 4). score participant can calculated converting categorical responses values summing values.\nRESPONSE types responses participants give (STRONGLY DISAGREE, SLIGHTLY DISAGREE, NEUTRAL, SLIGHTLY AGREE, STRONGLY AGREE)SCORE points awarded response type (0 4). score participant can calculated converting categorical responses values summing values.starting lets check:.csv files saved folder computer manually set folder working directory..csv files saved folder computer manually set folder working directory..Rmd file saved folder .csv files..Rmd file saved folder .csv files.","code":""},{"path":"data-wrangling-a-key-skill.html","id":"load-in-the-data","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.4.2 Load in the data","text":"see code chunk called libraries, similar one , top .Rmd assignment file. set-load data call tidyverse library(). Run code chunk now bring data tidyverse. can console, script, even code chunk clicking small green play symbol top right code chunk.View dataIt always good idea familiarise layout data just loaded . can using glimpse() View() Console window, must never put functions assignment file.Tasks:Now data loaded, tidyverse attached, viewed data, now try complete following 9 tasks. may want practice first get correct code format, make sure work. can console script, remember, correct code, edit necessary parts assignment .Rmd file produce reproducible .Rmd file. now assessment files practicing now really help. short, go tasks change NULL question asks make sure file knits end fully reproducible code.","code":"\nlibrary(\"tidyverse\")\n\nscreening <- read_csv(\"p_screen.csv\")\nresponses <- read_csv(\"QHC_responses.csv\")\nscoring <- read_csv(\"QHC_scoring.csv\")"},{"path":"data-wrangling-a-key-skill.html","id":"Ch2AssignQueT1","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.4.3 Task 1 - Oldest Participant","text":"Replace NULL T1 code chunk Participant ID oldest participant. Store single value oldest_participant (e.g. oldest_participant <- 999).hint: look data, oldest?","code":"\noldest_participant <- NULL"},{"path":"data-wrangling-a-key-skill.html","id":"Ch2AssignQueT2","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.4.4 Task 2 - Arranging D-SPAN","text":"Replace NULL T2 code chunk code arranges participants' D-SPAN performance highest lowest using appropriate one-table dplyr (.e., Wickham) verb. Store output cogtest_sort. (e.g. cogtest_sort <- verb(data, argument))hint: arrange screening data","code":"\ncogtest_sort <- NULL"},{"path":"data-wrangling-a-key-skill.html","id":"Ch2AssignQueT3","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.4.5 Task 3 - Foreign Language Speakers","text":"Replace NULL two lines code chunk T3, descriptives column called n shows number participants speak foreign language number participants speak foreign language, another column called median_age shows median age two groups. done correctly, descriptives 3 columns 2 rows data, including header row.hint: First need group_by() foreign languagehint: Second need summarise(). need n() function. Pay attention specific column names given.","code":"\nscreen_groups <- NULL\ndescriptives <- NULL"},{"path":"data-wrangling-a-key-skill.html","id":"Ch2AssignQueT4","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.4.6 Task 4 - Creating Percentage MOCA scores","text":"Replace NULL T4 code chunk code using one dplyr verbs add new column called MOCA_Perc dataframe screening new column MOCA scores converted percentages. maximum achievable score MOCA 30 percentages calculated (participant score / max score) * 100. Store output screening.hint: mutate() something using MOCA percentage formula","code":"\nscreening <- NULL"},{"path":"data-wrangling-a-key-skill.html","id":"Ch2AssignQueT5","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.4.7 Task 5 - Remove the MOCA column","text":"Now MoCA score expressed percentage MOCA_Perc longer need raw scores held MOCA. Replace NULL T5 code chunk using one-table dplyr verb keep columns screening, order, without MOCA column. Store output screening.hint: select columnsThe remaining tasks focus merging two tables.suspect older adults musical experience might report finely-tuned hearing abilities without musical experience. therefore decide check whether trend exists data. measured participants' self reported hearing abilities using Better Hearing Institute Quick Hearing Check Questionnaire. questionnaire, participants rated extent agree disagree list statements (e.g., 'problem hearing telephone') using 5 point Likert scale (Strongly Disagree, Slightly Disagree, Neutral, Slightly Agree, Strongly Agree).participant's response question contained responses dataframe environment. response type worth certain number points (e.g., Strongly Disagree = 0, Strongly Agree = 5) scoring key contained scoring dataframe. score participant calculated totaling number points across questions derive overall score. lower overall score, better participants' self-reported hearing ability.order score questionnaire first need perform couple steps.","code":"\nscreening <- NULL"},{"path":"data-wrangling-a-key-skill.html","id":"Ch2AssignQueT6","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.4.8 Task 6 - Gather the Responses together","text":"Replace NULL T6 code chunk using code gather responses questions QHC wide format tidy/long format. Put names Question values RESPONSE. Store output responses_long.hint: pivot_longer()hint: names \"Question\"hint: values \"RESPONSE\"","code":"\nresponses_long <- NULL "},{"path":"data-wrangling-a-key-skill.html","id":"Ch2AssignQueT7","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.4.9 Task 7 - Joining the data","text":"Now need join number points response scoring participants' responses responses_long.Replace NULL T7 code chunk using inner_join() combine responses_long scoring new variable called responses_points.hint: join column common scoring responses_long","code":"\nresponses_points <- NULL"},{"path":"data-wrangling-a-key-skill.html","id":"Ch2AssignQueT8","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.4.10 Task 8 - Working the Pipes","text":"given five lines code takes data current long format creates QHC score participant (group_by()...summarise()). joins screening information (inner_join()) calculating mean QHC score two groups participants - play musical instruments . final step stored tibble called musical_means.Use five lines code replace NULL T8 code chunk functioning code pipeline using pipes. Put function new line one . pipeline result mean QHC values musical non-musical people stored tibble musical_means. final tibble consist two rows two columns (.e. four cells total).hint: pipes, output previous function input subsequent function.hint: function1(...) %>% function2(...)","code":"participant_groups <- group_by(responses_points, ID)\nparticipant_scores <- summarise(participant_groups, Total_QHC = sum(SCORE))\nparticipant_screening <- inner_join(participant_scores, screening, \"ID\")\nscreening_groups_new <- group_by(participant_screening, MUSICAL)\nmusical_means <- summarise(screening_groups_new, mean_score = mean(Total_QHC))\nmusical_means <- NULL"},{"path":"data-wrangling-a-key-skill.html","id":"Ch2AssignQueT9","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.4.11 Task 9 - Difference in Musical Means","text":"Finally, replace NULL T9 code chunk value much higher QHC score people play music compared people play music. single numeric value, two decimal places, e.g. 2.93hint: look musical means enter difference two means.Well done, finished! Now go check answers solutions end chapter. looking check answers submitted exactly ones solution - example, remember Mycolumn different mycolumn one correct.","code":"\nQHC_diff <- NULL"},{"path":"data-wrangling-a-key-skill.html","id":"solutions-to-questions-1","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.5 Solutions to Questions","text":"find solutions questions Activities chapter. look giving questions good try speaking tutor issues.","code":""},{"path":"data-wrangling-a-key-skill.html","id":"data-wrangling-basics-1","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.5.1 Data Wrangling Basics","text":"","code":""},{"path":"data-wrangling-a-key-skill.html","id":"task-1","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.5.1.1 Task 1","text":"Using select() include stated columns:Using select() exclude certain columns:Using select() change order columns:Return Task","code":"\nselect(pong_data, Participant, PaddleLength, TrialNumber, BackgroundColor, HitOrMiss)\nselect(pong_data, -JudgedSpeed, -BallSpeed, -BlockNumber)\nselect(pong_data, BallSpeed, HitOrMiss, JudgedSpeed, Participant, TrialNumber)"},{"path":"data-wrangling-a-key-skill.html","id":"task-2","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.5.1.2 Task 2","text":"Return Task","code":"\narrange(pong_data, desc(HitOrMiss), desc(JudgedSpeed))"},{"path":"data-wrangling-a-key-skill.html","id":"task-3","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.5.1.3 Task 3","text":"Return Task","code":"\nfilter(pong_data, \n       JudgedSpeed == 1, \n       BallSpeed %in% c(\"2\", \"4\", \"5\", \"7\"), \n       HitOrMiss == 0)"},{"path":"data-wrangling-a-key-skill.html","id":"task-4","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.5.1.4 Task 4","text":"first step created filter()second step created mutate()Return Task","code":"\npong_data_filt <- filter(pong_data, TrialNumber >= 2) \npong_data2 <- mutate(pong_data_filt, TrialNumber = TrialNumber - 1)"},{"path":"data-wrangling-a-key-skill.html","id":"task-5","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.5.1.5 Task 5","text":"Return Task","code":"\ngroup_by(pong_data2, BlockNumber, BackgroundColor)"},{"path":"data-wrangling-a-key-skill.html","id":"task-6","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.5.1.6 Task 6","text":"find number hits made small paddle (50) red color background 0.450655Return Task","code":"\npong_data2_group <- group_by(pong_data2, BackgroundColor, PaddleLength)\npong_data2_hits <- summarise(pong_data2_group, mean_hits = mean(HitOrMiss))## `summarise()` has grouped output by 'BackgroundColor'. You can override using the `.groups` argument."},{"path":"data-wrangling-a-key-skill.html","id":"data-wrangling-application-1","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.5.2 Data Wrangling Application","text":"","code":""},{"path":"data-wrangling-a-key-skill.html","id":"task-2-1","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.5.2.1 Task 2","text":"orNote, difference library(tidyverse) library(\"tidyverse\") work.Return Task","code":"\nlibrary(tidyverse)\nlibrary(\"tidyverse\")"},{"path":"data-wrangling-a-key-skill.html","id":"task-3-1","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.5.2.2 Task 3","text":"Note difference responses <- read_csv(\"responses.csv\") responses <- read_csv(responses.csv). need quotes around .csv filename shown code chunk (e.g. responses <- read_csv(\"responses.csv\")), code work.Return Task","code":"\nresponses <- read_csv(\"responses.csv\")                  \nqformats <- read_csv(\"qformats.csv\")                 \nscoring <- read_csv(\"scoring.csv\")                  \npinfo <- read_csv(\"pinfo.csv\")"},{"path":"data-wrangling-a-key-skill.html","id":"task-7","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.5.2.3 Task 7","text":"Return Task","code":"\naq_scores <- rscores %>% \n             group_by(Id) %>% # group by the ID number in column Id\n             summarise(AQ = sum(Score)) # sum column Score to obtain AQ scores."},{"path":"data-wrangling-a-key-skill.html","id":"task-8","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.5.2.4 Task 8","text":"Return Task","code":"\naq_scores2 <- responses %>% \n  pivot_longer(cols = Q1:Q10,\n               names_to = \"Question\",\n               values_to = \"Response\") %>%\n  inner_join(qformats, \"Question\") %>%\n  inner_join(scoring, c(\"QFormat\", \"Response\")) %>%\n             group_by(Id) %>% \n             summarise(AQ = sum(Score))"},{"path":"data-wrangling-a-key-skill.html","id":"practice-your-skills-2","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.5.3 Practice Your Skills","text":"","code":""},{"path":"data-wrangling-a-key-skill.html","id":"task-1---oldest-participant","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.5.3.1 Task 1 - Oldest Participant","text":"Whether coded answer just read data, Participant ID Number 3 oldest.also answered code. quite shown yet look like :Return Task","code":"\noldest_participant <- 3\noldest_participant_code <- arrange(screening, desc(AGE)) %>% \n  slice(1) %>% \n  pull(ID)"},{"path":"data-wrangling-a-key-skill.html","id":"task-2---arranging-d-span","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.5.3.2 Task 2 - Arranging D-SPAN","text":"arrange() main function hereYou also needed use desc() sort high lowReturn Task","code":"\ncogtest_sort <- arrange(screening, desc(DSPAN))"},{"path":"data-wrangling-a-key-skill.html","id":"task-3---foreign-language-speakers","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.5.3.3 Task 3 - Foreign Language Speakers","text":"First group screening data FLANG using group_by()Next, summarise, paying attention use variable names instructedn() function use within summarise() count many observations . works like count() use count() within summarise()median() function use within summarise() calculate median. Much like sum() mean() sd(), etc.Return Task","code":"\nscreen_groups <- group_by(screening, FLANG) \ndescriptives <- summarise(screen_groups, \n                          n = n(), \n                          median_age = median(AGE))"},{"path":"data-wrangling-a-key-skill.html","id":"task-4---creating-percentage-moca-scores","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.5.3.4 Task 4 - Creating Percentage MOCA scores","text":"mutate() function add new column dataHere mutating/adding column called MOCA_Perc shows participant's MOCA score divided 30 multiplied 100.Return Task","code":"\nscreening <- mutate(screening, MOCA_Perc = (MOCA / 30) * 100)"},{"path":"data-wrangling-a-key-skill.html","id":"task-5---remove-the-moca-column","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.5.3.5 Task 5 - Remove the MOCA column","text":"select() key function keep remove certain columns.Two options ; give dataframe.first option shows deselect column keep everything else.second option shows select columns want.Remember order important select columns order want.Option 1:Option 2:Return Task","code":"\nscreening <- select(screening, -MOCA)\nscreening <- select(screening, ID, AGE, SEX, HANDEDNESS, EDUCATION, MUSICAL, FLANG, DSPAN, D2, MOCA_Perc)"},{"path":"data-wrangling-a-key-skill.html","id":"task-6---gather-the-responses-together","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.5.3.6 Task 6 - Gather the Responses together","text":"pivot_longer() function use .People take understand function spend time looking example start make sense.first argument data. case responses.second argument name columns want gather. gathering columns Q1 column Q15 column. Remember colon (:) says \"... ...\"\nactually need write cols = makes things clearer.\n\"Gathering\" columns based position tibble. order columns tibble Q1 Q15, code gather two columns. , tibble, order, Q1, Q2, Q3, ... Q15, therefore code gathers columns Q1 Q15.\nColum names put quotes exist already tibble responses.\nactually need write cols = makes things clearer.\"Gathering\" columns based position tibble. order columns tibble Q1 Q15, code gather two columns. , tibble, order, Q1, Q2, Q3, ... Q15, therefore code gathers columns Q1 Q15.Colum names put quotes exist already tibble responses.third fourth arguments names new columns creating;\nfirst store question numbers, Question. .e. put question names (names_to = ...) column called \"Question\".\nsecond store values/responses, Response. .e. put values/responses questions (values_to = ...) column called \"Response\".\nnew column names put quotes already exist tibble. always case case function.\nNote names anything using names code makes sense.\nLastly, need write names_to = ... values_to = ... otherwise columns created correctly.\nfirst store question numbers, Question. .e. put question names (names_to = ...) column called \"Question\".second store values/responses, Response. .e. put values/responses questions (values_to = ...) column called \"Response\".new column names put quotes already exist tibble. always case case function.Note names anything using names code makes sense.Lastly, need write names_to = ... values_to = ... otherwise columns created correctly.Return Task","code":"\nresponses_long <- pivot_longer(responses, \n                         cols = Q1:Q15, \n                         names_to = \"Question\", \n                         values_to = \"RESPONSE\")"},{"path":"data-wrangling-a-key-skill.html","id":"task-7---joining-the-data","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.5.3.7 Task 7 - Joining the data","text":"inner_join() combine common information two sets data common column columns.joining data responses_long data scoring common column RESPONSE.Keep mind inner_join() keeps rows data datasets. remove rows data one dataset.joining two datasets, join common columns one column common.Return Task","code":"\nresponses_points <- inner_join(responses_long, scoring, \"RESPONSE\")"},{"path":"data-wrangling-a-key-skill.html","id":"task-8---working-the-pipes","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.5.3.8 Task 8 - Working the Pipes","text":"code started .transcribe series functions pipeline.Remember, using pipes, output previous function input subsequent functionReturn Task","code":"\nparticipant_groups <- group_by(responses_points, ID)\nparticipant_scores <- summarise(participant_groups, Total_QHC = sum(SCORE))\nparticipant_screening <- inner_join(participant_scores, screening, \"ID\")\nscreening_groups_new <- group_by(participant_screening, MUSICAL)\nmusical_means <- summarise(screening_groups_new, mean_score = mean(Total_QHC))\nmusical_means <- group_by(responses_points, ID) %>%\n                  summarise(Total_QHC = sum(SCORE)) %>%\n                  inner_join(screening, \"ID\") %>%\n                  group_by(MUSICAL) %>%\n                  summarise(mean_score = mean(Total_QHC))"},{"path":"data-wrangling-a-key-skill.html","id":"task-9---difference-in-musical-means","chapter":"2 Data-Wrangling: A Key Skill","heading":"2.5.3.9 Task 9 - Difference in Musical Means","text":"People play music QHC score 1.53 units higher people play music.can looking musical_means, reading values, quick maths.second option code. Code always better can reduce error reproducible!Return Task","code":"\n# Option 1\nQHC_diff <- 1.53\n\n# Option 2\n# You will soon learn the functions to do this by code but here is how you could do it.\nQHC_diff_code <- pivot_wider(musical_means, \n                             names_from = \"MUSICAL\", \n                             values_from = \"mean_score\") %>% \n  mutate(diff = YES - NO) %>% \n  pull(diff) %>% \n  round(2)"},{"path":"data-visualisation-through-ggplot2.html","id":"data-visualisation-through-ggplot2","chapter":"3 Data Visualisation Through ggplot2","heading":"3 Data Visualisation Through ggplot2","text":"","code":""},{"path":"data-visualisation-through-ggplot2.html","id":"overview-3","chapter":"3 Data Visualisation Through ggplot2","heading":"3.1 Overview","text":"Data visualisation important understanding data. key part data analysis exploring data, checking assumptions, displaying results. Figures plots allow get insight patterns data. example, regards seeing differences groups, also seeing things quite match think happening. great example Anscombe's Quartet, can read later date like - see - four datasets given exact means, different underlying structures visualised. key point always good visualise data visualisation common step data skills set.PsyTeachR Data Skills book introduced data visualisation using ggplot2, main visualisation package tidyverse. look back working chapter, can find additional info main page package: ggplot2.visualisaion use ggplot2 listed great online resources might want consult want fuller understanding:R Graphics Cookbookggplot2 bookggplot2 cheatsheetggplot2 Reference GuideIn chapter, revisit plotting data expand skills order make effective informative figures. become really beneficial progress data visualisation skill applies multiple careers, just Psychology.chapter :Recap data visualisationExpand skills produce new figuresLearn Mental Rotation research","code":""},{"path":"data-visualisation-through-ggplot2.html","id":"data-visualisation-basics","chapter":"3 Data Visualisation Through ggplot2","heading":"3.2 Data Visualisation Basics","text":"","code":""},{"path":"data-visualisation-through-ggplot2.html","id":"introducing-the-data-set-mental-rotation-ability","chapter":"3 Data Visualisation Through ggplot2","heading":"3.2.1 Introducing the Data Set: Mental Rotation Ability","text":"data use today comes replication classic experiment merging fields Perception Cognition. Shepard Metzler (1971) demonstrated participants shown two similar three-dimensional shapes, one just rotated version (see figure - top panel), asked whether shape , reaction time error rates responses function rotation; .e. larger difference rotation two shapes, longer took participants say \"\" \"different\", errors made.\nFigure 3.1: Mental Rotation Task shown Ganis Kievit (2016) Figure 1\nimage shown Figure 3.1 actually comes replication Ganis Kievit (2016). top panel two shapes shape right rotated vertically 150 degrees original (left shape) participants respond \"\". bottom panel, however, two shapes different; one right rotated 150 degrees, trial takes longer participants realise different shapes.can read Ganis Kievit (2016) time, basic methods ran 54 participants series images using four angles rotation (0, 50, 100, 150 degrees) asked people respond '' 'different' trial. data can downloaded . use data follow along try answer questions.Look dataDownload data folder, unzip , save folder access .Set working directory folder Session >> Set Working Directory >> Choose DirectoryOpen new Rscript .RMarkdown file save within folder contains data, giving script sensible name, e.g. Chapter3_visualisations.R. prefer work RMarkdown, just remember need embed code code chunks, shown Chapter 1.Copy three code lines script run bring tidyverse library read two data files.Note, difference library(tidyverse) library(\"tidyverse\") work.However, difference demog <- read_csv(\"demographics.csv\") demog <- read_csv(demographics.csv). need quotes around .csv file name shown code chunk (e.g. demog <- read_csv(\"demographics.csv\")), code work.\nreally great question always seem saying use dplyr readr ggplot, never actually call . Remember, however, tidyverse actually collection packages, common packages fact, use bring common packages (including ggplot2) probably need packages along codes run smoothly. try tell need call packages alongside tidyverse, keep mind codes least start tidyverse package.\n\nSmall point, looking help ggplot, package actually called ggplot2. newer version package, search ggplot2 need help.\n\nstart look data brought . can whichever way choose; mentioned three ways previous chapter.First, demog - short demographics. three columns:Participant - ID participantAge - age participantSex - sex participantSecondly, menrot - short mental rotation. 8 columns:Participant - ID participant; matches ID demogTrial - trial number experiment participantCondition - name image shown; R indicates rotated image differentTime - reaction time respond trial millisecondsDesiredResponse - participants responded trial; Different SameActualResponse - participants respond trial; Different SameAngle - angle shape right rotated compared shape left (0, 50, 100, 150)CorrectResponse - whether participant correct incorrect given trial\nGanis Kievit (2016) short paper really introduce stimuli set rather give extensive background topic mental rotation - call 'methods paper'. said, writing paper clear procedure well detailed ran actual experiment.\n\nwriting procedure, remember give much information needed allow someone exactly replicate study. read procedure time think information , also information , help develop writing reports. example, fingers participants use respond important?\nnow data want create plots visualise . show code create four types plots get practice , remember PsyTeachR Data Skills book. go plots, edit/change code give see differences can control changes can create plots. Editing altering code works see happens change something great way working.","code":"\nlibrary(\"tidyverse\")\n\nmenrot <- read_csv(\"MentalRotationBehavioralData.csv\")\ndemog <- read_csv(\"demographics.csv\")"},{"path":"data-visualisation-through-ggplot2.html","id":"basic-structure-of-ggplot","chapter":"3 Data Visualisation Through ggplot2","heading":"3.2.2 Basic Structure of ggplot()","text":"two main things know working ggplot :usual ggplot format :ggplot(data, aes(x = x_axis, y = y_axis)) + geom_type_of_plot()first thing enter dataframe/tibble; data. , within aes() say x_axis y_axis, using column names within tibble. aes stands aesthetics maps data visual features. Finally, tell code type plot want.ggplot works concept layersLayers common way graphics work. Think ggplot() function creating first layer every function adding layers top create figure want. first layer always data axis/axes, .e. `ggplot(....). second layer, added using plus symbol '+', type plot. look adding layers progress.ggplot() powerful package used whole range industries, including newspapers mainstream media outlets, can make quite sophisticated images. One beauties data skills just transferable across many fields.","code":""},{"path":"data-visualisation-through-ggplot2.html","id":"scatterplots---geom_point","chapter":"3 Data Visualisation Through ggplot2","heading":"3.2.3 Scatterplots - geom_point()","text":"Scatterplots great way visualising continuous data - data can take value scale measured. example, current dataset, can use scatterplots explore potential relationship two continuous variables Age Reaction Time: variables increase/decrease rate (.e., positive relationship)? one variable increase decrease (.e., negative relationship)? maybe overall relationship?data, say want test overall average time respond mental rotation task related age participant highlighting sex participants. show relationship scatterplot using code , :Wrangles data create average response time participant, Mean_Time, joins information demographic data, Participant. stored tibble menrot_time_age.plots scatterplot (geom_point()) age plotted x-axis, Mean_Time y-axisFinally, uses additional aes call color Sex color point based whether male female participant responding. default coloring call two options. Later look controlling using colors .\nFigure 3.2: scatterplot Mean Time function Age\nQuickfire QuestionsLooking scatterplot Figure 3.2, can say relationship age overall response time? age increases, overall response time increasesas age increases, overall response time decreasesthere overall relationshipLooking scatterplot Figure 3.2, can say relationship age overall response time? age increases, overall response time increasesas age increases, overall response time decreasesthere overall relationshipLooking scatterplot, can say difference male female participants? males show increase overall response time age femalesfemales show increase overall response time age malesthere real difference males females terms overall response time ageLooking scatterplot, can say difference male female participants? males show increase overall response time age femalesfemales show increase overall response time age malesthere real difference males females terms overall response time age\nlook figure, appear age increases (x-axis) overall resposne time (y-axis)? age decreases overall response time? maybe even age increases, overall response time decreases? Well, actually, looking figure appears relationship two variables case one either increases decreases . relationship appears flat.\n\ncomparing sex, based color dots, appears major differences relationship looks flat sex.\n\nLater book look correlational analysis - method quantifying relationship two variables.\nNote: often case visualise data first wrangle format. using functions saw Chapter 2, make sure tasks understood wrangle verbs pipes work. Keep mind functions use format, function(data, argument)","code":"\nmenrot_time_age <- group_by(menrot, Participant) %>% \n  summarise(Mean_Time = mean(Time, na.rm = TRUE)) %>%\n  inner_join(demog, \"Participant\")\n\nggplot(data = menrot_time_age, \n       aes(x = Age, \n           y = Mean_Time, \n           color = Sex)) +\n  geom_point()"},{"path":"data-visualisation-through-ggplot2.html","id":"histograms---geom_histogram","chapter":"3 Data Visualisation Through ggplot2","heading":"3.2.4 Histograms - geom_histogram()","text":"Histograms great way showing overall distribution data. data look normally distributed? data skewed - positive skew negative skew? peaky? flat? terms become familiar learn statistics, try think terms concepts visualising looking data.Looking data, say wanted test overall distribution mean response times correct trials normally distributed. visualise question following code, :Wrangles data create average response time participant, Mean_Time, filters information correct trials . stored tibble menrot_hist_correct.Plots histogram (geom_histogram()) Mean_Time plotted x-axis, count value Mean_Time plotted y-axis. code creates y-axis automatically state :\nFigure 3.3: histogram distribution Mean Time counts\nQuickfire QuestionsLooking histogram Figure 3.3, can say overall shape distribution? data looks reasonably normally distributedthe data looks positively skewedthe data looks negatively skewedLooking histogram Figure 3.3, can say overall shape distribution? data looks reasonably normally distributedthe data looks positively skewedthe data looks negatively skewedLooking histogram, common average overall response time correct trials? approximately 2000 millisecondsapproximately 2500 millisecondsapproximately 3000 millisecondsLooking histogram, common average overall response time correct trials? approximately 2000 millisecondsapproximately 2500 millisecondsapproximately 3000 milliseconds\nKeep mind real data never give beautiful textbook shape see classic diagrams looking normally distributed data skewed data. decisions regarding distributions often require degree judgement.\n\nPositive skewed data means data shifted left (low numbers) tail stretching right (high numbers). Negative skew data shifted right (high numbers) tail stretching left (low numbers). Normally distributed data data middle even tails either side. Although perfect, data shown histogram reasonable representation normally distributed data real world; particularly small sample participants.\n\ny-axis count values x-axis, common overall response time can found reading highest column data. distribution, looks around 2500 milliseconds 2.5 seconds.\n","code":"\nmenrot_hist_correct <- group_by(menrot, Participant, CorrectResponse) %>% \n  summarise(Mean_Time = mean(Time, na.rm = TRUE)) %>%\n  filter(CorrectResponse == \"Correct\")\n\nggplot(data = menrot_hist_correct, \n       aes(x = Mean_Time)) + \n  geom_histogram()"},{"path":"data-visualisation-through-ggplot2.html","id":"boxplots---geom_boxplot","chapter":"3 Data Visualisation Through ggplot2","heading":"3.2.5 Boxplots - geom_boxplot()","text":"Boxplots great means visualising spread data highlighting outliers data. looking boxplots, consider:whether median (thick horizontal black line) middle box higher lower middle box?whether box evenly distributed around median ?box whiskers (vertical tails top bottom box) similar length sides box?outliers - usually highlighted star dot beyond whiskers?look compare distributions mean reaction times correct incorrect responses. can done using code, :Repeats first two wrangle steps created scatterplot, additionally groups CorrectResponse, stores data tibble menrot_box_correctPlots boxplot (geom_boxplot()) overall average response times y-axis, Mean_Time, based condition, CorrectResponse, x-axisUses additional aes call fill colour boxplots, two categories, based whether CorrectResponse correct incorrect. default look editing later.Turns legend using guides() call needed x-axis tells group . later though.Run code first. , run code fill = TRUE instead. difference? Notice fill name call ggplot(...) function. linked.\nFigure 3.4: boxplot spreads Mean Time Correct Incorrect Responses\nQuickfire QuestionsLooking boxplots, many outliers ? 1230Looking boxplots, many outliers ? 1230Looking boxplots Figure 3.4, condition longer median overall average response time mental rotation task? Median response time longer Correct responsesMedian response time longer Incorrect responsesBoth medians approximatelyLooking boxplots Figure 3.4, condition longer median overall average response time mental rotation task? Median response time longer Correct responsesMedian response time longer Incorrect responsesBoth medians approximately\nnumber ways determining outliers. Two methods standard deviations (usually 2.5 3 SD used cut-offs) boxplots, outlier determined \\(1.5*IQR\\) (inter-quartile range) top bottom box. Outliers shown dots whiskers boxplot. can see figure outliers see data.\n\nmedian one five values required make boxplot shown horizontal thick black line within box . Looking two conditions comparing position median y-axis (response time) can see median response time incorrect trials higher correct trials. suggest people take longer make mind give decision trials get wrong. Makes sense think ; uncertainty takes longer leads errors.\n","code":"\nmenrot_box_correct <- group_by(menrot, Participant, CorrectResponse) %>% \n  summarise(Mean_Time = mean(Time, na.rm = TRUE)) %>%\n  inner_join(demog, \"Participant\")\n\nggplot(data = menrot_box_correct, \n       aes(x = CorrectResponse, \n           y = Mean_Time, \n           fill = CorrectResponse)) + \n  geom_boxplot() +\n  guides(fill = FALSE)## `summarise()` has grouped output by 'Participant'. You can override using the `.groups` argument.## Warning: `guides(<scale> = FALSE)` is deprecated. Please use `guides(<scale> =\n## \"none\")` instead."},{"path":"data-visualisation-through-ggplot2.html","id":"barplots---geom_bar-or-geom_col","chapter":"3 Data Visualisation Through ggplot2","heading":"3.2.6 Barplots - geom_bar() or geom_col()","text":"Barplots typically show specific values condition. Sometimes really simple like count variable mean, e.g. many people replied yes. Others show something bit complex average spread values via error bars, e.g. standard error. looking barplots, main considerations whether appears difference conditions interested whether conditions .worth knowing barplots now used less frequently actually show lot information, discussed blog, One simple step improving statistical inference. However, still see used great able create interpret .Using geom_bar()Using data, say interested whether difference average percentage correct incorrect responses across male female participants. visualise using following code, :Wrangles data series steps establish overall percent average correct incorrect responses sex, stored menrot_resp_sex.Plots barplot (geom_bar()) condition Sex x-axis, Avg_Percent y-axis, created wrangle, fill bars based CorrectResponse.Finally, within geom_bar says treat data final values average , stat = \"identity\", makes columns visible moving apart position = position_dodge(.9)) - without last step bars overlap see everything. Try changing .9.Note: participant 96 trials study.\nFigure 3.5: barplot average percent Correct Incorrect responses Female Male participants - using geom_bar()\nUsing geom_col()geom_col() - short column - alternative geom_bar() require part code say anything data, .e. stat=\"identity\". shown . Notice difference codes, produce figure.\nFigure 3.6: barplot average percent Correct Incorrect responses Female Male participants - using geom_col()\nQuickfire QuestionsLooking barplot data, average, sex correct responses? femalemaleboth samecan't tellLooking barplot data, average, sex correct responses? femalemaleboth samecan't tellLooking barplot data, average, sex incorrect responses? femalemaleboth samecan't tellLooking barplot data, average, sex incorrect responses? femalemaleboth samecan't tellLooking code, happens decrease position.dodge() value? bars get apartthe bars start overlapnothing changes figureLooking code, happens decrease position.dodge() value? bars get apartthe bars start overlapnothing changes figureLooking code, happens change aes call fill color? bars stay different colorthe bars become grey outlines become different colorsnothing changes figureLooking code, happens change aes call fill color? bars stay different colorthe bars become grey outlines become different colorsnothing changes figure\nRemember barplots plotting mean, top column average value condition. actually people like barplots; though commonly used, really show one value data, average, disregard information unless indication spread given.\n\nmind, comparing two Correct columns can see females average correct responses males. Incorrect columns can see males incorrect responses females. actually makes sense response option experiment either correct incorrect, add correct incorrect percentage responses one sex together get 100%. females gave correct reponses must given less incorrect responses.\n\nlast two questions playing code. Remember said plots work concept layers. set position.dodge() 0, find one columns disappears completely overlap now. need set position.dodge() reasonable value columns separate. set 1? barplots, often find different levels (categories) variable touching. Note, however, value dodge, case 1, relative size x-axis - scale x-axis ran 0 100 dodge 1 little effect. Sometimes need little trial error. Always look output code.\n\nfinal point shows can add lot calls just x y axis change presentation figures. fill changes color columns, color changes outline color columns. see progress look difference putting inside aes() outside . play figures see happens. worth pointing though, turned legend using guides(fill = FALSE), works used fill = ... call change colours. used color = ... call change colours need use guides(colors = FALSE) turn legend. See linked? guide matches called.\n","code":"\ntotal_n_trials <- 96\n\nmenrot_resp_sex <- count(menrot, Participant, CorrectResponse) %>% \n  inner_join(demog, \"Participant\") %>%\n  mutate(PercentPerParticipant = (n/total_n_trials)*100) %>%\n  group_by(Sex, CorrectResponse) %>%\n  summarise(Avg_Percent = mean(PercentPerParticipant))\n\nggplot(data = menrot_resp_sex, \n       aes(x = Sex, \n           y = Avg_Percent, \n           fill = CorrectResponse)) + \n  geom_bar(stat = \"identity\", \n           position = position_dodge(.9))## `summarise()` has grouped output by 'Sex'. You can override using the `.groups` argument.\nggplot(data = menrot_resp_sex, \n       aes(x = Sex, \n           y = Avg_Percent, \n           fill = CorrectResponse)) +\n  geom_col(position = position_dodge(.9))"},{"path":"data-visualisation-through-ggplot2.html","id":"themes-labels-guides-and-facet_wraps","chapter":"3 Data Visualisation Through ggplot2","heading":"3.2.7 Themes, Labels, Guides, and facet_wraps()","text":"couple layers can add ggplot calls make figures look professional. show code , want run teach work changing code, removing parts within ggplot, adding figures shown .themes - changing overall presentation figure. Try running code comparing figure barplot . Remember, ?theme_bw() give information look cheatsheets different themes theme_light(), theme_classic(), theme_gray() theme_dark().\ntheme_gray() actually default equivalent stating theme function.\n_ theme_classic() close basic APA figure presentation.\nthemes - changing overall presentation figure. Try running code comparing figure barplot . Remember, ?theme_bw() give information look cheatsheets different themes theme_light(), theme_classic(), theme_gray() theme_dark().theme_gray() actually default equivalent stating theme function.\n_ theme_classic() close basic APA figure presentation.labs - putting appropriate labels figures readers understand displayed. Try changing text within quotes.labs - putting appropriate labels figures readers understand displayed. Try changing text within quotes.facet_wraps - splitting data separate figures clarity. work one conditions categorical, can really effective means displaying information.facet_wraps - splitting data separate figures clarity. work one conditions categorical, can really effective means displaying information.guides - remove see happens. understand use fill situation, perhaps others?guides - remove see happens. understand use fill situation, perhaps others?Try running editing code:","code":"\ntotal_n_trials <- 96\n\nmenrot_better_plot <- count(menrot, Participant, CorrectResponse) %>% \n  inner_join(demog, \"Participant\") %>%\n  mutate(PercentPerParticipant = n/total_n_trials) %>%\n  group_by(Sex, CorrectResponse) %>%\n  summarise(Avg_Percent = mean(PercentPerParticipant))\n\nggplot(data = menrot_better_plot, \n       aes(x = Sex,\n           y = Avg_Percent, \n           fill = CorrectResponse)) + \n  geom_col(position = position_dodge(.9)) +\n  labs(x = \"Sex of Participant\", \n       y = \"Percent Average (%)\") +\n  guides(fill = FALSE) +\n  facet_wrap(~CorrectResponse) +\n  theme_bw()"},{"path":"data-visualisation-through-ggplot2.html","id":"choosing-appropriate-figures","chapter":"3 Data Visualisation Through ggplot2","heading":"3.2.8 Choosing Appropriate Figures","text":"progress Psychology, come across variety different figures plots, looking slightly different giving different information. looking figures, indeed choosing one analyses, think figure appropriate data. example, scatterplots great variables continuous; boxplots histograms great viewing spreads data; barplots commonly used one variable categorical - note barplots can misleading lots new approaches display categorical information created. Violin-boxplots taught Chapter 7 Data Skills book provide complete way data visualisation. Always keep asking , plot display data correctly. Also, right number dots/conditions/groups figure? many suggest something quite right. Look data!","code":""},{"path":"data-visualisation-through-ggplot2.html","id":"data-visualisation-application","chapter":"3 Data Visualisation Through ggplot2","heading":"3.3 Data Visualisation Application","text":"","code":""},{"path":"data-visualisation-through-ggplot2.html","id":"mental-rotation-angle-and-reaction-time","chapter":"3 Data Visualisation Through ggplot2","heading":"3.3.1 Mental Rotation: Angle and Reaction Time","text":"continue using data set Ganis Kievit (2016). understanding experiment well develop skills visualisation interpretation, look mean reaction time correct trials, function angle rotation sex. idea rotated test image original image, longer take participants determine image completely different images. Fifty-four participants responded '' 'different' trial series rotated images using four angles rotation (0, 50, 100, 150 degrees rotated compared original). Link data.\ncome across phrase 'function ' quite bit dealing visualisations. means something like 'compared ' 'across'. say going look Mean Reaction Time across four different Angles Rotation written Mean Reaction Time function Angle Rotation. Usually, plotted y-axis function x-axis. similar idea functions use codes want see happens put y function x. good become familiar terms language used reports ) understand reading b) can use language writing.\n","code":""},{"path":"data-visualisation-through-ggplot2.html","id":"Ch3InClassQueT1","chapter":"3 Data Visualisation Through ggplot2","heading":"3.3.2 Task 1: Loading and Viewing the Data","text":"Download data, unzip , save folder access .Set working directory folder data .Start new script .Rmd file (RMarkdown), save folder data .script, load tidyverse library.Load datasets exactly , storing experimental data menrot demographic data demog.\nlibrary()\n\nmenrot <- read_csv()\n\ndemog <- read_csv()\n\nRemember always looking data good practice make sure expect . Use either View() glimpse(), console window RStudio, never script .Rmd file. useful functions can use check data structure :str() - shows type data . Look words like table, dataframe, character, integer, double.head(), tail(), names() - show top six bottom six rows column names, just column names names().dim() - shows dimensions data.Refer previous section list columns refer sure. keep mind reproducible means careful spelling punctuation names functions, tibbles, columns, conditions, etc, times - e.g. Juggler juggler.Quickfire QuestionsTake couple minutes try functions answer following questions.options, type data variable Angle, found dataframe menrot? characterintegerdouble/numericalFrom options, type data variable Angle, found dataframe menrot? characterintegerdouble/numericalType box name dataframe contains information regarding sex participants: Type box name dataframe contains information regarding sex participants: options, column within menrot? CorrectresponseCorretcResponseCorrectResponsecorrectReponseFrom options, column within menrot? CorrectresponseCorretcResponseCorrectResponsecorrectReponseFrom options, according dim() call, many rows demog? 38545184From options, according dim() call, many rows demog? 38545184\nmaking sure loading data correctly, using instructed names - reproducible - understand data looking . completed Task 1 successfully, loading data correct dataframes, following answers work questions.\n\n\ncalling str(menrot) looking information comes see data column Angle loaded double/numerical. Technically integers (whole numbers decimal places), default load make numerical.\n\n\ncalling str(menrot) looking information comes see data column Angle loaded double/numerical. Technically integers (whole numbers decimal places), default load make numerical.\n\n\ndemog loaded information regarding demographics including sex participant.\n\n\ndemog loaded information regarding demographics including sex participant.\n\n\nnames(menrot) give column names. question making sure correct spelling: CorrectResponse. spellings work data spelling column names specific!\n\n\nnames(menrot) give column names. question making sure correct spelling: CorrectResponse. spellings work data spelling column names specific!\n\n\ndim(demog) shows number rows (54) number columns (3).\n\n\ndim(demog) shows number rows (54) number columns (3).\n","code":""},{"path":"data-visualisation-through-ggplot2.html","id":"Ch3InClassQueT2","chapter":"3 Data Visualisation Through ggplot2","heading":"3.3.3 Task 2: Recreating the Figure","text":"start making representation top part Figure 2 Ganis Kievit (2016) - Mean Reaction Time function Angle Rotation.Copy lines code script.Copy lines code script.Replace NULLs order recreate figure similar Ganis Kievit (2016) Figure 2 (top).\nNote figure shows information correct responses just Ganis Kievit (2016).\nRemember ggplot case layers. first layer says data want axis. Every subsequent layer says want data displayed - points (geom_point()) connecting line (geom_line()).\nrunning tasks, come back one see can figure coord_cartesian() changing numbers ylim = () call. comment solutions.\nReplace NULLs order recreate figure similar Ganis Kievit (2016) Figure 2 (top).Note figure shows information correct responses just Ganis Kievit (2016).Remember ggplot case layers. first layer says data want axis. Every subsequent layer says want data displayed - points (geom_point()) connecting line (geom_line()).running tasks, come back one see can figure coord_cartesian() changing numbers ylim = () call. comment solutions.\nfirst four lines, create menrot_angle, functions Wickham Six verbs refer back see work.\n\n\nanswer CorrectResponse allow keep just correct answers?\n\n\nanswer CorrectResponse allow keep just correct answers?\n\n\ncommon variable allow join information demog?\n\n\ncommon variable allow join information demog?\n\n\nreally care four levels rotation, variable/column group_by?\n\n\nreally care four levels rotation, variable/column group_by?\n\n\nvariable/column want mean mean response time?\n\n\nvariable/column want mean mean response time?\n\nggplot line, think format, data, x-axis name, y-axis name.\n\nFigure 3.7: Basic Scatterplot Response Time Angle Rotation\nThinking Cap PointGreat, replicated figure! However, know means? figure tell mean reaction time angle rotation, fit overall theory introduced ? Answering question may help:options, figure suggest angle rotation increases: mean reaction time decreasesmean reaction time stays samemean reaction time increases\ncan see figure, consistent Shepard Metzler (1971), participants Ganis Kievit (2016) showed increase reaction time angle rotation increased. Therefore, Ganis Kievit (2016) replicated findings Shepard Metzler (1971).\n\nquick note though , yes, mean reaction time increase angle rotation, consistent increase. see difference mean reaction times 150 100 degrees smaller 0 50. Reaction times start plateau certain angle rotation.\n","code":"\nmenrot_angle <- filter(menrot, CorrectResponse == NULL) %>%\n  inner_join(demog, NULL) %>%\n  group_by(NULL) %>% \n  summarise(mean_Resp = mean(NULL))\n\nggplot(data = NULL, aes(x = NULL, y = NULL)) + \n  geom_point() +\n  geom_line() +\n  coord_cartesian(ylim = c(0, 3500), expand = TRUE)"},{"path":"data-visualisation-through-ggplot2.html","id":"Ch3InClassQueT3","chapter":"3 Data Visualisation Through ggplot2","heading":"3.3.4 Task 3: Examining Additional Variable Effects","text":"previous section, looked sex participant quite interesting. covered Ganis Kievit (2016), let us take look .pipeline Task 2, add variable Sex group_by() function group data Angle Sex.Running code creates figure.\nRemember, add grouping variables just separate comma. Everything else code stays .\n\nFigure 3.8: Separating points Sex\nHmmm, figure look informative. looks similar one created dots doubled - now 8 instead 4 - know male female, connecting line confusing. need add little code tell separate data based Sex.","code":"## `summarise()` has grouped output by 'Angle'. You can override using the `.groups` argument."},{"path":"data-visualisation-through-ggplot2.html","id":"Ch3InClassQueT4","chapter":"3 Data Visualisation Through ggplot2","heading":"3.3.5 Task 4: Grouping the Figure Data","text":"previous section used fill color inside aes() change basic information figure. also one called group. Add group call inside aes(...) separate data Sex.Run code see figure looks like\nggplot(....., aes(x = , y = , group = ???))\nnow least see different lines two sex, still tell sex line, can ? just looks like two black parallel lines, one slightly higher . ideal changing color points based whether male female participants! Fortunately, geoms can also take information well.","code":""},{"path":"data-visualisation-through-ggplot2.html","id":"Ch3InClassQueT5","chapter":"3 Data Visualisation Through ggplot2","heading":"3.3.6 Task 5: Identifying Groups Using aes()","text":"Add aes() call inside geom_point() function color dots Sex.\ngeom_point(aes(??? = ???)\n\nnow something like :\n\nFigure 3.9: Separate lines Sex\nGreat! can now see female line top male line bottom. start interpreting figure finish tidying tasks. example dots data point perhaps little small see, increase size. Also, color great can print color, also change shape dots help people distinguish Sex displaying color option. use additional calls shape size within geom_point().","code":"## `summarise()` has grouped output by 'Angle'. You can override using the `.groups` argument."},{"path":"data-visualisation-through-ggplot2.html","id":"Ch3InClassQueT6","chapter":"3 Data Visualisation Through ggplot2","heading":"3.3.7 Task 6: Changing the Shape and Size of Data Points","text":"want Sex different shaped points, add call shape within aes() call geom_point() function, just like color.want Sex different shaped points, add call shape within aes() call geom_point() function, just like color.However, want Sex size point, add call size within geom_point() function, inside aes() call. Set appropriate number size instead naming variable. Maybe size = 3?However, want Sex size point, add call size within geom_point() function, inside aes() call. Set appropriate number size instead naming variable. Maybe size = 3?\ngeom_point(aes(color = Sex, Shape = ???), size = ???)\ngive figure like :\nFigure 3.10: Changing Shape Size Data Points\nquick point - , , aes ?Hopefully beginning spot difference setting call within aes() (stands aesthetics) setting outside aes(). Outside aes() means observations take one value color type. Inside means observation within condition takes value color type, different conditions different values/color/type.look done help us compare:size called outside aes() assign specific value. can see Task 6 figure, condition now size points. set size want, keep smallish: 3 5 ok; 50 artistic, informative. set size within aes(), something like geom_point(aes(shape = Sex, size = Sex)) male female different shapes different sizes. can play around code see things work.size called outside aes() assign specific value. can see Task 6 figure, condition now size points. set size want, keep smallish: 3 5 ok; 50 artistic, informative. set size within aes(), something like geom_point(aes(shape = Sex, size = Sex)) male female different shapes different sizes. can play around code see things work.contrast, called shape inside aes() set based variable, Sex. way ensures level Sex variable, male female, get different shape. instead set shape outside aes(), something like geom_point(shape = 3, size = 3) conditions shape size. Different numbers relate different shapes different sizes. example compare shape = 3 shape = 13In contrast, called shape inside aes() set based variable, Sex. way ensures level Sex variable, male female, get different shape. instead set shape outside aes(), something like geom_point(shape = 3, size = 3) conditions shape size. Different numbers relate different shapes different sizes. example compare shape = 3 shape = 13There arguments use: example, wanted points color, say red example, geom_point(color = \"red\"). Remember put quotes around color.hopefully starting make sense can think implementing figures. Note arguments separated comma. e.g. geom_point(color = \"red\", size = 3, shape = 2).","code":"## `summarise()` has grouped output by 'Angle'. You can override using the `.groups` argument."},{"path":"data-visualisation-through-ggplot2.html","id":"Ch3InClassQueT7","chapter":"3 Data Visualisation Through ggplot2","heading":"3.3.8 Task 7: Adding Labels and Changing the Background","text":"figure looking really nice now. finish adding appropriate labels editing background. introduced previous section hopefully play see work.change label, use labs() function works like labs(x = \"Name\", y = \"Name\", title = \"Name\").Add function code y-axis indicates Mean Reaction Time (ms) x-axis indicates Angle Rotation (degrees). set title , can want practice. Titles Psychology figures common.Add function code y-axis indicates Mean Reaction Time (ms) x-axis indicates Angle Rotation (degrees). set title , can want practice. Titles Psychology figures common.Set figure theme_bw() - looks nice, options might want try can explore ?theme cheatsheet.Set figure theme_bw() - looks nice, options might want try can explore ?theme cheatsheet.\nlabs(x = \"...\", y = \"...\") + theme_bw()\n\nkey thing remember + layer ggplot chain. get confused pipes (%>%).\n\nNote: add (+) layers figures, pipe (%>%) functions.\n","code":""},{"path":"data-visualisation-through-ggplot2.html","id":"Ch3InClassQueT8","chapter":"3 Data Visualisation Through ggplot2","heading":"3.3.9 Task 8: Separating a Variable and Removing Legends","text":"Finally, showed two functions use tidy figures: facet_wrap() guides().facet_wrap() really effective splitting figures panels based variable; works like facet_wrap(~variable) ~ can read . \"split figure variable\", example Sex. two variables split figure , : facet_wrap(~variable1 + variable2).facet_wrap() really effective splitting figures panels based variable; works like facet_wrap(~variable) ~ can read . \"split figure variable\", example Sex. two variables split figure , : facet_wrap(~variable1 + variable2).guides() handy turning legends might taking space. instance, use facet_wrap() split panels Female Male, really need legend right saying Female Male? normally guide color, shape, etc, calls pipeline within aes() calls. works like guide(call = FALSE).guides() handy turning legends might taking space. instance, use facet_wrap() split panels Female Male, really need legend right saying Female Male? normally guide color, shape, etc, calls pipeline within aes() calls. works like guide(call = FALSE).Add facet_wrap() separate panels figure based Sex.Add facet_wrap() separate panels figure based Sex.Turn guides legend figure.Turn guides legend figure.\nfacet_wrap(~variable)\n\nguides(group = FALSE, ???? = False, ....)\nThinking Cap PointIf followed tasks correctly, following figure:\nFigure 3.11: finished figure!\nTake minutes look figure try interpret terms reaction time function rotation sex. Try answering following questions:sexes, mean reaction time decreases withincreases withis unaffected angle rotation.sexes, mean reaction time decreases withincreases withis unaffected angle rotation.Angle Rotation influences female participantsmale participants female participantsmale participantsAngle Rotation influences female participantsmale participants female participantsmale participants\nlooking figure, angle rotation increases (moving right x-axis), mean reaction time increases (getting higher y-axis), indicating participants take longer respond target image rotated original. Also, male mean reaction times quicker overall female mean reaction times, differences reaction times 0 degrees 150 degrees smaller males, perhaps say males affected less females, males perform task quicker.\n\nKeep mind looking correct responses . , figure suggest difference just male participants just responding quicker overall; instead may suggest males responding correctly quicker overall.\n\nDifferences mental rotation tasks received much attention years refer reference sections two main papers activity wish follow topic .\n","code":"## `summarise()` has grouped output by 'Sex'. You can override using the `.groups` argument.## Warning: `guides(<scale> = FALSE)` is deprecated. Please use `guides(<scale> =\n## \"none\")` instead."},{"path":"data-visualisation-through-ggplot2.html","id":"final-considerations","chapter":"3 Data Visualisation Through ggplot2","heading":"3.3.10 Final Considerations","text":"Many options seen terms geom_point() applied geom_line() make alterations line. Try playing options. example, code line result sexes red line equal size, style line different. Give shot!geom_line(aes(linetype = Sex), size = .5, color = \"red\")Finally, look closely figure, see line points actually goes front points. looks bit messy. make tidier line run behind data points? sure? Remember figures constructed based series layers. draw one layer next, try changing Task 8 draw lines first points top. Give go!chapter looked working layers variety calls shape, color, fills, etc, create professional looking figures. Understanding figures ggplot can seem like trial error lot experience. beauty figure really like, run code get exactly figure .","code":"\nggplot(data = menrot_facet_guide, aes(x = Angle, y = mean_Resp, group = Sex)) + \n  geom_line() +\n  geom_point(aes(color = Sex, shape = Sex), size = 3) +\n  coord_cartesian(ylim = c(0, 3500), expand = TRUE) +\n  labs(x = \"Angel of Rotation (degrees)\", y = \"Mean Reaction Time (ms)\") +\n  facet_wrap(~Sex) +\n  guides(group = FALSE, color = FALSE, shape = FALSE) +\n  theme_bw()"},{"path":"data-visualisation-through-ggplot2.html","id":"Ch3PracticeSkills","chapter":"3 Data Visualisation Through ggplot2","heading":"3.4 Practice Your Skills","text":"order complete tasks need download data .csv files .Rmd file, need edit, titled Ch3_PracticeSkills_Visualisations.Rmd. can downloaded within zip file link. downloaded unzipped, create new folder use working directory; put data files .Rmd file folder set working directory folder drop-menus top. Download Exercises .zip file .Now open .Rmd file within RStudio. see code chunk task. Follow instructions edit code chunk. often entering code based covered point.Happy Data Visualising!","code":""},{"path":"data-visualisation-through-ggplot2.html","id":"solutions-to-questions-2","chapter":"3 Data Visualisation Through ggplot2","heading":"3.5 Solutions to Questions","text":"find solutions questions Activities chapter. look giving questions good try speaking tutor issues.","code":""},{"path":"data-visualisation-through-ggplot2.html","id":"data-visualisation-application-1","chapter":"3 Data Visualisation Through ggplot2","heading":"3.5.1 Data Visualisation Application","text":"","code":""},{"path":"data-visualisation-through-ggplot2.html","id":"task-1-1","chapter":"3 Data Visualisation Through ggplot2","heading":"3.5.1.1 Task 1","text":"Return Task","code":"\nlibrary(\"tidyverse\")\n\nmenrot <- read_csv(\"MentalRotationBehavioralData.csv\")\ndemog <- read_csv(\"demographics.csv\")"},{"path":"data-visualisation-through-ggplot2.html","id":"task-2-2","chapter":"3 Data Visualisation Through ggplot2","heading":"3.5.1.2 Task 2","text":"coord_cartesian() function can used show certain parts figure, controlling visible X Y axes. expand = TRUE adds smaller buffer numbers set. want remove buffer set expand = FALSE.Return Task","code":"\nmenrot_angle <- filter(menrot, CorrectResponse == \"Correct\") %>%\n  inner_join(demog, \"Participant\") %>%\n  group_by(Angle) %>% \n  summarise(mean_Resp = mean(Time))\n\nggplot(data = menrot_angle, aes(x = Angle, y = mean_Resp)) + \n  geom_point() +\n  geom_line() +\n  coord_cartesian(ylim = c(0, 3500), expand = TRUE)"},{"path":"data-visualisation-through-ggplot2.html","id":"task-3-2","chapter":"3 Data Visualisation Through ggplot2","heading":"3.5.1.3 Task 3","text":"Return Task","code":"\nmenrot_angle_sex <- filter(menrot, CorrectResponse == \"Correct\") %>%\n  inner_join(demog, \"Participant\") %>%\n  group_by(Angle, Sex) %>% \n  summarise(mean_Resp = mean(Time))\n\nggplot(data = menrot_angle_sex, aes(x = Angle, y = mean_Resp)) + \n  geom_point() +\n  geom_line() +\n  coord_cartesian(ylim = c(0, 3500), expand = TRUE)"},{"path":"data-visualisation-through-ggplot2.html","id":"task-4-1","chapter":"3 Data Visualisation Through ggplot2","heading":"3.5.1.4 Task 4","text":"Return Task","code":"\nmenrot_grouped <- filter(menrot, CorrectResponse == \"Correct\") %>%\n  inner_join(demog, \"Participant\") %>%\n  group_by(Angle, Sex) %>% \n  summarise(mean_Resp = mean(Time))\n\nggplot(data = menrot_grouped, aes(x = Angle, y = mean_Resp, group = Sex)) + \n  geom_point() +\n  geom_line() +\n  coord_cartesian(ylim = c(0, 3500), expand = TRUE)"},{"path":"data-visualisation-through-ggplot2.html","id":"task-5-1","chapter":"3 Data Visualisation Through ggplot2","heading":"3.5.1.5 Task 5","text":"Return Task","code":"\nmenrot_grouped_color <- filter(menrot, CorrectResponse == \"Correct\") %>%\n  inner_join(demog, \"Participant\") %>%\n  group_by(Angle, Sex) %>% \n  summarise(mean_Resp = mean(Time))\n\nggplot(data = menrot_grouped_color, aes(x = Angle, y = mean_Resp, group = Sex)) + \n  geom_point(aes(color = Sex)) +\n  geom_line() +\n  coord_cartesian(ylim = c(0, 3500), expand = TRUE)"},{"path":"data-visualisation-through-ggplot2.html","id":"task-6-1","chapter":"3 Data Visualisation Through ggplot2","heading":"3.5.1.6 Task 6","text":"Return Task","code":"\nmenrot_shape_size <- filter(menrot, CorrectResponse == \"Correct\") %>%\n  inner_join(demog, \"Participant\") %>%\n  group_by(Angle, Sex) %>% \n  summarise(mean_Resp = mean(Time))\n\nggplot(data = menrot_shape_size, aes(x = Angle, y = mean_Resp, group = Sex)) + \n  geom_point(aes(color = Sex, shape = Sex), size = 3) +\n  geom_line() +\n  coord_cartesian(ylim = c(0, 3500), expand = TRUE)"},{"path":"data-visualisation-through-ggplot2.html","id":"task-7-1","chapter":"3 Data Visualisation Through ggplot2","heading":"3.5.1.7 Task 7","text":"Return Task","code":"\nmenrot_lab_theme <- filter(menrot, CorrectResponse == \"Correct\") %>%\n  inner_join(demog, \"Participant\") %>%\n  group_by(Angle, Sex) %>% \n  summarise(mean_Resp = mean(Time))\n\nggplot(data = menrot_lab_theme, aes(x = Angle, y = mean_Resp, group = Sex)) + \n  geom_point(aes(color = Sex, shape = Sex), size = 3) +\n  geom_line() +\n  coord_cartesian(ylim = c(0, 3500), expand = TRUE) +\n  labs(x = \"Angel of Rotation (degrees)\", y = \"Mean Reaction Time (ms)\") +\n  theme_bw()"},{"path":"data-visualisation-through-ggplot2.html","id":"task-8-1","chapter":"3 Data Visualisation Through ggplot2","heading":"3.5.1.8 Task 8","text":"\nFigure 3.12: Task 8\nRemembering layer system, use code lines behind points.\nFigure 3.13: Task 8 Alternative\nReturn Task","code":"\nmanrot_facet_guide <- filter(menrot, CorrectResponse == \"Correct\") %>%\n  inner_join(demog, \"Participant\") %>%\n  group_by(Angle, Sex) %>% \n  summarise(mean_Resp = mean(Time))## `summarise()` has grouped output by 'Angle'. You can override using the `.groups` argument.\nggplot(data = manrot_facet_guide, aes(x = Angle, y = mean_Resp, group = Sex)) + \n  geom_point(aes(color = Sex, shape = Sex), size = 3) +\n  geom_line() +\n  coord_cartesian(ylim = c(0, 3500), expand = TRUE) +\n  labs(x = \"Angel of Rotation (degrees)\", y = \"Mean Reaction Time (ms)\") +\n  facet_wrap(~Sex) +\n  guides(group = FALSE, color = FALSE, shape = FALSE) +\n  theme_bw()## Warning: `guides(<scale> = FALSE)` is deprecated. Please use `guides(<scale> =\n## \"none\")` instead.\nmanrot_facet_guide <- filter(menrot, CorrectResponse == \"Correct\") %>%\n  inner_join(demog, \"Participant\") %>%\n  group_by(Angle, Sex) %>% \n  summarise(mean_Resp = mean(Time))## `summarise()` has grouped output by 'Angle'. You can override using the `.groups` argument.\nggplot(data = manrot_facet_guide, aes(x = Angle, y = mean_Resp, group = Sex)) + \n  geom_line() +\n  geom_point(aes(color = Sex, shape = Sex), size = 3) +\n  coord_cartesian(ylim = c(0, 3500), expand = TRUE) +\n  labs(x = \"Angel of Rotation (degrees)\", y = \"Mean Reaction Time (ms)\") +\n  facet_wrap(~Sex) +\n  guides(group = FALSE, color = FALSE, shape = FALSE) +\n  theme_bw()## Warning: `guides(<scale> = FALSE)` is deprecated. Please use `guides(<scale> =\n## \"none\")` instead."},{"path":"data-visualisation-through-ggplot2.html","id":"practice-your-skills-3","chapter":"3 Data Visualisation Through ggplot2","heading":"3.5.2 Practice Your Skills","text":"Check work solution tasks : Chapter 3 Practice Skills Solution.Return Task","code":""},{"path":"data-visualisation-through-ggplot2.html","id":"additional-material","chapter":"3 Data Visualisation Through ggplot2","heading":"3.6 Additional Material","text":"additional material might help understand figures bit present reports. Thus, want clarification aes() call want know combine several plots one, read !","code":""},{"path":"data-visualisation-through-ggplot2.html","id":"more-on-aes","chapter":"3 Data Visualisation Through ggplot2","heading":"3.6.1 More on aes()","text":"chapter, added short note using aes() call, see people issues thought quick demonstration might help. code previous activity:\nFigure 3.14: Changing Shape Size Data Points\nSpecifically, going focus geom_point() line. Inside aes() stated color = Sex, shape = Sex outside aes() stated, size = 3. Earlier said, outside aes() means observations take one value color type. Inside means observation within condition takes value color type, different conditions different values/color/type. based understanding, plot, shapes size (.e., 3), different shape color shape sex. Now demonstrate alternatives.points shape, color size - nothing aes().\nneed state color, shape size want observations . chosen red color (quotes) shape style 3 (+) size 6. using variable split observations groups.\nchanged size make visualisation clearer\nneed state color, shape size want observations . chosen red color (quotes) shape style 3 (+) size 6. using variable split observations groups.changed size make visualisation clearer\nFigure 3.15: points shape, color size\npoints shape size, color determined Sex (goes inside aes()).\nneed state shape size want dots . time giving different levels within Sex (.e., male female) different colors - putting inside aes()\nneed state shape size want dots . time giving different levels within Sex (.e., male female) different colors - putting inside aes()\nFigure 3.16: points shape size color determined Sex\nshowed code setting color shape Sex previously. Instead now set color, shape size variable Sex.\noptions aes() different colors, sizes, shapes males females, males color, size shape, females color size shape.\noptions aes() different colors, sizes, shapes males females, males color, size shape, females color size shape.\nFigure 3.17: points shape size color determined Sex\nactually get warning option. ? numerous options many different shapes created cause issues code may even crash . Pay attention warnings.reason decide best approach displaying data observations within condition , showing different colors shapes makes little sense. always need think trying convey. Look two figures think one easier understand observations condition. one left! one right suggests something different observations.\nFigure 3.18: plot left suggests observations condition. figure right suggests difference observations. Always think information convey figures!\nHopefully beginning become clearer. Insider aes() means observations within variable/condition shown , different observations different variable/condition. Outside aes() means observations shown regardless condition.","code":"\nmenrot_angle_sex <- filter(menrot, CorrectResponse == \"Correct\") %>%\n  inner_join(demog, \"Participant\") %>%\n  group_by(Angle, Sex) %>% \n  summarise(mean_Resp = mean(Time))## `summarise()` has grouped output by 'Angle'. You can override using the `.groups` argument.\nggplot(data = menrot_angle_sex, aes(x = Angle, y = mean_Resp, group = Sex)) + \n  geom_point(aes(color = Sex, shape = Sex), size = 3) +\n  geom_line() +\n  coord_cartesian(ylim = c(0, 3500), expand = TRUE) +\n  theme_gray()\nggplot(data = menrot_angle_sex, aes(x = Angle, y = mean_Resp, group = Sex)) + \n  geom_point(color = \"red\", shape = 3, size = 6) +\n  geom_line() +\n  coord_cartesian(ylim = c(0, 3500), expand = TRUE) +\n  theme_bw()\nggplot(data = menrot_angle_sex, aes(x = Angle, y = mean_Resp, group = Sex)) + \n  geom_point(aes(color = Sex), shape = 3, size = 6) +\n  geom_line() +\n  coord_cartesian(ylim = c(0, 3500), expand = TRUE) +\n  theme_bw()\nggplot(data = menrot_angle_sex, aes(x = Angle, y = mean_Resp, group = Sex)) + \n  geom_point(aes(color = Sex, shape = Sex, size = Sex)) +\n  geom_line() +\n  coord_cartesian(ylim = c(0, 3500), expand = TRUE) +\n  theme_bw()## Warning: Using size for a discrete variable is not advised."},{"path":"data-visualisation-through-ggplot2.html","id":"combining-plots-into-one-figure","chapter":"3 Data Visualisation Through ggplot2","heading":"3.6.2 Combining Plots into one Figure","text":"Space within report commodity. Figures can incredibly useful getting information across efficient manner, strict word count, multiple figures can really chew limit, given figure needs legend legend counts. One way get around merge figures together one big figure perhaps convey similar related information. going show using package called patchwork.\npatchwork unlikely lab machines please try machine. previously installed patchwork package machine , install first, e.g. install.packages(\"patchwork\").\nPlots like boxplots histograms, combined, can incredibly useful understanding overall shape data whether fits assumptions inferential tests, something come later. create two separate plots, might get something like :\nFigure 3.19: histogram distribution Mean Time counts Sex\n:\nFigure 3.20: boxplot spreads Mean Time Correct Responses Sex\nNow given divide data sex, can start see figure legend plot becomes bit repetitive, combining one figure potentially make things easier. number packages , patchwork straightforward flexible.now call patchworkThe first thing need using patchwork save plots object (just like output function). Using code , might look like boxplot:histogram:Note: reason inclusion title plot become clear second.Note: run codes plots generated saving objects - boxplot p_box histogram p_hist. important realise distinction someone asks make produce code figure generated code knits, saved plot object, figure might show. save plot object, can generate figure just calling name object. look ggplot cheatsheet see approach lot. call boxplot stored p_box.\nFigure 3.21: boxplot spreads Mean Time Correct Responses Sex\n\nFigure 3.22: histogram distribution Mean Time counts Sex\nNote: see warning histogram plot selecting binwidth. really looked yet due course. wanted \"fix\" warning changing histrogram code something like + geom_histogram(binwidth = 100) might work. value enter relative scale data. binwidth 1 create bin every increase 1 ms. binwidth 100 creates bin every 100 ms.far nothing exciting. Looks just like seen . say wanted plots single figure, right? Well patchwork, simply \"add\" plots together using plus sign (+), :\nFigure 3.23: boxplot (- left) spreads Mean Time Correct Responses, histogram (B - right) distribution Mean Time counts, separated Sex (female - red, male - cyan)\nNote: can use \"titles\"\" added plots original code tell readers plot, within combined figure, referring , B, left right, shown figure legend beneath figure. might seem bit pedantic, control somebody views published figure, clarity paramount!Awesome, ? ! can also change configuration plots combined figure. Say wanted plots top - portrait rather landscape - well instance divide plots using divide sign (/), :\nFigure 3.24: boxplot (- top) spreads Mean Time Correct Responses, histogram (B - bottom) distribution Mean Time counts, separated Sex (female - red, male - cyan)\nnow refer top bottom, rather left right. fact, patchwork really flexible can work multiple plots arrangements. Hypothetically, say three plots wanted two top one, use approach combining \"+\" \"/\" :Remember trick using patchwork save plots objects first (p1 <- ggplot(....)) rest easy. sure always know figure shown knitted ; often , seeing figure important seeing code.Happy Visualising!End Additional Material!","code":"\nmenrot_hist_correct <- group_by(menrot, Participant, CorrectResponse) %>% \n  summarise(Mean_Time = mean(Time, na.rm = TRUE)) %>%\n  filter(CorrectResponse == \"Correct\") %>%\n  inner_join(demog, \"Participant\")\n\nggplot(data = menrot_hist_correct, \n       aes(x = Mean_Time,\n           fill = Sex)) + \n  geom_histogram() +\n  theme_bw()\nmenrot_box_correct <- group_by(menrot, Participant, CorrectResponse) %>% \n  summarise(Mean_Time = mean(Time, na.rm = TRUE)) %>%\n  filter(CorrectResponse == \"Correct\") %>%\n  inner_join(demog, \"Participant\")## `summarise()` has grouped output by 'Participant'. You can override using the `.groups` argument.\nggplot(data = menrot_box_correct, \n       aes(x = CorrectResponse, \n           y = Mean_Time, \n           fill = Sex)) + \n  geom_boxplot() +\n  theme_bw()\nlibrary(patchwork)\np_box <- ggplot(data = menrot_box_correct, \n       aes(x = CorrectResponse, \n           y = Mean_Time, \n           fill = Sex)) + \n  geom_boxplot() +\n  labs(title = \"A\") +\n  theme_bw()\np_hist <- ggplot(data = menrot_hist_correct, \n       aes(x = Mean_Time,\n           fill = Sex)) + \n  geom_histogram() +\n  labs(title = \"B\") +\n  theme_bw()\np_box\np_hist## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\np_box + p_hist## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\np_box / p_hist## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n(plot1 + plot2)/plot3"},{"path":"revisiting-probability-distributions.html","id":"revisiting-probability-distributions","chapter":"4 Revisiting Probability Distributions","heading":"4 Revisiting Probability Distributions","text":"","code":""},{"path":"revisiting-probability-distributions.html","id":"overview-4","chapter":"4 Revisiting Probability Distributions","heading":"4.1 Overview","text":"Probability degree cornerstone Psychological theory based quantitative analysis. establish outcome (e.g., difference two events), establish probability outcome model standard. Probability important quantifying uncertainty conclusions. already heard probability lectures/journal articles/etc., try help gain deeper understanding probability course next chapters use make inference population.start looking general ideas behind probability. using lot Psychology data concepts can easier understand probability first everyday concrete examples. said, whilst reading examples, trying , think might relate Psychology examples sure ask questions.preclass bit read take time try understand fully. Much familiar though PsyTeachR Data Skills book recaps ideas. Also, cheatsheets chapter using specific package. However can make full use R help function (e.g. ?sample) clear function . Also, remember said previously; shy run Google Search finding stats concepts covered . loads videos help pages clear examples explain difficult concepts.chapter :Revise probability concepts discussed PsyTeachR Data Skills bookCalculate probabilitiesCreate probability distributionsMake estimations probability distributions.\npopulation whole group want know something - everyone everything group. sample part population testing. sample always smaller population unlikely ever able test everyone population, sample representative population based random sampling. means even though using whole population, sample using represents whole population randomly sampled people . true, sample representative population, testing sample allows make inference population; infer characteristic population testing sample.\nDiscrete versus Continuous DataLet's recap questions level measurement can alter way tackle probability - .e., whether data discrete continuous.Quickfire QuestionsDiscrete data can take specific/certain/exact values (e.g., groups, integers). example, number participants experiment discrete - half participant! Discrete variables can also broken nominal/categorical ordinal variables.\n\nFill blanks sentences using words: ordinal, nominal/categorical.NominalOrdinal data based set categories natural ordering (e.g., left right handed). example, separate participants according left right handedness course study (e.g., psychology, biology, history, etc.).NominalOrdinal data based set categories natural ordering (e.g., left right handed). example, separate participants according left right handedness course study (e.g., psychology, biology, history, etc.).NominalOrdinal data set categories natural ordering; know top/best worst/lowest, difference categories may constant. example, ask participants rate attractiveness different faces based 5-item Likert scale (unattractive, unattractive, neutral, attractive, attractive).NominalOrdinal data set categories natural ordering; know top/best worst/lowest, difference categories may constant. example, ask participants rate attractiveness different faces based 5-item Likert scale (unattractive, unattractive, neutral, attractive, attractive).Continuous data hand can take value scale measured. example, can measure age continuous scale (e.g., can age 26.55 years), also reaction time distance travel university.Fill blanks sentences using two remaining levels measurement offered :Continuous data can broken   data.read journal articles working data, really good practice take minute two figure type variables reading /working .\nfour level measurements nominal (also called categorical), ordinal, interval, ratio. Discrete data uses categories whole numbers therefore either nominal ordinal data. Continuous data can take value, e.g., 9.00 9.999999999, either interval ratio data.\n","code":""},{"path":"revisiting-probability-distributions.html","id":"discrete-data-and-binomial-distributions","chapter":"4 Revisiting Probability Distributions","heading":"4.2 Discrete Data and Binomial Distributions","text":"","code":""},{"path":"revisiting-probability-distributions.html","id":"general-probability-calculations","chapter":"4 Revisiting Probability Distributions","heading":"4.2.1 General Probability Calculations","text":"Today begin recapping concepts probability calculations lectures PsyTeachR Data Skills book, looking discrete distributions - values categories (e.g., house, face, car) whole numbers (e.g., 1,2, 3 1.1, 1.2 etc).talk probability mean interested likelihood event occurring. probability discrete event occurring can formulated :\\[p = \\frac{number \\   \\ ways \\ \\ event \\ \\  arise}{number \\ \\ possible \\ outcomes}\\]probability event represented number 0 1, letter p. example, probability flipping coin landing 'tails', people say, estimated p = .5, .e. likelihood getting tails \\(p = \\frac {1}{2}\\) one desired outcome (tails) two possibilities (heads tails).example:1. probability drawing ten clubs standard pack cards 1 52: \\(p = \\frac {1}{52} \\ = .019\\). One outcome (ten clubs) 52 possible outcomes (cards)2. Likewise, probability drawing either ten clubs seven diamonds first card draw full deck 2 52: \\(p = \\frac {2}{52} \\ = .038\\). case adding chance event occurring giving two possible outcomes becomes likely happen one outcome.3. Now say two standard packs cards mixed together. probability drawing 10 clubs mixed pack 2 104: \\(p = \\frac{2}{104}= .019\\). Two possible outcomes alternatives , 104 time, meaning less probable Example 2 probability Example 1. key thing remember probability ratio number ways specified outcome can happen number possible outcomes.4. instead say two separate packs cards. probability drawing 10 clubs packs : \\(p = \\frac{1}{52} \\times \\frac{1}{52}= .0004\\). probability gone created event even unlikely happen. called joint probability events.5. probability drawing 10 clubs pack 52, putting back (call replacement), subsequently drawing 7 diamonds? , represented multiplying together probability events happening: \\(p = \\frac{1}{52} \\times \\frac{1}{52}= .0004\\).6. Finally, say draw 10 clubs pack 52 time replace . probability draw 7 diamonds next draw (without replacing ) 3 hearts third draw? time number cards pack fewer second (51 cards) third draws (50 cards) take account multiplication: \\(p = \\frac{1}{52} \\times \\frac{1}{51}\\times \\frac{1}{50}= .000008\\).\n, probability event number possible ways event happen, divided number possible outcomes. combine probabilities two separate events multiple together obtain joint probability.\n\nmay noticed tend write p = .008, example, opposed p = 0.008 (0 decimal place). ? Convention really. probability can never go 1, 0 decimal place pointless. Meaning people write p = .008 instead p = 0.008, indicating max value 1.\n\nallow either version answers chapter still learning, try get habit writing probability without 0 decimal place.\nQuickfire QuestionsWhat probability randomly drawing name hat 12 names one name definitely name? Enter answer 3 decimal places: probability randomly drawing name hat 12 names one name definitely name? Enter answer 3 decimal places: probability randomly drawing name hat 12 names, putting back, drawing name ? Enter answer 3 decimal places: probability randomly drawing name hat 12 names, putting back, drawing name ? Enter answer 3 decimal places: Tricky: stimuli set 120 faces, 10 inverted 110 right way , probability randomly removing one inverted face first trial, replacing , removing another inverted face second trial? Enter answer three decimal places:Tricky: stimuli set 120 faces, 10 inverted 110 right way , probability randomly removing one inverted face first trial, replacing , removing another inverted face second trial? Enter answer three decimal places:\n\n12 possible outcomes looking one possible event.\n\n\n12 possible outcomes looking one possible event.\n\n\ntwo separate scenarios . scenarios 12 possible outcomes looking one possible event. Since two separate scenarios, make less likely draw name twice?\n\n\ntwo separate scenarios . scenarios 12 possible outcomes looking one possible event. Since two separate scenarios, make less likely draw name twice?\n\n\nfirst trial 120 possible outcomes (faces) looking 10 possible events (inverted faces). second trial removed first inverted face stimuli set now 119 trials total 9 inverted faces. Remember need multiply probabilities first trial second trial results together!\n\n\nfirst trial 120 possible outcomes (faces) looking 10 possible events (inverted faces). second trial removed first inverted face stimuli set now 119 trials total 9 inverted faces. Remember need multiply probabilities first trial second trial results together!\n\n\np = .083. One outcome (name) 12 possibilities, .e. \\(p = \\frac{1}{12}\\)\n\n\np = .083. One outcome (name) 12 possibilities, .e. \\(p = \\frac{1}{12}\\)\n\n\np = .007. replace name draws \\(p = \\frac{1}{12}\\) draw. \\(p = \\frac{1}{12} * \\frac{1}{12}\\) rounded three decimal places\n\n\np = .007. replace name draws \\(p = \\frac{1}{12}\\) draw. \\(p = \\frac{1}{12} * \\frac{1}{12}\\) rounded three decimal places\n\n\np = .006. first trial 10 120, remove one inverted face second trial 9 119. formula \\(p = \\frac{10}{120} * \\frac{9}{119}\\)\n\n\np = .006. first trial 10 120, remove one inverted face second trial 9 119. formula \\(p = \\frac{10}{120} * \\frac{9}{119}\\)\n","code":"* To find the joint probability of two separate events occuring you multiply together the probabilities of the two individual separate events (often stated as independent, mutually exclusive events). * The second event (drawing the 7 of diamonds) has the same probability as the first event (drawing the 10 of clubs) because we put the original card back in the pack, keeping the number of all possible outcomes at 52. This is **replacement**."},{"path":"revisiting-probability-distributions.html","id":"creating-a-simple-probability-distribution","chapter":"4 Revisiting Probability Distributions","heading":"4.2.2 Creating a Simple Probability Distribution","text":"now recap plotting probability distributions looking simulated coin toss. may remember PsyTeachR Data SKills book worry going work . Work read example apply logic quickfire questions end section.Scenario: Imagine want know probability X number heads 10 coin flips - example, probability flipping coin 10 times coming heads two times.simulate 10 coin flips use sample() function randomly sample (replacement) possible events: .e. either heads tails.begin:Open new script copy code lines .\nfirst line code loads library normal.\nsecond line code provides instruction sample options \"Heads\" \"Tails\", ten times, replacement set TRUE.\nfirst line code loads library normal.second line code provides instruction sample options \"Heads\" \"Tails\", ten times, replacement set TRUE.Note: event labels strings (text), enter function vector; .e. \"quotes\"Note: lines code, see output got ran code. worry sequence heads tails different output; expected generating random sample.Note: want get output , add line code script prior loading library. set.seed() function can put number time run randomisation get number.\nSampling simply choosing selecting something - randomly choosing one possible options; heads tails. examples 'sampling' include randomly selecting participants, randomly choosing stimuli present given trial, randomly assigning participants condition e.g.drug placebo...etc.\n\nReplacement putting sampled option back 'pot' possible options. example, first turn randomly sample HEADS options HEADS TAILS replacement, meaning next turn two options ; HEADS TAILS. Sampling without replacement means remove option subsequent turns. say first turn randomly sample HEADS options HEADS TAILS without replacement. Now second turn option TAILS 'randomly' sample . third turn without replacement options.\n\nreplacement means putting option back next turn turn possible outcome options.\n\nwant use sampling replacement coin toss scenario? sure set replacement FALSE (change last argument TRUE FALSE) run code . code stop working 2 coin flips. want sample replacement want options available sampling - run options quickly since 10 flips.far code returns outcomes 10 flips; either heads tails. want count many 'heads' can simply sum heads. However, heads number, make life easier can re-label events (.e. flips) 0 tails 1 heads. Now run code can pipe sample sum() function total 1s (heads) 10 flips.Run line code number times, notice output?Note: event labels now numeric, need vector.Note: 0:1 means numbers 0 1 increments 1. basically, 0 1.ouptut line changes every time run code randomly sampling 10 coin flips time. clear, get answer 6 example, means 6 heads, turn, 4 tails. running code basically demonstrating sampling distribution created.\nsampling distribution shows probability drawing sample certain characteristics population; e.g. probability 5 heads 10 flips, probability 4 heads 10 flips, probability X heads 10 flips coin.\n\nNow order create full accurate sampling distribution scenario need replicate 10 flips large number times - .e. replications. replications reliable estimates. 10000 replications 10 coin flips. means flip coin 10 times, count many heads, save number, repeat 10000 times. slow way demonstrated , just running line noting outcome time. use replicate() function.Copy line code script run .exactly said saving 10000 outputs (counts heads) dataframe called heads10k (k shorthand thousand).reiterate, sum heads (.e., number times got heads) 10000 replications now stored vector heads10k. look heads10k, shown box , series 10000 numbers 0 10 indicating number heads, specifically 1s, got set 10 flips.Now, order complete distribution need :Convert vector (list numbers heads counts) data frame (tibble) can work . numbers stored column called heads.group results number possible heads; .e. group times got 5 heads together, times got 4 heads together, etc.Finally, work probability heads result, (e.g., probability 5 heads), totaling number observations possible result (e.g., 5 heads) submitting probability formula (number outcomes event divided possible outcomes)\nnumber times got specific number heads (e.g., 5 heads) divided total number outcomes (.e., number replications - 10000).\nnumber times got specific number heads (e.g., 5 heads) divided total number outcomes (.e., number replications - 10000).can carry steps using following code:Copy code script run .now discrete probability distribution number heads 10 coin flips. Use View() function look data10k variable. now see heads outcome, total number occurrences 10000 replications (n) plus probability outcome (p).Table 4.1: sampling distribution number heads 10 flips coin. p = probability obtaining number heads 10000 replications 10 flips coinIt useful visualize distribution:\nFigure 4.1: Probability Distribution Number Heads 10 Flips\nanalysis, probability getting 5 heads 10 flips 0.2401. remember, surprised get slightly different value. Ten thousand replications lot huge amount compared infinity. run analysis replications numbers become stable, e.g. 100K.Note possible number heads 10 flips related one another, summing probabilities different number heads give total 1. different looked earlier cards events unrelated . , can use information start asking questions probability obtaining 2 less Heads 10 flips? Well, probability getting heads (10 flips) distribution 0.0007, probability getting 1 head 0.0082, probability getting 2 heads 0.0465, probability 2 less Heads distribution simply sum values: 0.0554. Pretty unlikely !Quickfire QuestionsLook probability values corresponding number coin flips created data10k sample distribution (use View() see ):Choose following options, wanted calculate probability getting 4, 5 6 heads 10 coin flips : multiply individual probabilities togethersum individual probabilities togetherChoose following options, wanted calculate probability getting 4, 5 6 heads 10 coin flips : multiply individual probabilities togethersum individual probabilities togetherChoose following options, wanted calculate probability getting 6 heads 10 coin flips : multiply individual probabilities togethersum individual probabilities togetherChoose following options, wanted calculate probability getting 6 heads 10 coin flips : multiply individual probabilities togethersum individual probabilities togetherChoose following options, distribution created : continuousdiscreteChoose following options, distribution created : continuousdiscrete\nthink , get 5.5 heads 2.3 heads, can get whole numbers, 2 heads 5 heads. means data distribution discrete. (confused one functions saying continuous)\n\nfind probability getting say 4, 5, 6 heads 10 coin flips, combining related scenarios together, therefore need find individual probabilities getting 4, 5 6 heads 10 coin flips, sum probabilities together get appropriate probability obtaining 4, 5 6 heads. 6 heads, just sum probabilities 6, 7, 8, 9 10 heads get probability 6 heads.\n\nsure summing multiplying probabilities? good way remember, coin flip examples pack cards examples earlier, scenarios related summing probabilities, scenarios separate multiplying probabilities. Related scenarios usually asking probability 'either / ' scenarios occuring, whereas separate scenarios usually ask probability one scenario '' another scenario occuring.\n\nsample distribution data10k already completed first part calculation (finding individual probabilities n heads 10 coin flips), need sum required probabilities together!\n","code":"\nlibrary(\"tidyverse\")\nsample(c(\"HEADS\", \"TAILS\"), 10, TRUE) ##  [1] \"TAILS\" \"HEADS\" \"TAILS\" \"HEADS\" \"TAILS\" \"TAILS\" \"TAILS\" \"HEADS\" \"HEADS\"\n## [10] \"TAILS\"\nset.seed(1409)\nsample(0:1, 10, TRUE) %>% sum() ## [1] 5\nheads10k <- replicate(10000, sample(0:1, 10, TRUE) %>% sum())   ##  int [1:10000] 7 4 5 6 2 6 2 6 8 5 ...\ndata10k <- tibble(heads = heads10k) %>%       # creating a tibble/data frame\n                group_by(heads) %>%           # group by number of possibilities\n                summarise(n = n(), p=n/10000) # count occurences of possibility,\n                                              # & calculate probability (p) of\n                                              # each\nggplot(data10k, aes(heads,p)) + \n  geom_col(fill = \"skyblue\") + \n  labs(x = \"Number of Heads\", y = \"Probability of Heads in 10 flips (p)\") +\n  theme_bw() +\n  scale_x_discrete(limits=0:10)## Warning: Continuous limits supplied to discrete scale.\n## Did you mean `limits = factor(...)` or `scale_*_continuous()`?"},{"path":"revisiting-probability-distributions.html","id":"the-binomial-distribution---creating-a-discrete-distribution","chapter":"4 Revisiting Probability Distributions","heading":"4.2.3 The Binomial Distribution - Creating a Discrete Distribution","text":"Great, now learning probabilities distributions work. However, wanted calculate probability 8 heads 10 coin flips, go entire procedure time. Instead, dichotomous outcome, \"heads tails\", can establish probabilities using binomial distribution - effectively just created. can look R help page binomial distribution (type ?dbinom directly console) understand use walk essentials .use 3 functions work binomial distribution ask questions asked :dbinom() - density function. function gives probability x successes (e.g., heads) given size (e.g., number trials) probability success prob single trial (0.5, assume flipping fair coin - Heads Tails)dbinom() - density function. function gives probability x successes (e.g., heads) given size (e.g., number trials) probability success prob single trial (0.5, assume flipping fair coin - Heads Tails)pbinom() - cumulative probability function. function gives probability getting number successes certain cut-point given size prob. questions probability 5 heads less example. sums probability 0, 1, 2, 3, 4, 5 heads.pbinom() - cumulative probability function. function gives probability getting number successes certain cut-point given size prob. questions probability 5 heads less example. sums probability 0, 1, 2, 3, 4, 5 heads.qbinom() - quantile function. function inverse pbinom gives x-axis value (including value) summation probabilities greater equal given probability p, given size prob. words, many heads need probability p = 0.0554qbinom() - quantile function. function inverse pbinom gives x-axis value (including value) summation probabilities greater equal given probability p, given size prob. words, many heads need probability p = 0.0554Let's look functions turn little. thing keep mind probability every event likelihood occurring distribution. trying look numbers come mean us.","code":""},{"path":"revisiting-probability-distributions.html","id":"dbinom---the-density-function","chapter":"4 Revisiting Probability Distributions","heading":"4.2.4 dbinom() - The Density Function","text":"Using dbinom() function can create probabilities possible outcomes two possibilities outcome trial - e.g., heads tails, cats dogs, black red. going stick coin flip idea. showing code obtaining 3 heads 10 flips:possible outcomes heads (0:10) 10 flips:plot probability possible outcomes 10 flips look like :\nFigure 4.2: Probability Distribution Number Heads 10 Flips\ndbinom (density binom) function takes format dbinom(x, size, prob), arguments give :x number 'heads' want know probability . Either single one, 3 series 0:10.size number trials (flips) ; case, 10 flips.prob probability 'heads' one trial. chance 50-50 probability state 0.5 .5Now say wanted know probability 6 heads 10 flips. change first argument code used 3 heads, :probability 6 heads, using dbinom() p = 0.2050781. compare value data10k value 6 see similar quite . dbinom() uses lot replications 10000 used simulation.terms visualising just calculated, p = 0.2050781 height green bar plot .\nFigure 4.3: Probability Distribution Number Heads 10 Flips probability 6 10 Heads highlighted green\nQuickfire QuestionsTo three decimal places, probability 2 heads 10 flips? \nwant know probability 2 heads 10 flips.\n\nX therefore 2;\n\nSize therefore 10;\n\nprobability outcomes trial stays .5.\n\ndbinom(2, 10, 0.5) = .04394531 rounded = .044\n","code":"\ndbinom(3, 10, 0.5)\ndbinom(0:10, 10, 0.5)\ndbinom(6, 10, 0.5)## [1] 0.2050781"},{"path":"revisiting-probability-distributions.html","id":"pbinom---the-cumulative-probability-function","chapter":"4 Revisiting Probability Distributions","heading":"4.2.5 pbinom() - The Cumulative Probability Function","text":"wanted know probability including 3 heads 10 flips? asked similar questions . can either use dbinom outcome 3 heads sum results:can use pbinom() function; known cumulative probability distribution function cumulative density function. first argument give cut-value including value want know probability (3 heads). , , tell many flips want probability heads single trial.Copy line script run :probability including 3 heads 10 flips 0.172. visualization, done calculated cumulative probability lower tail distribution (lower.tail = TRUE; shown green ) cut-3:\nFigure 4.4: Probability Distribution Number Heads 10 Flips probability 0 3 Heads highlighted green - lower.tail = TRUE\npbinom function gives us cumulative probability outcomes including cut-. wanted know probability outcomes including certain value? Say want know probability 7 heads 10 coin flips. code :explain code little.First, switch lower.tail call TRUE FALSE tell pbinom() want lower tail distribution time (left including cut-), want upper tail, right cut-. results cumulative probability upper tail distribution cut-value (shown green ).Next specify cut-instead stating 7 might expect, even though want 7 , specify cut-6 heads. ? set cut-'6' working discrete distribution, lower.tail = TRUE includes cut-(6 ) whereas lower.tail = FALSE everything cut-including cut-(7 ).short, want upper tail using discrete distribution set cut-value (x) one lower number interested . wanted know 7 heads set cut-6.\nFigure 4.5: Probability Distribution Number Heads 10 Flips probability 7 Heads highlighted green - lower.tail = FALSE\n\nconfusing part people find concept lower.tail. look distribution, say binomial, find lot high bars middle distribution smaller bars far left right distribution. Well far left right distribution called tail distribution - tend extremity distribution taper like .....well like tail. lot time talk left right tails pbinom() function ever considers data relation left side distribution - calls lower.tail.\n\nconsider lower.tail = TRUE. default, state lower.tail = ... considered want. lower.tail = TRUE means values left value including value state. binomial distribution say give probability 5 heads less, set lower.tail = TRUE counting summing probability 0, 1, 2, 3, 4 5 heads. can check dbinom(0:5, 10, .5) %>% sum().\n\nHowever, say give probability 7 heads, need lower.tail = FALSE, consider right-hand side tail, also, need set code pbinom(6, 10, .5, lower.tail = FALSE). 6 7? pbinom() function, lower.tail = FALSE, starts value plus one value state; always considers value state part lower.tail say 6, includes 6 lower.tail gives 7, 8, 9 10 upper tail. said 7 lower.tail = FALSE, give 8, 9 10. tricky worth keeping mind using pbinom() function. remember, can always check using dbinom(7:10, 10, .5) %>% sum() seeing whether matches pbinom(6, 10, 0.5, lower.tail=FALSE) pbinom(7, 10, 0.5, lower.tail=FALSE)\nQuickfire QuestionsUsing format shown pbinom() function, enter code determine probability including 5 heads 20 flips, assuming probability 0.5: Using format shown pbinom() function, enter code determine probability including 5 heads 20 flips, assuming probability 0.5: two decimal places, probability obtaining including 50 heads 100 flips? two decimal places, probability obtaining including 50 heads 100 flips? \n\nlooking calcuate probability 5 less heads (x) 20 flips (size), probability 'heads' one trial (prob) remaining . need lower.tail call calculating cumulative probability lower tail distribution?\n\n\nlooking calcuate probability 5 less heads (x) 20 flips (size), probability 'heads' one trial (prob) remaining . need lower.tail call calculating cumulative probability lower tail distribution?\n\n\nlooking calculate probability 51 heads (x), 100 flips (size), probability 'heads' one trial (prob) remaining (0.5). need lower.tail call calculating cumulative probability upper tail distribution? Remember, looking lower.tail, value heads enter pbinom() included final calculation, e.g. entering pbinom(3, 100, lower.tail = FALSE) give probability 4 heads. instead looking lower.tail, entering pbinom(3, 100, lower.tail = TRUE) give probability 3 heads.\n\n\nlooking calculate probability 51 heads (x), 100 flips (size), probability 'heads' one trial (prob) remaining (0.5). need lower.tail call calculating cumulative probability upper tail distribution? Remember, looking lower.tail, value heads enter pbinom() included final calculation, e.g. entering pbinom(3, 100, lower.tail = FALSE) give probability 4 heads. instead looking lower.tail, entering pbinom(3, 100, lower.tail = TRUE) give probability 3 heads.\n\n\ncode first one : pbinom(5, 20, 0.5) pbinom(5, 20, 0.5, lower.tail = TRUE)\n\n\ncode first one : pbinom(5, 20, 0.5) pbinom(5, 20, 0.5, lower.tail = TRUE)\n\n\ncode second one : pbinom(50, 100, 0.5, lower.tail = FALSE), giving answer .46. Remember can confirm : dbinom(51:100, 100, 0.5) %>% sum()\n\n\ncode second one : pbinom(50, 100, 0.5, lower.tail = FALSE), giving answer .46. Remember can confirm : dbinom(51:100, 100, 0.5) %>% sum()\n","code":"\ndbinom(0:3, 10, 0.5) %>% sum()## [1] 0.171875\npbinom(3, 10, 0.5, lower.tail = TRUE)  ## [1] 0.171875\npbinom(6, 10, 0.5, lower.tail = FALSE) ## [1] 0.171875"},{"path":"revisiting-probability-distributions.html","id":"qbinom---the-quantile-function","chapter":"4 Revisiting Probability Distributions","heading":"4.2.6 qbinom() - The Quantile Function","text":"qbinom() function inverse pbinom() function. Whereas pbinom() supply outcome value x get tail probability, qbinom() supply tail probability get outcome value (approximately) cuts tail probability. Think rephrase questions pbinom() ask qbinom() question. Worth noting though qbinom() approximate discrete distribution \"jumps\" probability discrete outcomes (.e. can probability 2 heads 3 heads 2.5 heads).see two functions inverses one another. code probability 49 heads less 100 coin flipsThis tells us probability p = 0.4602054. now put probability (stored p1) qbinom get back started. E.g.can stated number heads required obtain probability 0.4602054 0.4602054. qbinom() function useful want know minimum number successes (heads) needed achieve particular probability. time cut-specify number heads want probability want.example say want know minimum number heads 10 flips result 5% heads success rate (probability .05), use following code.dealing lower tail, telling us lower tail probability .05, expect 2 heads 10 flips. However, important note discrete distribution, value exact. can see :exactly p = .05 close. data working discrete distribution qbinom() gives us closest category boundary.\nfound lot students asking qbinom() works inputting two different probabilities arguments qbinom(). Let us try make things clearer.\n\nFirst, useful remember inverse pbinom(): pbinom() gives tail probability associated x, qbinom() gives closest x cuts specified tail probability. understand pbinom() try reversing question see helps understand qbinom().\n\nqbinom() function set qbinom(p, size, prob). First , used prob previous two functions, dbinom() pbinom(), represents probability success single trial (probability 'heads' one coin flip, prob = .5). Now, prob represents probability success one trial, whereas p represents tail probability want know . function gives value x yield probability asked . give qbinom() tail probability p = .05, 10 flips, probability success one flip prob = .5. tells answer 2, meaning getting 2 flips 10 trials probability roughly .05.\n\nqbinom() also uses lower.tail argument works similar fashion pbinom().\nQuickfire QuestionsType box, maximum number heads associated tail probability 10% (.1) 17 flips: \nanswer 6 code :\n\nqbinom(0.1, 17, 0.5, lower.tail = TRUE)\n\nRemember want overall probability 10% (p = .1), 17 flips go (size = 17), probability heads one flip .5 (prob = .5). want maximum number lower tail, lower.tail TRUE.\nKeep mind: trying get understanding every value distribution probability existing distribution. probability may large, meaning , bell-shaped distributions looked , value middle distribution, probability might rather low, meaning tail, ultimately every value distribution probability.","code":"\np1 <- pbinom(49, 100, .5, lower.tail = TRUE)\np1## [1] 0.4602054\nqbinom(p1, 100, .5, lower.tail = TRUE)## [1] 49\nqbinom(.05, 10, 0.5, lower.tail = TRUE) ## [1] 2\npbinom(2, 10, .5, lower.tail = TRUE) ## [1] 0.0546875"},{"path":"revisiting-probability-distributions.html","id":"continuous-data-and-normal-distribution","chapter":"4 Revisiting Probability Distributions","heading":"4.3 Continuous Data and Normal Distribution","text":"","code":""},{"path":"revisiting-probability-distributions.html","id":"continuous-data-properties","chapter":"4 Revisiting Probability Distributions","heading":"4.3.1 Continuous Data Properties","text":"previous section, seen can use distribution estimate probabilities determine cut-values (play important part hypothesis testing later chapters), looked discrete binomial distribution. Many variables encounter continuous tend show normal distribution (e.g., height, weight, IQ).say interested height population psychology students, estimate 146cm 194cm. plotted continuous, normal distribution, look like:\nFigure 4.6: Normal Distribution height Psychology students (black line). Green line represents mean. Blue line represent 1 Standard Deviation mean. Yellow line represents 2 Standard Deviation mean. Red line represents 3 Standard Deviation mean.\nfigure shows hypothetical probability density heights ranging 146cm 194cm population Psychology students (black curve). data normally distributed following properties:Properties Normal distribution1. distribution defined mean standard deviation: mean (\\(\\mu\\)) describes center, therefore peak density, distribution. largest number people population terms height. standard deviation (\\(\\sigma\\)) describes much variation mean distribution - figure, standard deviation distance mean inflection point curve (part curve changes upside-bowl shape right-side-bowl shape).2. Distribution symmetrical around mean: mean lies middle distribution divides area curve two equal sections - get typical bell-shaped curve.3. Total area curve equal 1: add probabilities (densities) every possible height, end value 1.4. mean, median mode equal: good way check given dataset normally distributed calculate measure central tendency see approximately (normal distribution) (skewed distribution).5. curve approaches, never touches, x axis: never probability 0 given x axis value.6. normal distribution follows Empirical Rule: Empirical Rule states 99.7% data within normal distribution falls within three standard deviations (\\(\\pm3\\sigma\\)) mean, 95% falls within two standard deviations (\\(\\pm2\\sigma\\)), 68% falls within one standard deviation (\\(\\pm\\sigma\\)).Continuous data can take precise specific value scale, e.g. 1.1, 1.2, 1.11, 1.111, 1.11111. Many variables encounter Psychology :continuous opposed discrete.tend show normal distribution.look similar - bell-shaped curve - plotted.","code":""},{"path":"revisiting-probability-distributions.html","id":"estimating-from-the-normal-distribution","chapter":"4 Revisiting Probability Distributions","heading":"4.3.2 Estimating from the Normal Distribution","text":"Unlike coin flips, outcome normal distribution just 50/50 ask create normal distribution complicated binomial distribution estimated previous section. Instead, just binomial distribution (distributions) functions allow us estimate normal distribution ask questions distribution. :dnorm() - Density function normal distributionpnorm() - Cumulative Probability function normal distributionqnorm() - Quantile function normal distributionYou might thinking look familiar. fact work similar way binomial counterparts. unsure function works remember can call help typing console, example, ?dnorm ?dnorm().\nQuickfire QuestionsType box binomial counterpart dnorm()? Type box binomial counterpart dnorm()? Type box binomial counterpart pnorm()? Type box binomial counterpart pnorm()? Type box binomial counterpart qnorm()? Type box binomial counterpart qnorm()? \ncounterpart functions start letter, d, p, q, just distribution name changes, binom, norm, t - though quite come across t-distribution yet.\n\n\ndbinom() binomial equivalent dnorm()\n\n\ndbinom() binomial equivalent dnorm()\n\n\npbinom() binomial equivalent pnorm()\n\n\npbinom() binomial equivalent pnorm()\n\n\nqbinom() binomial equivalent qnorm()\n\n\nqbinom() binomial equivalent qnorm()\n\nalso rnorm() rbinom() look another time.\n","code":""},{"path":"revisiting-probability-distributions.html","id":"dnorm---the-density-function","chapter":"4 Revisiting Probability Distributions","heading":"4.3.3 dnorm() - The Density Function","text":"Using dnorm(), like dbinom, can plot normal distribution. time however need:x, vector quantiles (words, series values x-axis - think max min distribution want plot)mean dataand standard deviation sd data.use IQ example. actually disagreement whether IQ continuous data degree depend measurement use. IQ however definitely normally distributed assume continuous purposes demonstration. Many Psychologists interested studying IQ, perhaps terms heritability, interested controlling IQ studies rule effect (e.g., clinical autism studies).","code":""},{"path":"revisiting-probability-distributions.html","id":"Ch4InClassQueT1","chapter":"4 Revisiting Probability Distributions","heading":"4.3.3.1 Task 1: Standard Deviations and IQ Score Distribution","text":"Copy code new script run . Remember need call tidyverse library first.code creates plot showing normal distribution IQ scores (M = 100, SD = 15) ranging 40 160. values considered typical general population.First set range IQ values 40 160Then plot distribution IQ_data, M = 100 SD = 15\nFigure 4.7: Distribution IQ scores mean = 100, sd = 15\npart code need change alter SD plot? mean = 100sd = 15(40, 160)Now copy edit code plot distribution mean = 100 sd = 10, visually compare two plots.\nThinking Cap PointWhat changing standard deviation (sd) shape distribution? Spend minutes changing code various values running , discussing group answer following questions:happens shape distribution change sd 10 20? distribution gets narrowerthe distribution gets widerWhat happens shape distribution change sd 10 20? distribution gets narrowerthe distribution gets widerWhat happens shape distribution change sd 10 5? distribution gets narrowerthe distribution gets widerWhat happens shape distribution change sd 10 5? distribution gets narrowerthe distribution gets widerWhat small large standard deviation sample tell data collected?small large standard deviation sample tell data collected?\nChanging SD 10 20 means larger standard deviation wider distribution.\n\nChanging SD 10 5 means smaller standard deviation narrower distribution.\n\nSmaller SD results narrower distribution meaning data less spread ; larger SD results wider distribution meaning data spread .\n\nnote Standard Deviation:\n\nknow lectures can estimate data two ways: point-estimates spread estimates. mean point-estimate condenses data one data point - tells average value data tells nothing spread data . standard deviation however spread estimate gives estimate spread data mean - measure standard deviation mean.\n\nimagine looking IQ scores test 100 people get mean 100 SD 5. means vast majority sample IQ around 100 - probably fall within 1 SD mean, meaning participants IQ 95 105.\n\nNow test find mean 100 SD 20, means data much spread . take 1 SD approach participants IQ 80 120.\n\none sample tight range IQs sample wide range IQs. , point-estimate spread estimate data can tell shape sample distribution.\n\nfar good! example told dnorm() values limit range rest; said give us range 40 160 IQ scores. However, plot another way telling dnorm() sequence, range, values want much precision want .","code":"\nIQ_data <- tibble(IQ_range = c(40, 160))\n\nggplot(IQ_data, aes(IQ_range)) + \n  stat_function(fun = dnorm, args = list(mean = 100, sd = 15)) +\n  labs(x = \"IQ Score\", y = \"probability\") +\n  theme_classic()"},{"path":"revisiting-probability-distributions.html","id":"Ch4InClassQueT2","chapter":"4 Revisiting Probability Distributions","heading":"4.3.3.2 Task 2: Changing Range and Step Size of The Normal Distribution","text":"Copy code script run .\nplot standard Normal Distribution -4 4 steps 0.01. also stated mean 0 sd 1.\nFigure 4.8: Normal Distribution Mean = 0 SD = 1\nQuickfire QuestionsFill box show type create tibble containing column called ND_range values ranging -10 10 steps .05:ND_data <- Now know change, try plotting normal distribution following attributes:range -10 10 steps 0.05,range -10 10 steps 0.05,mean 0,mean 0,standard deviation 1.standard deviation 1.Compare new plot original one created. change distribution? Distribution widensNo change distributionDistribution narrowsCompare new plot original one created. change distribution? Distribution widensNo change distributionDistribution narrows\nchange distribution write: ND_data <- tibble(ND_range = seq(-10, 10, 0.05))\n\nHowever, comparing plots, whilst plot may look thinner, distribution changed. change appearance due range sd values extended -4 4 -10 10. density values within values changed however see, clearly second plot, values beyond -3 3 unlikely.\nRemember, every value probability distribution able use dnorm() function get visual representation probability values change normal distribution. values probable. values less probable. key concept comes thinking significant differences later.However, know, one important difference continuous discrete probability distributions - number possible outcomes. discrete probability distributions usually finite number outcomes take probability. instance, 5 coin flips, 5 possible outcomes number heads: 0, 1, 2, 3, 4, 5. binomial distribution exact finite outcomes, can use dbinom() get exact probability outcome.contrast, truly continuous variable, number possible outcomes infinite, 0.01 also .0000001 .00000000001 arbitrary levels precision. rather asking probability single value, ask probability range values, equal area curve (black line plots ) range values., leave dnorm() now move onto looking establishing probability range values using Cumulative Probability function","code":"\nND_data <- tibble(ND_range = seq(-4, 4, 0.01))\nggplot(ND_data, aes(ND_range)) + \n  stat_function(fun = dnorm, args = list(mean = 0, sd = 1)) +\n  labs(x = \"SD units\", y = \"probability\", title = \"The Normal Distribution\") +\n  theme_classic()"},{"path":"revisiting-probability-distributions.html","id":"pnorm---the-cumulative-probability-function","chapter":"4 Revisiting Probability Distributions","heading":"4.3.4 pnorm() - The Cumulative Probability Function","text":"Just dnorm() works like dbinom(), pnorm() works just like pbinom(). , pnorm(), given mean sd data, returns cumulative density function (cumulative probability) given probability (p) lies specified cut-point , unless course lower.tail = FALSE specified case cut-point .OK, English people can understand, means pnorm() function tells probability obtaining given value lower set lower.tail = TRUE. Contrastingly, pnorm() function tells probability obtaining given value higher set lower.tail = FALSE.use height give concrete example. Say test sample students (M = 170cm, SD = 7) want calculate probability given student 150cm shorter following:Remember, lower.tail = TRUE means lower including value XTRUE default actually need declare itThis tells us finding probability someone 150cm shorter class p = 0.0021374. Stated differently, expect proportion students 150cm shorter 0.21% (can convert probability proportion multiplying probability 100). small probability suggests pretty unlikely find someone shorter 150cm class. mainly small standard deviation distribution . Think back said earlier narrow standard deviations round mean!Another example might , probability given student 195 cm taller? , set following code:tells us finding probability someone 150cm shorter class p = 0.9998225. 99.98%. , really unlikely.notice something different cut-example using dbinom() function looking cut-? might ? discuss second first quick task.","code":"\npnorm(150, 170, 7, lower.tail = TRUE)\npnorm(195, 170, 7, lower.tail = FALSE)"},{"path":"revisiting-probability-distributions.html","id":"Ch4InClassQueT3","chapter":"4 Revisiting Probability Distributions","heading":"4.3.4.1 Task 3: Calculating Cumulative Probability of Height","text":"Edit pnorm() code calculate probability given student 190cm taller.three decimal places, Task 3, probability student 190cm taller class? \nanswer .002. See solution code end chapter.\n\nkey thing difference need specify cut-point pbinom() (discussed preclass activity) pnorm() functions values x, .e. lower.tail = FALSE.\n\ndiscrete data, say number coin flips result heads, wanted calculate probability x, apply pbinom() specify cut-point x-1 include x calculation. example, calculate probability 4 'heads' occuring 10 coin flips, specify pbinom(3, 10, 0.5, lower.tail = FALSE) lower.tail includes value state.\n\ncontinuous data, however, height, applying pnorm() therefore can specify cut-point simply x. example, cut-point 190, mean 170 standard deviation 7, can write pnorm(190, 170, 7, lower.tail = FALSE). way think setting x 189 continuous scale, want values greater 190, also include possible values 189 190. Setting x 190 starts 190.0000000...001.\n\ntricky difference pbinom() pnorm() recall easily, best include explanation point portfolio help carry correct analyses future!\n","code":""},{"path":"revisiting-probability-distributions.html","id":"Ch4InClassQueT4","chapter":"4 Revisiting Probability Distributions","heading":"4.3.4.2 Task 4: Using Figures to Calculate Cumulative Probability","text":"look distribution :\nFigure 4.9: Normal Distribution Height probability people 185cm highlighted purple, mean = 170cm SD = 7\nUsing information figure, mean SD , calculate probability associated shaded area.\nalready mean standard deviations input pnorm(), look shaded area obtain cut-point. lower.tail call set according shaded area?\nQuickfire QuestionTo three decimal places, cumulative probability shaded area Task 4? \nanswer p = .016. See solution code end chapter correct code.\n\nRemember, lower.tail set FALSE want area right.\npnorm() great telling us probability obtaining specific value greater distribution, given mean standard deviation distribution. significance come clearer coming chapters key point mind progress understanding analyses. leave now look last function normal distribution.","code":""},{"path":"revisiting-probability-distributions.html","id":"qnorm---the-quantile-function","chapter":"4 Revisiting Probability Distributions","heading":"4.3.5 qnorm() - The Quantile Function","text":"Using qnorm() can inverse pnorm(), instead finding cumulative probability given set values (cut-value), can find cut-value given desired probability. example, can use qnorm() function ask maximum IQ person bottom 10% IQ distribution (M = 100 & SD = 15)?Note: first need convert 10% probability dividing 10010% = 10 / 100 = 0.1.anyone IQ 80.8 lower bottom 10% distribution. rephrase , person bottom 10% distribution max IQ value 80.8.recap, calculated inverse cumulative density function (inverse cumulative probability) lower tail distribution, cut-probability 0.1 (10%), illustrated purple :\nFigure 4.10: Normal Distribution Height bottom 10% heights highlighted purple\n, English people can understand, means qnorm() function tells maximum value person can maintain given probability set lower.tail = TRUE. Contrastingly, pnorm() function tells minimum value person can maintain given probability set lower.tail = FALSE.","code":"\nqnorm(0.1, 100, 15) "},{"path":"revisiting-probability-distributions.html","id":"Ch4InClassQueT5","chapter":"4 Revisiting Probability Distributions","heading":"4.3.5.1 Task 5: Using pnorm() and qnorm() to find probability and cut-off values","text":"Calculate lowest IQ score student must top 5% distribution.Calculate lowest IQ score student must top 5% distribution.challenging: Using appropriate normal distribution function, calculate probability given student IQ 105 110, normal distribution mean = 100, sd = 15.challenging: Using appropriate normal distribution function, calculate probability given student IQ 105 110, normal distribution mean = 100, sd = 15.\nPart 1: Remember include lower.tail call required! unsure, visualise trying find (.e. lowest IQ score can top 5%) sketching normal distribution curve. may help reverse question sound like previous example.\n\nPart 2: second part, function, necessarily qnorm(), gives one value, looking separate calculation IQ. combine two values, summing subtracting ? less likely students IQ falls range cut-? try sketching trying achieve.\nQuickfire QuestionsTo one decimal place, enter answer Task 5 part 1: lowest IQ score student must top 5% distribution? one decimal place, enter answer Task 5 part 1: lowest IQ score student must top 5% distribution? two decimal places, enter answer Task 5 part 2: probability student IQ 105 110, normal distribution mean = 100, sd = 15? two decimal places, enter answer Task 5 part 2: probability student IQ 105 110, normal distribution mean = 100, sd = 15? \n\nquestion can rephrased value give 95% distribution - answer 124.7. See solution code Task 5 Question 1 end chapter.\n\n\nquestion can rephrased value give 95% distribution - answer 124.7. See solution code Task 5 Question 1 end chapter.\n\n\nuse pnorm() establish probability IQ 110. use pnorm() establish probability IQ 105. answer difference two probabilities p = .12. See solution code Task 5 Question 2 end chapter.\n\n\nuse pnorm() establish probability IQ 110. use pnorm() establish probability IQ 105. answer difference two probabilities p = .12. See solution code Task 5 Question 2 end chapter.\n","code":""},{"path":"revisiting-probability-distributions.html","id":"practice-your-skills-4","chapter":"4 Revisiting Probability Distributions","heading":"4.4 Practice Your Skills","text":"order complete exercise, first download assignment .Rmd file need edit - titled GUID_Ch4_PracticeSkills_Probabilities.Rmd. can downloaded within zip file link . downloaded unzipped create new folder use working directory; put .Rmd file folder set working directory folder drop-menus top. Download Assignment .zip file .Now open assignment .Rmd file within RStudio. see code chunk 10 tasks. Follow instructions edit code chunk. often entering code single value based skills learnt current chapter well previous chapters.","code":""},{"path":"revisiting-probability-distributions.html","id":"topic-probabilities","chapter":"4 Revisiting Probability Distributions","heading":"4.4.1 Topic: Probabilities","text":"recapped expanded understanding probability, including number binom norm functions well basic ideas probability. need skills complete following exercises.starting, checkThe .Rmd file saved folder computer access manually set folder working directory. assessments ask save format GUID_Ch4_PracticeSkills_Probabilities.Rmd GUID replaced GUID. Though practice exercise may good practice .Note: complete code chunks replacing NULL (except library chunk appropriate code just entered). answers require coding. require code, can enter answer either code, mathematical notation, actual single value. Pay attention number decimal places required.","code":""},{"path":"revisiting-probability-distributions.html","id":"Ch4AssignQueLib","chapter":"4 Revisiting Probability Distributions","heading":"4.4.2 Load in the Library","text":"good chance need tidyverse library point exercise load code chunk :Basic probability binomial distribution questionsBackground Information: conducting auditory discrimination experiment participants listen series sounds determine whether sound human . trial participants hear one brief sound (100 ms) must report whether sound human (coded 1) (coded 0). sounds either: person, animal, vehicle, tone, type sound equally likely appear.","code":"\n# hint: something to do with library() and tidyverse"},{"path":"revisiting-probability-distributions.html","id":"Ch4AssignQueT1","chapter":"4 Revisiting Probability Distributions","heading":"4.4.3 Task 1","text":"single trial, probability sound person? Replace NULL t1 code chunk either mathematical notation single value. entering single value, give answer two decimal places.","code":"\nt1 <- NULL"},{"path":"revisiting-probability-distributions.html","id":"Ch4AssignQueT2","chapter":"4 Revisiting Probability Distributions","heading":"4.4.4 Task 2","text":"sequence 4 trials, one trial sound, sampled replacement, probability following sequence sounds: animal, animal, vehicle, tone? Replace NULL t2 code chunk either mathematical notation single value. entering single value, give answer three decimal places.","code":"\nt2 <- NULL"},{"path":"revisiting-probability-distributions.html","id":"Ch4AssignQueT3","chapter":"4 Revisiting Probability Distributions","heading":"4.4.5 Task 3","text":"sequence four trials, one trial sound, without replacement, probability following sequence sounds: person, tone, animal, person? Replace NULL t3 code chunk either mathematical notation single value.","code":"\nt3 <- NULL"},{"path":"revisiting-probability-distributions.html","id":"Ch4AssignQueT4","chapter":"4 Revisiting Probability Distributions","heading":"4.4.6 Task 4","text":"Replace NULL code, using appropriate binomial distribution function, determine probability hearing exactly 17 'tone' trials sequence 100 trials. Assume probability tone single trial 1 4. Store output t4.","code":"\nt4 <- NULL"},{"path":"revisiting-probability-distributions.html","id":"Ch4AssignQueT5","chapter":"4 Revisiting Probability Distributions","heading":"4.4.7 Task 5","text":"Replace NULL code using appropriate binomial distribution function determine probability hearing 30 'vehicle' trials sequence 100 trials. Assume probability vehicle trial one trial 1 4. Store output t5.\nHint: want upper lower tails distribution?","code":"\nt5 <- NULL"},{"path":"revisiting-probability-distributions.html","id":"Ch4AssignQueT6","chapter":"4 Revisiting Probability Distributions","heading":"4.4.8 Task 6","text":"block experiment contained 100 trials, enter line code run 10000 replications one block, summing many living sounds heard replication. Code 1 living sounds (person/animal) 0 non living sounds (vehicle/tone) assume probability living sound given trial \\(p = .5\\).Normal Distribution QuestionsPreviously, Chapter 2, looked ageing research project investigating differences visual processing speed younger (M = 22 years) older adults (M = 71 years). One check experiment, prior analysis, make sure older participants show signs mild cognitive impairment (early symptoms Alzheimer's disease). , carry battery cognitive tests screen symptoms. One tests D2 test attention target cancellation task (.e., participants cross letter d's two dashes line letters). designed test peoples' selective sustained attention visual scanning speed. results test give single score Concentration Performance participant. key piece information analysis distributions D2 test scores typically normally distributed (M = 100, SD = 10).","code":"\nt6 <- NULL"},{"path":"revisiting-probability-distributions.html","id":"Ch4AssignQueT7","chapter":"4 Revisiting Probability Distributions","heading":"4.4.9 Task 7","text":"Replace NULL code using appropriate function determine probability given participant D2 score 90 lower? Store output t7","code":"\nt7 <- NULL"},{"path":"revisiting-probability-distributions.html","id":"Ch4AssignQueT8","chapter":"4 Revisiting Probability Distributions","heading":"4.4.10 Task 8","text":"Replace NULL code using appropriate function determine probability given participant D2 score 120 ? Store output t8","code":"\nt8 <- NULL"},{"path":"revisiting-probability-distributions.html","id":"Ch4AssignQueT9","chapter":"4 Revisiting Probability Distributions","heading":"4.4.11 Task 9","text":"Replace NULL code using appropriate function(s) determine difference scores cut top 5% bottom 5% distribution? Store output t9.","code":"\nt9 <- NULL"},{"path":"revisiting-probability-distributions.html","id":"Ch4AssignQueT10","chapter":"4 Revisiting Probability Distributions","heading":"4.4.12 Task 10","text":"Finally, participant says worried heard Concentration Performance bottom 2% scores distribution, maximum D2 score can ? Replace NULL single value two decimal places. enter code. Store t10Job Done - Activity Complete!Well done, finished! Now go check answers solutions end chapter. looking check questions looking single value answer , questions asking code code give answer alternative variations code allowed (e.g., including lower.tail = TRUE including default). Remember single value coded answer spelling matters, replicate() replicat(). alternative answers, means submitted one options return answer.Lastly, keep mind main point probability, interested determining probability given value distribution! .","code":"\nt10 <- NULL"},{"path":"revisiting-probability-distributions.html","id":"solutions-to-questions-3","chapter":"4 Revisiting Probability Distributions","heading":"4.5 Solutions to Questions","text":"find solutions questions Activities chapter. look giving questions good try speaking tutor issues.","code":""},{"path":"revisiting-probability-distributions.html","id":"continuous-data-and-normal-distribution-tasks","chapter":"4 Revisiting Probability Distributions","heading":"4.5.1 Continuous Data and Normal Distribution Tasks","text":"","code":""},{"path":"revisiting-probability-distributions.html","id":"task-1-2","chapter":"4 Revisiting Probability Distributions","heading":"4.5.1.1 Task 1","text":"First set range IQ values 40 160Then plot distribution IQ_data, M = 100 SD = 10\nFigure 4.11: Distribution IQ scores mean = 100, sd = 10\nReturn Task","code":"\nlibrary(tidyverse)\n\nIQ_data <- tibble(IQ_range = c(40, 160))\n\nggplot(IQ_data, aes(IQ_range)) + \n  stat_function(fun = dnorm, args = list(mean = 100, sd = 15)) +\n  labs(x = \"IQ Score\", y = \"probability\") +\n  theme_classic()"},{"path":"revisiting-probability-distributions.html","id":"task-2-3","chapter":"4 Revisiting Probability Distributions","heading":"4.5.1.2 Task 2","text":"\nFigure 4.12: Normal Distribution shown scale -10 10, mean = 0, sd = 1\nReturn Task","code":"\nND_data <- tibble(ND_range = seq(-10,10,0.05))\n\nggplot(ND_data, aes(ND_range)) + \n  stat_function(fun = dnorm, args = list(mean = 0, sd = 1)) +\n  labs(x = \"SD units\", y = \"probability\", title = \"The Normal Distribution\") +\n  theme_classic()"},{"path":"revisiting-probability-distributions.html","id":"task-3-3","chapter":"4 Revisiting Probability Distributions","heading":"4.5.1.3 Task 3","text":"Key thing set lower.tail FALSE calculate area. using pnorm() state actual cut-even using lower.tail = FALSE. using pbinom() state cut-minus one using lower.tail = FALSEReturn Task","code":"\npnorm(190, 170, 7, lower.tail = FALSE)## [1] 0.002137367"},{"path":"revisiting-probability-distributions.html","id":"task-4-2","chapter":"4 Revisiting Probability Distributions","heading":"4.5.1.4 Task 4","text":"highlighted area 185cm .Key thing set lower.tail FALSE calculate area cut-.Return Task","code":"\npnorm(185, 170, 7, lower.tail = FALSE)## [1] 0.01606229"},{"path":"revisiting-probability-distributions.html","id":"task-5-2","chapter":"4 Revisiting Probability Distributions","heading":"4.5.1.5 Task 5","text":"Question 1 - lowest IQ score student must top 5% distribution.Question 2 - calculate probability given student IQ 105 110, normal distribution mean = 100, sd = 15.Return Task","code":"\nqnorm(0.95, 100, 15, lower.tail = TRUE)## [1] 124.6728\npnorm(105, 100, 15, lower.tail = FALSE) - \n  pnorm(110, 100, 15, lower.tail = FALSE)## [1] 0.1169488"},{"path":"revisiting-probability-distributions.html","id":"practice-your-skills-5","chapter":"4 Revisiting Probability Distributions","heading":"4.5.2 Practice Your Skills","text":"","code":""},{"path":"revisiting-probability-distributions.html","id":"load-in-the-library","chapter":"4 Revisiting Probability Distributions","heading":"4.5.2.1 Load in the Library","text":"Return Task","code":"\nlibrary(tidyverse)"},{"path":"revisiting-probability-distributions.html","id":"task-1-3","chapter":"4 Revisiting Probability Distributions","heading":"4.5.2.2 Task 1","text":"probability sound person 0.75Return Task","code":"\nt1 <- 3/4\nt1 <- .75"},{"path":"revisiting-probability-distributions.html","id":"task-2-4","chapter":"4 Revisiting Probability Distributions","heading":"4.5.2.3 Task 2","text":"probability sequence sounds 0.004Return Task","code":"\nt2 <- (1/4) * (1/4) * (1/4) * (1/4)\nt2 <- .004"},{"path":"revisiting-probability-distributions.html","id":"task-3-4","chapter":"4 Revisiting Probability Distributions","heading":"4.5.2.4 Task 3","text":"probability sequence sounds 0The reason replacement repeat person trial happen.Return Task","code":"\nt3 <- (1/4) * (1/3) * (1/2) * (0/1)\nt3 <- 0"},{"path":"revisiting-probability-distributions.html","id":"task-4-3","chapter":"4 Revisiting Probability Distributions","heading":"4.5.2.5 Task 4","text":"Assuming probability tone given trial 1 4, probability hearing 17 'tone' trials sequence 100 trials 0.0165156Return Task","code":"\nt4 <- dbinom(17, 100, 1/4)"},{"path":"revisiting-probability-distributions.html","id":"task-5-3","chapter":"4 Revisiting Probability Distributions","heading":"4.5.2.6 Task 5","text":"answered using either pbinom() dbinom(). trick remember set cut-depending function used.scenario, probability hearing 30 'vehicle' trials sequence 100 trials 0.149541Return Task","code":"\nt5 <- pbinom(29, 100, 1/4, lower.tail = FALSE)\nt5 <- dbinom(30:100, 100, 1/4) %>% sum()"},{"path":"revisiting-probability-distributions.html","id":"task-6-2","chapter":"4 Revisiting Probability Distributions","heading":"4.5.2.7 Task 6","text":"appropriate code :look output see something like following. Remember numbers vary due random sampling. showing first 10 values 10000Return Task","code":"\nt6 <- replicate(10000, sample(0:1, 100, TRUE, c(.5,.5)) %>% sum())##  int [1:10000] 44 54 47 52 54 45 54 48 48 55 ..."},{"path":"revisiting-probability-distributions.html","id":"task-7-2","chapter":"4 Revisiting Probability Distributions","heading":"4.5.2.8 Task 7","text":"probability given participant D2 score 90 lower 0.1586553Return Task","code":"\nt7 <- pnorm(90, 100, 10, lower.tail = TRUE)"},{"path":"revisiting-probability-distributions.html","id":"task-8-2","chapter":"4 Revisiting Probability Distributions","heading":"4.5.2.9 Task 8","text":"probability given participant D2 score 120 0.0227501Return Task","code":"\nt8 <- pnorm(120, 100, 10, lower.tail = FALSE)"},{"path":"revisiting-probability-distributions.html","id":"task-9","chapter":"4 Revisiting Probability Distributions","heading":"4.5.2.10 Task 9","text":"difference scores cut top bottom 5% distribution 32.8970725Return Task","code":"\nt9 <- qnorm(.95, 100, 10) - qnorm(.05, 100, 10)"},{"path":"revisiting-probability-distributions.html","id":"task-10","chapter":"4 Revisiting Probability Distributions","heading":"4.5.2.11 Task 10","text":"maximum D2 score can situation 79.46Return TaskChapter Complete!","code":"\nt10 <- 79.46"},{"path":"acknowledgements.html","id":"acknowledgements","chapter":"Acknowledgements","heading":"Acknowledgements","text":"book work many people, staff students within School Psychology, University Glasgow. special mention however go following people: Stephanie Boyle, Molly Burr, Morgan Daniel, Amalia Gomoiu, Kate Haining, Jesse Klein, Rebecca Lai, Steven McNair, Shannon McNee, Jennifer Murch, Jack Taylor, Jaimie Torrance, Ana Skolaris & Hollie Sneddon.hugely appreciate comments help creating material contained within book.","code":""},{"path":"installing-r.html","id":"installing-r","chapter":"A Installing R","heading":"A Installing R","text":"Installing R RStudio usually straightforward. sections explain helpful YouTube video .","code":""},{"path":"installing-r.html","id":"installing-base-r","chapter":"A Installing R","heading":"A.1 Installing Base R","text":"Install base R. Choose download link operating system (Linux, Mac OS X, Windows).Mac, install latest release newest R-x.x.x.pkg link (legacy version older operating system). install R, also install XQuartz able use visualisation packages.installing Windows version, choose \"base\" subdirectory click download link top page. install R, also install RTools; use \"recommended\" version highlighted near top list.using Linux, choose specific operating system follow installation instructions.","code":""},{"path":"installing-r.html","id":"installing-rstudio","chapter":"A Installing R","heading":"A.2 Installing RStudio","text":"Go rstudio.com download RStudio Desktop (Open Source License) version operating system list titled Installers Supported Platforms.","code":""},{"path":"installing-r.html","id":"rstudio-settings","chapter":"A Installing R","heading":"A.3 RStudio Settings","text":"settings fix immediately updating RStudio. Go Global Options... Tools menu (,), General tab, uncheck box says Restore .RData workspace startup. keep things around workspace, things get messy, unexpected things happen. always start clear workspace. also means never want save workspace exit, set Never. thing want save scripts.may also want change appearance code. Different fonts themes can sometimes help visual difficulties dyslexia.\nFigure .1: RStudio General Appearance settings\nmay also want change settings Code tab. Foe example, Lisa prefers two spaces instead tabs code likes able see whitespace characters. matter personal preference.\nFigure .2: RStudio Code settings\n","code":""},{"path":"installing-r.html","id":"installing-latex","chapter":"A Installing R","heading":"A.4 Installing LaTeX","text":"can install LaTeX typesetting system produce PDF reports RStudio. Without additional installation, able produce reports HTML PDF. course require make PDFs. generate PDF reports, additionally need install tinytex (Xie, 2021) run following code:","code":"\ntinytex::install_tinytex()"},{"path":"updating-r-rstudio-and-packages.html","id":"updating-r-rstudio-and-packages","chapter":"B Updating R, RStudio, and packages","heading":"B Updating R, RStudio, and packages","text":"time--time, updated version R, RStudio, packages use (e.g., ggplot) become available. Remember separate, different process come different considerations. recommend updating latest version three start academic year.","code":""},{"path":"updating-r-rstudio-and-packages.html","id":"updating-rstudio","chapter":"B Updating R, RStudio, and packages","heading":"B.1 Updating RStudio","text":"RStudio easiest component update. Typically, updates RStudio affect code, instead add new features, like spell-check upgrades RStudio can . usually little downside updating RStudio easy .Click Help - Check updates\nFigure B.1: Updating RStudio\nupdate available, prompt download can install usual.","code":""},{"path":"updating-r-rstudio-and-packages.html","id":"updating-packages","chapter":"B Updating R, RStudio, and packages","heading":"B.2 Updating packages","text":"Package developers occasionally release updates packages. typically add new functions package, fix amend existing functions. aware package updates may cause previous code stop working. tend happen minor updates packages, occasionally major updates, can serious issues developer made fundamental changes code works. reason, recommend updating packages beginning academic year (semester) - assessment deadline just case!update individual package, easiest way use install.packages() function, always installs recent version package.update multiple packages, indeed packages, RStudio provides helpful tools. Click Tools - Check Package Updates. dialogue box appear can select packages wish update. aware select packages, may take time unable use R whilst process completes.\nFigure B.2: Updating packages RStudio\nOccasionally, might problem packages seemingly refuse update, , rlang vctrs cause end trouble. packages likely every explicitly load, required beneath surface R things like knit Markdown files etc.try update package get error message says something like Warning install.packages : installation package vctrs non-zero exit status perhaps Error loadNamespace(, c(lib.loc, .libPaths()), versionCheck = vI[[]]) :  namespace 'rlang' 0.4.9 loaded, >= 0.4.10 required one solution found manually uninstall package, restart R, install package new, rather trying update existing version. installr package also useful function uninstalling packages.","code":"\ninstall.packages(\"tidyverse\")\n# Load installr\nlibrary(installr)\n\n# Uninstall the problem package\nuninstall.packages(\"package_name\")\n\n# Then restart R using session - restart R\n# Then install the package fresh\n\ninstall.packages(\"package\")"},{"path":"updating-r-rstudio-and-packages.html","id":"updating-r","chapter":"B Updating R, RStudio, and packages","heading":"B.3 Updating R","text":"Finally, may also wish update R . key thing aware update R, just download latest version website, lose packages. easiest way update R cause huge headache use installr package. use updateR() function, series dialogue boxes appear. fairly self-explanatory full step--step guide available use installr, important bit select \"Yes\" asked like copy packages older version R.always, issues, please ask Teams book GTA session.","code":"\n# Install the installr package\ninstall.packages(\"installr\")\n\n# Load installr\nlibrary(installr)\n\n# Run the update function\nupdateR()"},{"path":"exporting-files-from-the-server.html","id":"exporting-files-from-the-server","chapter":"C Exporting files from the server","heading":"C Exporting files from the server","text":"using R server, may need export files share people submit assignments.First, make sure saved changes made file. clicking \"File - Save\", Ctrl + S, clicking save icon. changes saved, save icon greyed . new unsaved changes, able click icon.Select file download files pane (bottom right) ticking box next , click \"- Export\" save file computer.R installed, try open computer. , open Word, Endnote similar, may corrupt code. open file R R Studio installed.want double check file definitely right one submit assignment, can re-upload server open make sure answers .","code":""},{"path":"symbols.html","id":"symbols","chapter":"D Symbols","heading":"D Symbols","text":"\nFigure D.1: Image James Chapman/Soundimals\n","code":""},{"path":"license.html","id":"license","chapter":"License","heading":"License","text":"book licensed Creative Commons Attribution-ShareAlike 4.0 International License (CC--SA 4.0). free share adapt book. must give appropriate credit, provide link license, indicate changes made. adapt material, must distribute contributions license original.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
