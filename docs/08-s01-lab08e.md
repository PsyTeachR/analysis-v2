## Solutions to Questions

Below you will find the solutions to the questions for the Activities for this chapter. Only look at them after giving the questions a good try and speaking to the tutor about any issues.

### InClass Activities

#### InClass Task 1


```r
d <- 3.24 / sqrt(25 +1)
```

* Giving an effect size of d = 0.64 and as such a medium to large effect size according to Cohen (1988)

[Return to Task](#Ch8InClassQueT1)

#### InClass Task 2


```r
d <- (2*2.9) / sqrt(30)
```

* Giving a effect size of d = 1.06 and as such a large effect size according to Cohen (1988)

[Return to Task](#Ch8InClassQueT2)

#### InClass Task 3


```r
N = 39 + 1

d <- 2.1 / sqrt(N)
```

* Giving an N = 40 and an effect size of d = 0.33. This would be considered a small effect size according to Cohen (1988)

[Return to Task](#Ch8InClassQueT3)

#### InClass Task 4


```r
t = (10 - 11)/sqrt((1.3^2/30) + (1.7^2/30))

d = (2*t)/sqrt((30-1) + (30-1))
```

* Giving a t-value of t = 2.56 and an effect size of d = 0.67.
* Remember that convention is that people tend to report the t and d as positive values.

[Return to Task](#Ch8InClassQueT4)

#### InClass Task 5


```r
sample_size <- pwr.t.test(d = .23,
                          power = .8, 
                          sig.level = .05, 
                          alternative = "two.sided", 
                          type = "one.sample") %>%
  pluck("n") %>% 
  ceiling()
```

* Giving a sample size of n = 151

[Return to Task](#Ch8InClassQueT5)

#### InClass Task 6


```r
cohens <- pwr.t.test(n = 50,
                    power = .9, 
                    sig.level = .05, 
                    alternative = "two.sided", 
                    type = "two.sample") %>% 
  pluck("d") %>% 
  round(2)
```

* Giving a Cohen's d effect size of d = 0.65

[Return to Task](#Ch8InClassQueT6)

#### InClass Task 7

**Example 1**


```r
ach_d_exp1 <- pwr.t.test(power = .8, 
                         n = 32, 
                         type = "one.sample", 
                         alternative = "two.sided", 
                         sig.level = .05) %>% 
  pluck("d") %>% 
  round(2) 

exp1_d <- 2.96/sqrt(31+1) 
```

* Giving an achievable effect size of 0.51 and they found an effect size of 0.52.

This study seems ok as the authors could achieve an effect size as low as .51 and found an effect size at .52

**Example 2**


```r
ach_d_exp2 <- pwr.t.test(power = .8, 
                         n = 32, 
                         type = "paired", 
                         alternative = "two.sided", 
                         sig.level = .05) %>% 
  pluck("d") %>% 
  round(2) 

exp2_d <- 2.42/sqrt(31+1) 
```

* Giving an achievable effect size of 0.51 and they found an effect size of 0.43.

This effect might not be reliable given that the effect size found was much lower than the achievable effect size. The issue here is that the researchers established their sample size based on a previous effect size and not on the minimum effect size that they would find important. If an effect size as small as .4 was important then they should have powered all studies to that level and ran the appropriate n ~52 babies (see below). Flipside of course is that obtaining 52 babies isnt easy; hence why some people consider the Many Labs approach a good way ahead.

**ONE CAVEAT** to the above is that before making the assumption that this study is therefore flawed, we have to keep in mind that this is one study using one sample from a potentially huge number of samples within a population. As such there will be a degree of variance in the true effect size within the population regardless of the effect size of one given sample. What that means is we have to be a little bit cautious when making claims about a study. Ultimately the higher the power the better.

Below you could calculate the actual sample size required to achieve a power of .8:


```r
sample_size <- pwr.t.test(power = .8,
                          d = .4,
                          type = "paired", 
                          alternative = "two.sided", 
                          sig.level = .05) %>%
  pluck("n") %>% 
  ceiling()
```

* Suggesting a sample size of n = 52 would be appropriate.

[Return to Task](#Ch8InClassQueT7)

### Test Yourself Activities

**Libraries**


```r
library(pwr)
library(tidyverse)
```

#### Assignment Task 1


```r
error_rate <- 1 - .87
```

* The Type II error rate of your study would be $\beta$ = 0.13.

[Return to Task](#Ch8AssignQueT1)

#### Assignment Task 2


```r
effect1 <- (2*3.26)/sqrt(32)
```

* The effect size would be d = 1.1525841

[Return to Task](#Ch8AssignQueT2)

#### Assignment Task 3


```r
effect2 <- 2.24/sqrt(43+1)
```

* The effect size would be d = 0.3376927

[Return to Task](#Ch8AssignQueT3)

#### Assignment Task 4


```r
participants <- pwr.t.test(power = .9,
                           d = .5,
                           sig.level = 0.05,
                           type = "paired",
                           alternative = "two.sided") %>% 
  pluck("n") %>% 
  ceiling()
```

* Given the detailed scenario, the appropriate number of participants would be n = 44

[Return to Task](#Ch8AssignQueT4)

#### Assignment Task 5 


```r
effect3 <- power.t.test(power = 1-.16,
                      n = 30,
                      sig.level = 0.01,
                      type = "one.sample",
                      alternative = "two.sided") %>% 
  tidy() %>% 
  pull(delta) %>% 
  round(2)
```

* Given the detailed scenario, we would be able to detect an effect size of  d = 0.69

[Return to Task](#Ch8AssignQueT5)

#### Assignment Task 6


```r
tval <- (5.1 - 4.4) / sqrt((1.34^2/32) + (1.27^2/32))
```

* Given the stated means and standard deviations, the t-value for this study would be t = 2.1448226

[Return to Task](#Ch8AssignQueT6)

#### Assignment Task 7


```r
d1 <- (2*tval)/sqrt((32-1)+(32-1))
```

* Given the t-value in Task 6, the effect size of this study would be d = 0.5447855.

[Return to Task](#Ch8AssignQueT7)

#### Assignment Task 8


```r
poss_d <- pwr.t.test(power = .8,
                     n = 32,
                     sig.level = 0.05,
                     type = "two.sample",
                     alternative = "two.sided") %>% 
  pluck("d") %>% 
  round(2)

answer_T8 <- 4
```

* The smallest effect size that this study can determine is d = 0.71. The detected effect size, `d1`, is smaller than this (d1 = 0.5447855) and as such this study is not suitably powered.
* Given that outcome, the 4th statement is the most suitable answer - answer_T8 = 4.

[Return to Task](#Ch8AssignQueT8)

#### Assignment Task 9


```r
effect4 <- pwr.t.test(power = .8,
                      n = 18,
                      sig.level = .01,
                      alternative = "two.sided",
                      type = "two.sample") %>% 
  pluck("d") %>% 
  round(3)
```

* The smallest stated n is n = 18 and the stated $\alpha$ is $\alpha$ = .01
* Given these details, the minimum effect size that this paper could have reliably detected was d = 1.198

[Return to Task](#Ch8AssignQueT9)

#### Assignment Task 10


```r
answer_t10 <- 4
```

* This study does not have enough power to detect effect sizes at d1 or lower and as such answer_t10 = 4
* However, it is worth keeping in mind that we are only looking at one study here which drew one sample from a population of samples. This means that there is always uncertainty about the true effect size of a difference or association - taking a different sample may have given a different effect size. As such, the comparison we are making here is not entirely valid and we should see it more as a reminder that we should always think of power as more in the planning of studies rather than in the search for criticism.

[Return to Task](#Ch8AssignQueT10)

#### Assignment Task 11


```r
answer_t11 <- 2
```

* In general, increasing sample size will increase the power of a study whereas lowering alpha (from .05 to .01) will decrease the power of a study. As such, statements a and c, answer_t11 = 2.  

[Return to Task](#Ch8AssignQueT11)

<span style="font-size: 22px; font-weight: bold; color: var(--purple);">Chapter Complete!</span>
