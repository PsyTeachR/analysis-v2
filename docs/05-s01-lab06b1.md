## Background of data: Sleep

<a href = "https://www.sciencedirect.com/science/article/pii/S0005796708002738" target = "_blank">Woods and colleagues (2009)</a> were interested in how the attention of people with poor sleep (Primary Insomnia - PI) was more tuned towards sleep-related stimuli than the attention of people with normal sleep (NS). Woods et al. hypothesised that participants with poor sleep would be more attentive to images related to a lack of sleep (i.e., an alarm clock showing 2AM) than participants with normal sleep would be. To test their hypothesis, the authors used a modified Posner paradigm, shown in Figure 1 of the paper, where images of an alarm clock acted as the cue on both valid and invalid trials, with the symbol **( .. )** being the target. 

As can be seen in Figure 3 of <a href = "https://www.sciencedirect.com/science/article/pii/S0005796708002738" target = "_blank">Woods et al.</a> found that, on valid trials, whilst Primary Insomnia participants were faster in responding to the target, suggesting a slight increase in attention to the sleep related cue compared to the Normal Sleepers, there was no difference between groups. In contrast, for invalid trials, where poor sleep participants were expected to be distracted by the cue, the authors did indeed find a significant difference between groups consistent with their alternative hypothesis $H_{1}$. Woods et al., concluded that poor sleepers (Primary Insomnia participants) were slower to respond to the target on invalid trials, compared to Normal Sleepers, due to the attention of the Primary Insomnia participants being drawn to the misleading cue (the alarm clock) on the invalid trials. This increased attention to the sleep-related cue led to an overall slower response to the target on these invalid trials.




Now, imagine you are looking to replicate this finding from Woods et al. (2009). As a pilot study, to test recruitment procedures, you gather data from 22 Normal Sleepers. It is common to use only the control participants in a pilot (in this case the NS participants) as they are more plentiful in the population than the experimental group (in this case PI participants) and saves using participants from the PI group which may be harder to obtain in the long run.

After gathering your data, you want to check the recruitment process: Whether or not you were able to draw a sample of normal sleepers similar to the sample drawn by Woods et al. To keep things straightforward, allowing us to understand the analyses better, we will only look at valid trials today, in NS participants, but in effect you could perform this test on all groups and conditions.



<!-- **ManyLabs - an approach to reproducible science** -->

<!-- As you will learn from reading papers around the reproduciblity crisis, findings from experiments tend to be more reproducible when we increase participant numbers as this increases the <a class='glossary'>power<span class='def'></span></a> of the study's design; the likelihood of an experimental design detecting an effect, of a given size, when there is an effect to detect.  -->

<!-- 
<div class='webex-solution'><button>Portfolio Point - The power of what?</button>
 -->
<!-- ```{block, type ="info"} -->
<!-- Power is a rather tricky concept in research that essentially amounts to the probability of your design being able to detect a significant difference when there is actually a significant difference to detect.  -->

<!-- Power is an interplay between three other aspects of research design:  -->

<!-- * alpha - your critical p-value (normally .05);  -->
<!-- * the sample size (n);  -->
<!-- * the effect size - how big is the difference (measured in a number of ways).  -->

<!-- If you know any three of these four elements (power, alpha, effect size, n) you can calculate the fourth. We will save further discussion of power until Chapter 8 but if you want to read ahead then this blog is highly recommended: <a href="https://pigee.wordpress.com/2016/09/13/the-power-dialogues/" target ="_blank">The Power Dialogues</a>. -->
<!-- ``` -->
<!-- 
</div>
 -->
<!-- <br> -->

<!-- However, running several hundred participants in your one study can be a significant time and financial investment. Fortunately, the idea of a "ManyLabs" project can solve this problem. In this scenario the same experiment is run in various locations, all using the same procedure, and then the data is collapsed together and analysed as one. You can see a nice example of a Many Labs project in the paper <a href="" target = "_blank">Investigating Variation in Replicability (Klein et al., 2014)</a>. See how many labs and researchers are involved? Perhaps this is a better approach than lots of researchers working individually?  -->

<!-- You think this all sounds a great idea so in your quest to be a collaborative reproducible researcher, and as a high-five to #TeamScience, you have joined a ManyLabs study replicating the findings of Woods et al. (2009). And that study is the premis for today's activities so let's start by having a quick-run through of the background of the experiment. -->

<!-- **The Background** -->

<!-- <a href = "https://www.sciencedirect.com/science/article/pii/S0005796708002738" target = "_blank">Woods and colleagues (2009)</a> were interested in how the attention of people with poor sleep (Primary Insomnia - PI) was more tuned towards sleep-related stimuli than the attention of people with normal sleep (NS). Woods et al., hypothesised that participants with poor sleep would be more attentive to images related to a lack of sleep (i.e. an alarm clock showing 2AM) than participants with normal sleep would be. To test their hypothesis, the authors used a modified Posner paradigm, shown in Figure 1 of the paper, where images of an alarm clock acted as the cue on both valid and invalid trials, with the symbol **( .. )** being the target.  -->

<!-- As can be seen in Figure 3 of <a href = "https://www.sciencedirect.com/science/article/pii/S0005796708002738" target = "_blank">Woods et al.,</a> the authors found that, on valid trials, whilst Primary Insomnia participants were faster in responding to the target, suggesting a slight increase in attention to the sleep related cue compared to the Normal Sleepers, there was no difference between groups. In contrast, for invalid trials, where poor sleep participants were expected to be distracted by the cue, the authors did indeed find a significant difference between groups consistent with their alternative hypothesis $H_{1}$. Woods et al., concluded that poor sleepers (Primary Insomnia participants) were slower to respond to the target on invalid trials, compared to Normal Sleepers, due to the attention of the Primary Insomnia participants being drawn to the misleading cue (the alarm clock) on the invalid trials. This increased attention to the sleep-related cue led to an overall slower reponse to the target on these invalid trials. -->

<!-- ```{r ch6-preclass-setup, echo = FALSE, message=FALSE, warning=FALSE, results='asis'} -->
<!-- # all data in here to make inline code work  -->
<!-- # solutions are shown for students at the bottom -->
<!-- # key values -->
<!-- n_new <- 22 -->
<!-- orig_mean <- 590 -->
<!-- orig_sd <- 94 -->
<!-- #Task 1 -->
<!-- ns_data <- tibble(participant = 1:n_new, -->
<!--                   valid_rt = c(631.2,800.8,595.4,502.6,604.5, -->
<!--                                516.9,658.0,502.0,496.7,600.3, -->
<!--                                714.6,623.7,634.5,724.9,815.7, -->
<!--                                456.9,703.4,647.5,657.9,613.2, -->
<!--                                585.4,674.1)) -->

<!-- #Task 2 -->
<!-- woods_mean <- 590 -->
<!-- n_participants <- ns_data %>% -->
<!--   filter(valid_rt > woods_mean) %>% -->
<!--   nrow() -->
<!-- #Task 3 -->
<!-- pval_dbinom <- sum(dbinom(n_participants:nrow(ns_data), nrow(ns_data), .5)) -->
<!-- #Task 4 -->
<!-- ns_data_mean <- ns_data %>% summarise(m = mean(valid_rt)) %>% pull(m)   -->
<!-- ns_data_sd <- ns_data %>% summarise(sd = sd(valid_rt)) %>% pull(sd)  -->
<!-- #Task 5 -->
<!-- t_obs <- (ns_data_mean - woods_mean) / (ns_data_sd / sqrt(nrow(ns_data))) -->
<!-- #Task 6 -->
<!-- pval <- pt(abs(t_obs), nrow(ns_data) - 1L, lower.tail = FALSE) * 2L -->
<!-- #Task 7 -->
<!-- ttest <- t.test(pull(ns_data, valid_rt), mu = woods_mean) -->
<!-- ``` -->

<!-- As we said above, your lab is now part of a ManyLabs project that is looking to replicate this finding from Woods et al., (2009). As a <a class='glossary'>pilot study<span class='def'></span></a>, to test recruitment procedures, as well as the experimental paradigm and analyses pipeline, each lab gathers data from 22 Normal Sleepers. It is common to use only the control participants in a pilot (in this cas the NS participants) as they are more plentiful in the population than the experimental group (in this case PI participants) and saves using participants from the PI group which may be harder to obtain in the long run. -->

<!-- After gathering your data, we want to check the recruitment process and whether or not you have been able to draw a sample of normal sleepers similar to the sample drawn by Woods et al. To keep things straightforward, allowing us to understand the analyses better, we will only look at valid trials today, in NS participants, but in effect you could perform this test on all groups and conditions. -->

**Are These Participants Normal Sleepers (NS)?**

Below is the data from the 22 participants you have collected in your pilot study. Their mean reaction time for valid trials (in milliseconds) is shown in the right hand column, `valid_rt`.

<table>
<caption>(\#tab:ch6-preclass-nsdata)Pilot Data for 22 Participants on a Sleep-Related Posner Paradigm. ID is shown in participant column and mean reaction time (ms) on valid trails is shown in valid_rt column.</caption>
 <thead>
  <tr>
   <th style="text-align:center;"> participant </th>
   <th style="text-align:center;"> valid_rt </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:center;"> 1 </td>
   <td style="text-align:center;"> 631.2 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 2 </td>
   <td style="text-align:center;"> 800.8 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 3 </td>
   <td style="text-align:center;"> 595.4 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 4 </td>
   <td style="text-align:center;"> 502.6 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 5 </td>
   <td style="text-align:center;"> 604.5 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 6 </td>
   <td style="text-align:center;"> 516.9 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 7 </td>
   <td style="text-align:center;"> 658.0 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 8 </td>
   <td style="text-align:center;"> 502.0 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 9 </td>
   <td style="text-align:center;"> 496.7 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 10 </td>
   <td style="text-align:center;"> 600.3 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 11 </td>
   <td style="text-align:center;"> 714.6 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 12 </td>
   <td style="text-align:center;"> 623.7 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 13 </td>
   <td style="text-align:center;"> 634.5 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 14 </td>
   <td style="text-align:center;"> 724.9 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 15 </td>
   <td style="text-align:center;"> 815.7 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 16 </td>
   <td style="text-align:center;"> 456.9 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 17 </td>
   <td style="text-align:center;"> 703.4 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 18 </td>
   <td style="text-align:center;"> 647.5 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 19 </td>
   <td style="text-align:center;"> 657.9 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 20 </td>
   <td style="text-align:center;"> 613.2 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 21 </td>
   <td style="text-align:center;"> 585.4 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> 22 </td>
   <td style="text-align:center;"> 674.1 </td>
  </tr>
</tbody>
</table>

If you look at <a href="https://www.sciencedirect.com/science/article/pii/S0005796708002738" target = "_blank">Woods et al (2009)</a> Figure 3 you will see that, on valid trials, the mean reaction time for NS participants was 590 ms with a SD = 94 ms. As above, as part of our pilot study, we want to confirm that the 22 participants we have gathered are indeed Normal Sleepers. We will use the mean and SD from Woods et al., to confirm this. Essentially we are asking if the participants in the pilot are responding in a similar fashion as NS participants in the original study.

When using NHST we are working with both a null hypothesis ($H_{0}$) and an alternative hypothesis ($H_{1}$). Thinking about this experiment it makes some logical sense to think about it in terms of the null hypothesis ($\mu1 = \mu2$). So we could phrase our hypothesis as: "We hypothesise that there is no significant difference in mean reaction times to valid trials on the modified Posner task between the participants in the pilot study and the participants in the original study by Woods et al."

There is actually a few ways to test this null hypothesis. Today we will show you how to do two of these: In tasks 1-3 we will use a **binomial test** and in tasks 4-8 we will use a **one-sample t-test**


<div class='webex-solution'><button>Thinking Cap Point - Binomial test and the one-sample t-test</button>

<div class="info">
<p>The <strong>Binomial test</strong> is a very simple test that
converts all participants to either being above or below a cut-off
point, e.g.Â a mean value, and looking at the probability of finding that
number of participants above that cut-off.</p>
<p>The <strong>One-sample t-test</strong> is similar in that it compares
participants to a cut-off, but it compares the mean and standard
deviation of the collected sample to an ideal mean and standard
deviation. By comparing the difference in means, divided by the standard
deviation of the difference (a measure of the variance), we can
determine if the sample is similar or not to the ideal mean.</p>
</div>

</div>

