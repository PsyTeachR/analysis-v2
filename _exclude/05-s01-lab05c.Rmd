## InClass Activity 

A common statistical question when comparing two groups might be, "**Is there a real difference between the group means?**" From this we can establish two contrasting hypotheses: 

1. The **null hypothesis** which states that the group means **are equivalent** and is written as: $H_0: \mu_1 = \mu_2$ 
    - where $\mu_1$ is the population mean of group 1 
    - and $\mu_2$ is the population mean of group 2  
2. Or the **alternative hypothesis** which states that the group means **are not equivalent** and is written as: $H_1: \mu_1 \ne \mu_2$.

Using the techniques you read about in the PreClass and in previous chapters, today you will learn how to test the null hypothesis of no difference between two independent groups. We will first do this using a **permutation test** before looking at other tests in later chapters. 

### Permutation Tests of Hypotheses

A permutation test is a basic inferential procedure that involves a reshuffling of group labels or values (PreClass Skill 2) to create new possible outcomes of the data you collected to see how your original mean difference (PreClass Skill 4) compares to a distribution of possible outcomes (InClass). Permutation tests can in fact be applied in many situations, this is just one, and it provides a good starting place for understanding hypothesis testing. 

The steps for the InClass exercises below, and really the logic of a permutation test for two independent groups, are:

1. Calculate the real difference $D_{orig}$ between the means of two groups (e.g. Mean of A minus Mean of B).
2. Randomly shuffle the group labels (i.e. which group each participant belonged to - A or B) and re-calculate the difference, $D'$.
3. Repeat Step 2 $N_{r}$ times, where $N_r$ is a large number (typically greater than 1000), storing each $D_i'$ value to form a null hypothesis distribution.
4. Locate the difference you observed in Step 1 (the real difference) on the null hypothesis distribution of possible differences created in Step 3. 
5. Decide whether the original difference is sufficiently extreme to reject the null hypothesis of no difference ($H_0$) - related to the idea of probability in Chapter 4.

This logic of the test works because if the null hypothesis ($H_0$) is true (there is no difference between the groups, $\mu_1 = \mu_2$) then the labeling of the observations/participants into groups is arbitrary, and we can rearrange the labels in order to estimate the likelihood of our original difference under the $H_0$. In other words, if you know the original value of the difference between two groups (or the true difference) falls in the middle of your permuted distribution then there is no significant difference between the two groups. If, however, the original difference falls in the tail of the permuted distribution then there might be a significant difference depending on how far into the tail it falls. Again, think back to Chapter 4 and using `pbinom()` and `pnorm()` to ask what is the probability of a certain value or observation - e.g. a really tall student. Unlikely values appear in the tails of distributions. We are goign to use all the skills we have learnt up to this point to visualise this concept and what it means for making inferences about populations in our research.

Let's begin!

### Step 1: Load in Add-on Packages and Data {#Ch5InClassQueT1}

1.1.  Open a new script and call `tidyverse` into your library.  

1.2.  Now type the statement `set.seed(1409)` at the top of your script after your library call and run it.  (This 'seeds' the random number generator in R so that you will get the same results as everyone else. The number 1409 is a bit random but if everyone uses it then we all get the same outcome. Different seeds give different outcomes) 

Note: This lab was written under `r R.version.string`. If you use a different RVersion (e.g. R 3.6.x) or set a different seed (e.g. `1509`) you may get different results.

1.3.  [Download the data file from here](data/05-s01/inclass/ch5-inclass-data.zip) and store the data in `perm_data.csv` in a tibble called `dat` using `read_csv()`.  

1.4.  Let's give every participant a participant number by adding a new column to `dat`. Something like this would work: `mutate(subj_id = row_number())`

`r hide("Helpful Hint")`
```{block, type ="info"}

1.1 - Something to do with `library()`

1.2 - `set.seed(1409)`

1.3 - Something to do with `read_csv()`

1.4 - pipe (`%>%`) `dat` into the mutate line shown
```
`r unhide()`

`r hide("Portfolio Point - Different uses of row_number")`
```{block, type ="info"}
You will see that, in the example here, to put a row number for each of the participants we do not have to state the number of participants we have. In Preclass Activity SKill 3, however, we did. What is the difference?  

In the PreClass Activity we were making a new tibble from scratch and trying to create a column in that tibble using `row_numbers`. If you want to do that you have to state the number of rows, e.g. `1:20`.  However, in this example in the lab today the tibble already exists, we are just adding to it. If that is the case then you can just mutate on a column of row numbers without stating the number of participants. 

In summary:

* When creating the tibble, state the number of participants in `row_numbers()`.
* If tibble already exists, just mutate on `row_numbers()`. No need for specific numbers.
```
`r unhide()`
<br>

Have a look at the resulting tibble, `dat`. The columns refer to:

* The column `group` is your independent variable (IV) - Group A or Group B.
* The column `Y` is your dependent variable (DV) 
* The column `subj_id` is the participant number.

```{r read-dat, echo = FALSE, message = FALSE, warning = FALSE}
library("tidyverse")
set.seed(1409)
dat <- read_csv("data/05-s01/inclass/perm_data.csv") %>%
  mutate(subj_id = row_number())
dat
```

### Step 2: Calculate the Original Mean Difference - $D_{orig}$ {#Ch5InClassQueT2}

We now need to write a pipeline of five functions (i.e. commands) that calculates the mean difference between the groups in `dat`, Group A minus Group B. Just like we did in PreClass Skill 4 starting from `group_by() %>% summarise()`. Broken down into steps this would be: 

2.1.1. Starting from `dat`, use a pipe of two `dplyr` one-table verbs (e.g. from Chapter 2) to create a tibble where each row contains the mean of one of the groups. Name the column storing the means as `m`. 

2.1.2. Continue the pipe to spread your data from long to wide format, based on the names in column `group` and values in `m`. You should use `pivot_wider()`.

2.1.3. Now add a pipe that **creates** a new column in this wide dataset called `diff` which is the value of group A's mean minus group B's mean.   

2.1.4.  Pull out the value in `diff` (the mean of group A minus the mean of group B) to finish the pipe.  

`r hide("Helpful Hint")`
```{block, type ="info"}
`dat %>%`

  `group_by(?) %>%`

  `summarise(m = ?) %>%`

  `pivot_wider(names_from = "group", values_from = "m") %>%`

  `mutate(diff = ? - ?) %>%`

  `pull(?)`
```
`r unhide()`
<br> 

```{r hidden-1, include=FALSE}
diff <- dat %>%
  group_by(group) %>%
  summarise(m = mean(Y)) %>%
  pivot_wider(names_from = "group", values_from = "m") %>%
  mutate(x = A - B) %>%
  pull(x)
```

<span style="font-size: 22px; font-weight: bold; color: var(--green);">Quickfire Questions</span>

* Check that your value for $D_{orig}$ is correct, without using the solution, by typing your $D_{orig}$ value to two decimal places in the box. Include the sign, e.g. -1.23. The box will go green if you are correct. `r fitb(round(diff, 2), width = 10, ignore_ws = TRUE)`

Just as we did in Skill 4 in the PreClass Activity, the above steps have created a pipeline of five functions to get one value. Nice! Now, using the knowledge from Skills 2 and 5 of the PreClass Activity, we now need to turn this into a function because we are going to be permuting the data set (specifically the grouping labels) and re-calculating the difference many, many times. This is how we are going to create a distribution of values.

2.2. Now, using what you learnt in PreClass Activity Skill 5, wrap your pipeline (from above) in a function (between the curly brackets) called `calc_diff`. However, instead of starting your pipeline with `dat`, start it with `x` - literally change the word `dat` at the start of your pipeline to `x`. 

* This function will take a single argument named `x`, where `x` is any tibble that you want to calculate group means from. As in the previous step, the function will atill return a single value which is the difference between the group means. The start of your function will look like this below:  

```{r calc_diff_example, include=TRUE, eval=FALSE}
calc_diff <- function(x){
  x %>%....
}
```

`r hide("Helpful Hint")`
```{r calc-diff-hint, eval = FALSE}
calc_diff <- function(x) {
  x %>%
    group_by(group) %>%
    the_rest_of_your_pipe... %>%
    pull(diff)
}
```
`r unhide()`
<br>

2.3.  Now call your new function where `x` = `dat` as the argument and store the result in a new variable called `d_orig`.  Make sure that your function returns the same value for $D_{orig}$ as you got above and that your function returns a single value rather than a tibble. 

* You can test whether something is a tibble or a value by: 
    * `is.tibble(d_orig)` should give you `FALSE` and 
    * `is.numeric(d_orig)` should give you `TRUE`.

`r hide("Helpful Hint")`
```{r d-orig-hint, eval = FALSE}
d_orig <- function_name(x = data_name) 
# or
d_orig <- function_name(data_name)

# Then type the following in the Console and look at the answer:

is.tibble(d_orig)
# True (is a tibble) or False (is not a tibble)

is.numeric(d_orig)
# True (is numeric) or False (is not numeric; it is a character or integer instead.)
```
`r unhide()`
<br>

Great. To recap, using what we learnt in PreClass Skills 4 & 5, we now have a function called `calc_diff()` that, when we give it our data (`dat`), it returns the original difference between the groups - which we have stored in `d_orig`. 

Ok, so we now know the original difference between Groups A and B. Also, we know at the start of this InClass Activity we said we wanted to determine if there was a significant difference between Groups A and B by looking at the probability of obtaining the $D_{orig}$ value from the distribution of all possible outcomes for this data, right? So in order to do that, using what we learnt in Skills 2 and 6 of the PreClass Activity, we need to create a distribution of all possible differences between Groups A and B to see where our original difference lies in that distribution. And our first step in that process is shuffling the `group` (A or B) in our dataset and finding the difference...a few hundred times! 

### Step 3: Permute the Group Labels {#Ch5InClassQueT3}

3.1.  Create a new function called `permute()` that: 

* Takes as input a dataset (e.g. `x`) and returns the same dataset transformed such that the group labels (the values in the column `group`) are shuffled: started below for you.  
* This will require using the `sample()` function within a `mutate()` function. 
* You have used `mutate()` twice already today and you saw how to `sample()` **letters** in the PreClass Activity Skill 2.
* Get this working outside the function first, e.g. in your console windown, and then add it to the function.

```{r permute_example, include=TRUE, eval=FALSE}
permute <- function(x){
  x %>%.....
}
```

`r hide("Helpful Hint")`
```{block, type ="info"}
Might be easier to think of these steps in reverse.  

1. Start with a `mutate()` function that rewrites the column `group` every time you run it, e.g. `dat %>% mutate(variable = sample(variable))`  

**Note:** Be accurate on the spelling within the mutate() function. If your original column is called `group` then you should `sample(group)`.

2. Now put that into your `permute()` function making the necessary adjustments to the code so it starts `x %>%...` instead of `dat %>%...`. Again `x` should be in the function and not `dat`.
```
`r unhide()`
<br>


3.2.  Try out your new `permute()` function by calling it on `dat` (i.e. `x = dat`) a few times.  You should see the group labels in the `group` column changing randomly. The most common mistake is that people mutate a new column by mispelling `group`. You want to overwrite/change the information in the `group` column not make a new one, so be careful with the spelling.

<span style="font-size: 22px; font-weight: bold; color: var(--pink);">Group Discussion Point</span>

Now would be an excellent time to spend five minutes as a group recapping what you are doing. 

* You have the original difference between groups. 
* You have a function that calculates and stores this difference.
* You have a function that reshuffles the labels of the group. 
* You understand probability is based on where a specific value occurs on the distribution of all possible values
* You know extreme differences are significant.

Do you understand why? If not, go back to the principles of the permutation test at the start of the lab then read on...

### Step 4: Create the Null-Hypothesis Distribution (NHD) for the Difference {#Ch5InClassQueT4}

Now that we have the original difference and our two functions, one to shuffle group labels (`permute`) and one to calculate the difference between two groups (`calc_diff`), we need to actually create the distribution of possible differences and see where the original difference lies in it.

4.1.1.  Write a **a single pipeline** that takes `dat` as the input, permutes the group labels with a call to your function `permute()`, and then calculates the difference in means between these new groups with a call to your function `calc_diff()`.  

4.1.2. Run this line manually a few times and watch the resulting value change every time you run it. This is because on each run the order of A and B labels within the data is getting changed and a new difference is calculated.

`r hide("Helpful Hint")`
```{block, type ="info"}
Think about verbalising your pipelines. In a single pipeline:

1. I want to permute the data into two new groups.
2. Then I want to calculate the difference between these two new groups. 

The functions you have created do these steps. You just have to put them in order and pipe the data through it:

* `dat %>% function1() %>% function2()`

```
`r unhide()`
<br>


4.2.  Now take your pipeline of functions and repeat it 1000 times using the `replicate()` function as you saw in PreClass Activity Skill 6. Store the output in a variable called `nhd`. `nhd` will contain 1000 values where each value is the mean difference of each of the 1000 random permutations of the data. (**Warning:** This will probably take a while to run, perhaps 10 seconds.)

* This step will give you 1000 possible values of the difference between the permuted groups A and B - your permuted distribution. 

`r hide("Helpful Hint")`
```{block, type ="info"}
This is going to look something like

`nhd <- replicate(times, expression)`

* Replace `expression` with the pipeline you created in 4.1.1
* Replace `times` with how many times you want to run it the `expression`
```
`r unhide()`
<br>

4.3 Now that we have all the values for our distribution in `nhd`, let's visualise this distribution in a histogram.  This shows us the likelihood of various mean differences under $H_0$. 

* We have started the code for you but one thing to note however is that `nhd` is not a `tibble` and `ggplot` needs it to be a `tibble`. You need to convert it just like you did in Preclass Activity Skill 3. You might start by do something like:

```{r histogram_example, include = TRUE, eval = FALSE}
ggplot(data = tibble(x = NULL), aes(x)) + NULL
```

`r hide("Helpful Hint")`
```{block, type ="info"}
Remember that `ggplot` works as: `ggplot(data, aes(x)) + geom...`. Here you need to convert `nhd` into a tibble and put that in as your data. Look at the example above and keep in mind that, in this case, the first NULL could be replaced with the data in `nhd`.
```
`r unhide()`
<br>

<span style="font-size: 22px; font-weight: bold; color: var(--pink);">Group Discussion Point</span>

* Looking at the histogram, visually locate where your original value would sit on this distribution. Would it be extreme, in the tail, or does it look rather common, in the middle? `r mcq(c("is in the middle so looks common",answer = "is in the tail so looks extreme"))`

Before moving on stop to think about what this means - that the difference between the two original groups is rather uncommon in this permuted distribution, i.e. is in the tails! Again, if unsure, go back to the principles of NHST, or the ideas raised about Probability in Chapter 4, or discuss it with your tutor!

### Step 5: Compare the Observed Mean Difference to the NHD {#Ch5InClassQueT5}

Right! We know $D_{orig}$ and we know all the values of the simulated distribution, $D_i'$. If the null hypothesis is false $\mu1 \ne \mu2$, and there is a real difference between the groups, then the difference in means we observed for the original data ($D_{orig}$) should be somewhere in either tail of the null-hypothesis distribution we just estimated, $D_i'$ - i.e. $D_{orig}$ should be an "extreme" value.  How can we test this beyond a visual inspection?

First, we have to decide on a false positive (Type I error) rate which is the rate at which we will falsely reject $H_0$ when it is true.  This rate is referred to by the Greek letter $\alpha$ ("alpha").  Let's just use the conventional level used in Psychology: $\alpha = .05$.

So the question we must ask is, if the null hypothesis was true, what would be the probability of getting a difference in means as extreme as the one we observed in the original data? We will label this `p` for probability.  

<span style="font-size: 22px; font-weight: bold; color: var(--pink);">Group Discussion Point</span>

Take a few moments as a group to see if you can figure out how you might compute `p` from the data before we show you how. We will then show you the process in the next few, final, steps.

5.1.  Replace the `NULL`s in the code below to create a logical vector which states TRUE for all values of `nhd` greater than or equal to `d_orig` regardless of sign. 

* **Note:** A logical vector is one that returns TRUE when the expression is true and FALSE when the expression is false. 
* **Hint:** You have two `NULL`s to replace and two "things" to replace them with - `d_orig` or `nhd`.
* **Hint:** You want `lvec` to show every where that the values in `nhd` are greater than or equal to the `d_orig` value.

```{r lvec_example, include=TRUE, eval = FALSE}
lvec <- abs(NULL) >= abs(NULL)
```

`r hide("Portfolio Point - abs and the case of one or two tails")`
```{block, type ="info"}
In the code above, the function `abs()` says to ignore the sign and use the absolute value. For instance, if `d_orig = -7`, then `abs(d_orig) = 7`. Why do we do this here? Can you think why you want to know how extreme your value is in this distribution regardless of whether the value is positive or negative?

The answer relates to whether you are testing in one or two tails of your distribution; the positive side, the negative side, or both. You will have heard in your lectures of one or two-tailed tests. Most people would say to run two-tailed tests. This means looking at the negative and positive tails of the distribution to see if our original value is extreme, and the simplest way to do this is to ignore the sign of the values and treat both sides equally. If you wanted to only test one-tail, say that your value is extreme to the negative side of the tail, then you would not use the `abs()` and set the expression to make sure you only find values less than your original value. To test only on the positive side of the distribution, make sure you only get values higher than the original. But for now we will mostly look at two-tailed tests.
```
`r unhide()`
<br>

5.2.  Replace the NULL in the code below to `sum()` the `lvec` vector to get the total number of values equal to or greater than our original difference, `d_orig`. Fortunately, R is fine with summing TRUEs and FALSEs so you do not have to convert the data at all.

* **Hint:** This step is easier than you think. `sum(...)`

```{r n_exceeding_example, include=TRUE, eval = FALSE}
n_exceeding_orig <- NULL
```

5.3.  Replace the NULL in the code below to calculate the probability of finding a value of `d_orig` in our `nhd` distribution by dividing `n_exceeding_orig`, the number of values greater than or equal to your original value, by the `length()` of your whole distribution `nhd`. **Note: the length of `nhd` is the same as the number of replications we ran. Using code reduces the chance of human error.**

* **Hint:** We saw the `length()` function in the PreClass Activity Skill 1.

```{r p_example, include=TRUE, eval = FALSE}
p <- NULL
```

5.4.  Finally, complete the sentence below determining if the original value was extreme or not in regards to the distribution. Use inline coding, shown in Chapter 1, to replace the `XXX`s. For example, if you were to write, `r backtick("r length(nhd)")`, when knitted would appear as 1000.

**" The difference between Group A and Group B (M = `XXX`) was found to be have a probability of p = `XXX`. This means that the original mean difference was ...... and the null hypothesis is ....." **

<span style="font-size: 22px; font-weight: bold; color: var(--blue);">Job Done - Activity Complete!</span>

Well done in completing this lab. Let's recap before finishing. We had two groups, A and B, that we had tested in an experiment. We calculated the mean difference between A and B and wanted to know if this was a significant difference. To test this, we created a distribution of possible differences between A and B using the premise of permutation tests and then found the probability of our original value in that permuted distribution. The more extreme the value in a distribution, the more likely that the difference is significant. And that is exactly what we found, $p < .05$. Next time we will look at using functions and inferential tests to perform this analysis but by understanding the above you now know how probability is determined and have a very good understanding of null-hypothesis significance testing (NHST); one of the main analytical approaches in Psychology.

You should now be ready to complete the Homework Assignment for this lab. **The assignment for this Lab is summative and should be submitted through the Moodle Level 2 Assignment Submission Page no later than 1 minute before your next lab.** If you have any questions, please post them on the available forums or ask a member of staff. Finally, don't forget to add any useful information to your Portfolio before you leave it too long and forget.
