## InClass Activity

Hopefully you now have a decent understanding at least of the four APES that need to be considered when designing a study: $\alpha$, $power$, effect size and sample size. We are going to look more at calculating and understanding these elements today. You don't have to fully understand everything about power to complete this chapter - believe us when we say many seasoned researchers struggle with parts - you just need to get the general gist that there is always a level of acceptable error in hypothesis testing and we are trying to minimise that for a given effect size (i.e. the magnitude of the difference, relationship, association). 

So let's jump into this a bit now and start running some analyses to help further our understanding of alpha, power, effect sizes and sample size! To help our understanding we will focus on t-tests for this chapter which you will know well from previous chapters. 

**Effect Sizes - Cohen's $d$**

There are a number of different "effect sizes" that you can choose to calculate but a common one for t-tests is **Cohen's d**: the standardised difference between two means (in units of SD) and is written as d = effect-size-value. The key point is that Cohen's d is a standardised difference, meaning that it can be used to compare against other studies regardless of how the measurement was made. Take for example height differences in men and women which is estimated at about 5 inches (12.7 cm). That in itself is an effect size, but it is an unstandardised effect size in that for every sample that you test, that difference is dependent on the measurement tools, the measurement scale, and the errors contained within them (Note: ask Helena about the time she photocopied some rulers). As such using a standardised effect size allows you to make comparisons across studies regardless of measurement error. In standardised terms, the height difference above is considered a medium effect size (d = .5) which Cohen (1988, as cited by Schafer and Schwarz (2019)) defined as representing "an effect likely to be visible to the naked eye of a careful observer". Cohen (1988) in fact stated three sizes of Cohen's d that people could use as a guide:

<br>

|Effect size|Cohen's d value|
|:--:|:---:|
|small| .2 to .5|
|medium| .5 to .8|
|large| > .8|

<br>

You may wish to read this paper later about different effect sizes in psychology - <a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2019.00813/full" target = "_blank">Schafer and Schwarz (2019) The Meaningfulness of Effect Sizes in Psychological Research: Differences Between Sub-Disciplines and the Impact of Potential Biases</a>.

One thing to note is that the formula for Cohen's d is slightly different depending on the type of t-test used. And even within a type of t-test the formula can sometimes change depending on who you read. For today, and this chapter, let's go with the following formulas:

* One-sample t-test & within-subjects (paired-sample) t-test:  

$$d = \frac{t}{sqrt(N)}$$

* Between-subjects (Independent) t-test: 

$$d = \frac{2t}{sqrt(df)}$$

Let's now try using these formulas in order to calculate the effect sizes for given scenarios; we will work up to calculating power later in the chapter.

### Task 1: Effect size from a one-sample t-test {#Ch8InClassQueT1}

* You run a one-sample t-test and discover a significant effect, t(25) = 3.24, p = .003. Calculate `d` and determine whether the effect size is small, medium or large.

`r hide("Helpful Hint")`
```{block, type ="info"}
* Use the appropriate formula from above for the one-sample t-tests. 
* You have been given a t-value and df (degrees of freedom), you still need to determine `n` before you calculate `d`. 
* According to Cohen (1988), the effect size is small (.2 to .5), medium (.5 to .8) or large (> .8).
```
`r unhide()`  
<br>

<span style="font-size: 22px; font-weight: bold; color: var(--green);">Quickfire Questions</span>  

Answer the following questions to check your answers. The solutions are at the end of the chapter:

* Enter, in digits, how many people were run in this study: `r fitb("26", ignore_ws = TRUE)`
* Which of these codes is the appropriate calculation of `d` in this instance:`r mcq(c(answer = "d = t/sqrt(N)","d = 2t/sqrt(df)"))`
* Enter the correct value of `d` for this analysis rounded to 2 decimal places: `r fitb(c("0.64", ".64"), ignore_ws = TRUE)`
* According to Cohen (1988), the effect size for this t-test would be considered: `r mcq(c("small", answer = "medium", "large"))`   

### Task 2: Effect size from between-subjects t-test {#Ch8InClassQueT2}

* You run a between-subjects t-test and discover a significant effect, t(30) = 2.9, p = .007. Calculate `d` and determine whether the effect size is small, medium or large.

`r hide("Helpful Hint")`
```{block, type ="info"}
* Use the appropriate formula above for between-subjects t-tests. 
* remember that df = (N-1) + (N-1) for a between-subjects t-test.
* According to Cohen (1988), the effect size is small (.2 to .5), medium (.5 to .8) or large (> .8).
```
`r unhide()`  
<br>

<span style="font-size: 22px; font-weight: bold; color: var(--green);">Quickfire Questions</span>  

Answer the following questions to check your answers. The solutions are at the end of the chapter:

* Enter, in digits, how many people were run in this study: `r fitb("32", ignore_ws = TRUE)`
* Which of these codes is the appropriate calculation of `d` in this instance:`r mcq(c("d = t/sqrt(N)",answer = "d = 2t/sqrt(df)"))`
* Enter the correct value of `d` for this analysis rounded to 2 decimal places:  `r fitb(c("1.06"), ignore_ws = TRUE)`
* According to Cohen (1988), the effect size for this t-test would be considered: `r mcq(c("small", "medium", answer = "large"))`

### Task 3: Effect Size from matched-pairs t-test {#Ch8InClassQueT3}

* You run a matched-pairs t-test between an ASD sample and a non-ASD sample and discover a significant effect t(39) = 2.1, p < .05. How many people are there in each group? Calculate `d` and determine whether the effect size is small, medium or large.

`r hide("Helpful Hint")`
```{block, type ="info"}
* You need the df value to determine `N`.
* A matched pairs is treated like a paired-sample t-test but with two separate groups.
```
`r unhide()`  
<br>

<span style="font-size: 22px; font-weight: bold; color: var(--green);">Quickfire Questions</span>  

Answer the following questions to check your answers. The solutions are at the end of the chapter:

* Enter, in digits, how many people were in each group in this study. Note, not the total number of participants: `r fitb("40", ignore_ws = TRUE)`
* Which of these codes is the appropriate calculation of `d` in this instance:`r mcq(c(answer = "d = t/sqrt(N)","d = 2t/sqrt(df)"))`
* Enter the correct value of `d` for this analysis rounded to 2 decimal places: `r fitb(c("0.33", ".33"), ignore_ws = TRUE)`
* According to Cohen (1988), the effect size for this t-test would be considered: `r mcq(c(answer = "small", "medium", "large"))`

`r hide("Explain This - I don't understand the number of people in each group answer!")`
```{block, type ="info"}
* df in a paired-samples and in a matched-pairs t-test is calculated as `df = N - 1`.  
* Conversely, to find the total number of participants: `N = df + 1` so N = 39 + 1 = 40. 
* Given that this is a matched-pairs t-test, by design there has to be an equal number of participants in each group. Therefore 40 participants in each group. 
```
`r unhide()`  

### Task 4: t-value and effect size for a between-subjects Experiment {#Ch8InClassQueT4}

* You run a between-subjects design study and the descriptives tell you: **Group 1**, M = 10, SD = 1.3, n = 30; **Group 2**, M = 11, SD = 1.7, n = 30. Calculate `t` and `d` for this between-subjects experiment.

`r hide("Helpful Hint")`
```{block, type ="info"}  
* Before you can calculate `d` (using the appropriate formula for a between-subjects experiment), you need to first calculate `t` using the formula:  

`t = (Mean1 - Mean2)/sqrt((var1/n1) + (var2/n2))`

* `var` stands for variance in the above formula. Variance is not the same as the standard deviation, right? Variance is measured in squared units. So for this equation, if you require variance to calculate `t` and you have the standard deviation, then you need to remember that $var = SD^2$ (otherwise written as $var = SD \times SD$.
* Now you have your t-value, but for calculating `d` you also need degrees of freedom. Think about how you would calculate `df` for a between-subjects experiment, taking `n` for both Group 1 and Group 2 into account.
* Remember that convention is that people report the `t` as a positive. As such, convention also dictates that `d` is reported as a positive value.
```
`r unhide()`   
<br>

<span style="font-size: 22px; font-weight: bold; color: var(--green);">Quickfire Questions</span>  

Answer the following questions to check your answers. The solutions are at the end of the chapter:

* Enter the correct `t-value` for this test, rounded to two decimal places: `r fitb(c("2.56","-2.56"))`
* Which of these codes is the appropriate calculation of `d` in this instance:`r mcq(c("d = t/sqrt(N)",answer = "d = 2t/sqrt(df)"))`
* Based on the above t-value above, enter the correct value of `d` for this analysis rounded to 2 decimal places: `r fitb(c(".67", "0.67", "-0.67", "-.67"))`
* According to Cohen (1988), the effect size for this t-test would be described as: `r mcq(c("small", answer = "medium", "large"))`

**Excellent!** Now that you are comfortable with calculating effect sizes, we will look at using them to establish the sample size for a required power. One thing you will realise as we progress is that the true effect size in a population is something we do not know, but we need to justify one for our design. A clever approach is laid out by Daniel Lakens in the blog from the PreClass on the Smallest Effect Size of Interest (SESOI) - you set the smallest effect that you would be interested in! This can be determined through theoretical analysis, through previous studies, through pilot studies, or through rules of thumb like Cohen (1988). However, also keep in mind that the lower the effect size, the larger the sample size you will need. Everything is a trade-off.

**Power Calculations**

Today we are going to use the function `pwr.t.test()` to run our calculations from the **`pwr`** library. This is a really useful library of functions for various tests but we will just use it for t-tests right now. If you are using the Boyd Orr machines the `pwr` package is already installed and you will just need to call it like all other packages, e.g. `library(pwr)`. Do not attempt to install it yourself on the Boyd Orr machines. If you are using your own laptop then feel free to install it.  

Remember that for more information on the function `pwr.t.test()`, simply do `?pwr.t.test` in the console. Or you can have a look at these webpages to get in idea (or bad ideas if you spot where they erroneously calculate post-hoc power!):

* A quick-R summary of the **`pwr`** package - <a href= "https://www.statmethods.net/stats/power.html" target = "_blank">https://www.statmethods.net/stats/power.html</a>
* the **`pwr`** package vignette - <a href = "https://cran.r-project.org/web/packages/pwr/vignettes/pwr-vignette.html" target = "_blank"> https://cran.r-project.org/web/packages/pwr/vignettes/pwr-vignette.html</a>

From these you will see that `pwr.t.test()` takes a series of inputs:

* **n** - observations/participants, **per group** for the independent samples version, or the **number of subjects or matched pairs** for the paired and one-sample designs.
* **d** - the effect size of interest
* **sig.level** or $\alpha$
* **power** or $1-\beta$
* **type** - the type of t-test; e.g. `"two.sample", "one.sample", "paired"`
* **alternative** - the type of hypothesis; `"two.sided", "one.sided"`

And it works on a leave one out principle. You give it all the info you have and it returns the element you are missing.  So, for example, say you needed to know how many people per group you would need to detect an effect size as low as `d = .4` with `power = .8`, `alpha = .05` in a `two.sample (between-subjects) t-test` on a `two.sided` hypothesis test.  You would do:

```{r pwr_example_out-1, echo=FALSE, message=FALSE}
n_test1 <- pwr.t.test(d = .4, 
                      power = .8,
                      sig.level = .05,
                      alternative = "two.sided",
                      type = "two.sample") %>%
  pluck("n")
```

```{r pwr_example, eval=FALSE}
pwr.t.test(d = .4,
           power = .8,
           sig.level = .05,
           alternative = "two.sided",
           type = "two.sample")
```

Which will show you the following output, which, if you look at it, tells you that you need `r n_test1` people per condition. 

```{r pwr_example-show, echo = FALSE}
pwr.t.test(d = .4,
           power = .8,
           sig.level = .05,
           alternative = "two.sided",
           type = "two.sample")
```


But you only get whole people and we like to be conservative on our estimates so we would actually run `r ceiling(n_test1)` **per condition**. That is a lot of people!!!

One problem though is that the output of the `pwr.t.test()` is an object and not that easy to work with in terms of getting values out from it to be reproducible. However, we have already seen a function in Chapter 5 that we can use to pluck values from objects - `purr::pluck()`. And the code would look like this

```{r pwr_example_out-2, message=FALSE}
n_test <- pwr.t.test(d = .4, 
                     power = .8,
                     sig.level = .05,
                     alternative = "two.sided",
                     type = "two.sample") %>%
  pluck("n")
```

So when we call `n_test` we get the same answer as above, but it is saved as a single value and easier to work with:

```{r pwr-show-n}
n_test
```

And we could use the `ceiling()` funtion to round up to whole people:

```{r pwr-show-n-ceiling}
n_test %>% ceiling()
```

**Note:** `ceiling()` is better to use than `round()` when dealing with people as it always rounds up. For example, `ceiling(1.1)` gives you `r ceiling(1.1)`. `round()` on the other hand is useful for rounding an effect size, for example, to two decimal places - e.g. d = `round(.4356, 2)` would give you d = `r round(.4356, 2)`

We will use this approach `pwr.t.test() %>% pluck()` and `pwr.t.test() %>% pluck() %>% ceiling()` throughout the rest of this chapter to get used to it. **But before you start with this next task**, you will need to make sure you have loaded in the `tidyverse`.

### Task 5: Sample size for standard power one-sample t-test {#Ch8InClassQueT5}

* Assuming the smallest effect size of interest is a Cohen's d of **d = .23**, what would be the minimum number of participants you would need in a one-sample t-test, assuming **$power = .8$**, **$\alpha = .05$**, on a two-sided hypothesis? 

```{r hidden-1, include = FALSE}
.n_onesamp <- pwr.t.test(d = .23, 
                         power = .8, 
                         sig.level = .05, 
                         alternative = "two.sided", 
                         type = "one.sample") %>%
  pluck("n") %>%
  ceiling()
```

Using a pipeline, store the answer as a single value called `sample_size` (e.g. think `pluck()`) and round up to the nearest whole participant. 

`r hide("Helpful Hint")`
```{block, type ="info"}
* Use the list of inputs above as a kind of checklist to clearly determine which inputs are known or unknown. This can help you enter the appropriate values to your code.
* The structure of the `pwr.t.test()` would be very similar to the one shown above except two.sample would become one.sample
* You will also need to use `pluck("n")` to help you obtain the sample size and `%>% ceiling()` to round up to the nearest whole participant.
```
`r unhide()`  
<br>

<span style="font-size: 22px; font-weight: bold; color: var(--green);">Quickfire Questions</span>  

Answer the following question to check your answers. The solutions are at the end of the chapter to check against:

* Enter the minimum number of participants you would need in this one-sample t-test: `r fitb(.n_onesamp, num = TRUE)`

### Task 6: Effect size from a high power between-subjects t-test {#Ch8InClassQueT6}

* Assuming you run a between-subjects t-test with 50 participants per group and want a power of .9, what would be the minimum effect size you can reliably detect? Assume the field standard $\alpha = .05$ and alternative hypothesis settings ("two-tailed"). Using a pipeline, store the answer as a single value called `cohens` and round to two decimal places.

```{r hidden-2, include = FALSE}
.esize <- pwr.t.test(50L, sig.level = .05, power = .9) %>%
  pluck("d") %>%
  webexercises::round2(2)
```

`r hide("Helpful Hint")`
```{block, type ="info"}
* Again, use the list of inputs above as a kind of checklist to clearly determine which inputs are known or unknown. This can help you enter the values to your code. 
* You will also need to use `pluck()` to obtain Cohen's `d`, and `round()` so the value is rounded to two decimal places.
* Don't forget the quotes when using `pluck()`. i.e. `pluck("value")` and not `pluck(value)`
```
`r unhide()`  
<br>

<span style="font-size: 22px; font-weight: bold; color: var(--green);">Quickfire Questions</span>  

Answer the following questions to check your answers. The solutions are at the end of the chapter:

* Based on the information given, what will you set `type` as in the function? `r mcq(c("one.sample", answer = "two.sample"))`
* Based on the output, enter the minimum effect size you can reliably detect in this test, rounded to two decimal places: `r fitb(.esize, num = TRUE, ignore_ws = TRUE)`
* According to Cohen (1988), the effect size for this t-test is `r mcq(c("small", answer = "medium", "large"))`
* Say you run the study and find that the effect size determined is d = .50. Given what you know about power, select the statement that is most accurate: `r mcq(c("the study is sufficiently powered as the analysis indicates you can only reliably detect effect sizes smaller than d = .65",answer = "the study is potentially underpowered as the analysis indicates you can really only reliably detect effect sizes larger than d = .65"))`

### Task 7: Power of Published Research {#Ch8InClassQueT7}

Thus far we have used hypothetical situations - now go look at the paper on the Open Stats lab website called <a href="https://sites.trinity.edu/osl/data-sets-and-activities/t-test-activities" target = "_blank">Does Music Convey Social Information to Infants?</a>. You can download the pdf and look at it, but here we will determine the power of the significant t-tests reported in Experiment 1 under the Results section on Pg489. There is a one-sample t-test and a paired-samples t-test to consider, summarised below. Assume testing was at power = .8, alpha = .05. Based on your calculations are either of the stated effects underpowered?

1. one-sample: t(31) = 2.96, p = .006
2. paired t-test: t(31) = 2.42, p = .022

`r hide("Helpful Hint")`
```{block, type ="info"}
* A one-sample t-test and a paired t-test use the same formula for Cohen's d.
* To calculate n: `n = df + 1`.
* Calculate the achievable Cohens d for the studies and then calculate the established Cohen's d for the studies. 
```
`r unhide()`
<br>
<span style="font-size: 22px; font-weight: bold; color: var(--pink);">Group Discussion Point</span>

Based on what you have found out, think about the following questions and discuss them in your groups:

* Which of the t-tests do you believe to be potentially underpowered? 
* Why do you think this may be? 

Additional information about this discussion can be found in the solutions at the end of this chapter.

**One caveat to Tasks 6 and 7:** We have to keep in mind that here we are looking at single studies using one sample from a potentially huge number of samples within a population. As such there will be a degree of variance in the true effect size within the population regardless of the effect size of one given sample. What that means is we have to be a little bit cautious when making claims about a study. Ultimately the higher the power the better as you can detect smaller effect sizes!

<span style="font-size: 22px; font-weight: bold; color: var(--blue);">Job Done - Activity Complete!</span>

**Great!** So hopefully you are now starting to see the interaction between alpha, power, effect sizes, and sample size. We should always want high powered studies and depending on the size of the effect we are interested in (small to large), and our $\alpha$ level, this will determine the number of observations we need to make sure our study is well powered. Points to note:

* Lowering the $\alpha$ level (e.g. .05 to .01) will reduce the power.
* Lowering the effect size (e.g. .8 to .2) will reduce the power.
* Increasing power (.8 to .9) will require more participants.
* It is also possible to increase power for a fixed sample size by reducing sources of noise in the study.

A high-powered study looking to detect a small effect size at a low alpha may require a large number of participants!

Another point probably to consider for the future: what about studies with multiple observations per participant? How do you calculate power for this? This is a **very** common situation.

You should now be ready to complete the Homework Assignment for this lab. **The assignment for this Lab is FORMATIVE and is NOT to be submitted and will NOT count towards the overall grade for this module.** However, you are strongly encouraged to do the assignment as it will continue to boost your skills which you will need in future assignments. If you have any questions, please post them on the forums!
