## PreClass Activity

```{r lab2-preclass-data, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}
pong_data <- read_csv("./data/02-s01/preclass/PongBlueRedBack 1-16 Codebook.csv")
``` 

**Revisiting Tabular Data**

From working with data previously you know that nearly all data in research methods is stored in two-dimensional tables, either called data-frames, tables or tibbles. There are other ways of storing data that you will discover in time but mainly we will be using tibbles (if you like more info, type `vignette("tibble")` in the Console Window). A tibble is really just a table of data with columns and rows of information, and within the tibble you can get different `r glossary("data type", display = "types of data")`, i.e. `r glossary("double")`, `r glossary("integer")`, and `r glossary("character")`.

|Type of Data     | Description                                                  |
|:------------|:-------------------------------------------------------------| 
|Double     | Numbers including decimals (e.g. 3.14) |
|Integer     | Numbers without decimals  (e.g. 3)|
|Character     | Tends to contain letters or be words, but can be numbers (e.g. "AB12", "Data Rocks!")                       |

* **Note:** Double and Integer can both be referred to as Numeric data, and you will see this word from time to time. For clarity, we will use Double as a term for any number with a decimal (e.g. 3.14) and Integer as a term for any whole number (no decimal, e.g. 3).

<span style="font-size: 22px; font-weight: bold; color: var(--green);">Quickfire Questions</span>

What type of data would these most likely be:

* Male = `r mcq(c(answer = "Character","Double","Integer"))`

* 7.15 = `r mcq(c("Character",answer = "Double","Integer"))`

* 137 = `r mcq(c("Character","Double",answer = "Integer"))`

`r hide("Portfolio Point - Data types and levels of measurement")`
```{block, type ="info"}
There are lots of different types of data as well as different levels of measurements and it can get very confusing. It's important to try to remember which is which because you can only do certain types of analyses on certain types of data and certain types of measurements. For instance, you can't take the average of characters just like you can't take the average of categorical data. Likewise, you can do any maths on double and integer data, just like you can on interval and ratio data. Integer data is funny in that sometimes it is ordinal and sometimes it is interval, sometimes you should take the median, sometimes you should take the mean. 

The main point is to always know what type of data you are using and to think about what you can and cannot do with them.
```
`r unhide()`

### Revisiting the Wickham Six

The main way we teach data-wrangling skills is by using the Wickham Six one-table verbs. These are part of the `tidyverse` package which we introduced to you in the first PsyTeachR book, and more specifically from the `dplyr` package that is contained within the `tidyverse`. These six verbs are often referred to as the Wickham Six "one-table" dplyr verbs as they perform actions on a single table of data.

We will look at some of the basics again here but try to look back at the exercises in the <a href="https://psyteachr.github.io/" target = "_blank">Grassroots book</a> to see how we used these verbs (functions) previously. The Wickham Six are: 

|Function     | Description                                                  |
|:------------|:-------------------------------------------------------------| 
|select()     | Include or exclude certain variables (columns)             |
|filter()     | Include or exclude certain observations/data (rows)             |
|mutate()     | Creates new variables (columns)                              |
|arrange()    | Changes the order of observations (rows)                     |
|group_by()   | Organises the observations (rows) into groups                |
|summarise()  | Create summary variables for groups of observations (rows)  |

<br>
`r hide("Portfolio Point - The Wickham Six")`
```{block, type = "info"}
You will use the Wickham Six very frequently for wrangling your data so this would definitely be something you should be making notes about - not just the names, but how they work and any particular nuances that you spot. Perhaps recreate the above table and add your own examples.
```
`r unhide()` 

### Learning to Wrangle: Is there a Chastity Belt on Perception

Today we are going to be using data from this recent paper: [Is there a Chastity Belt on Perception](http://journals.sagepub.com/doi/abs/10.1177/0956797617730892). You can read the full paper if you like, it is a nice representation of action/perception/cogntion working together, but we will summarise the paper for you. The main research question asks, **does your ability to perform an action influence your perception?** For instance, does your ability to hit a tennis ball influence how fast you perceive the ball to be moving? Or to phrase another way, do expert tennis players perceive the tennis ball moving slower than novice tennis players?  

This experiment does not use tennis players however, they used the Pong task: "a computerised game in which participants aim to block moving balls with various sizes of paddles". A bit like a very classic retro arcade game. Participants tend to estimate the balls as moving faster when they have to block it with a smaller paddle as opposed to when they have a bigger paddle. You can read the paper to get more details if you wish but hopefully that gives enough of an idea to help you understand the wrangling we will do on the data. We have cleaned up the data a little to start with. Let's begin!

1. [Download the data as a zip file from this link](data/02-s01/preclass/ch2-preclass-data.zip) and save it somewhere you have access. In the lab, use your `M:` drive.

2. Set your working directory to the same folder as the data. `Session >> Set Working Directory >> Choose Directory`

3. Open a new script and copy and paste the two lines below. Here we are:
    a. loading the `tidyverse` library into our session and then 
    b. loading in the data through the `read_csv()` function and storing it in the tibble called `pong_data`.

``` {r libraries, eval = FALSE, message = FALSE, warning = FALSE}
library("tidyverse")
pong_data <- read_csv("PongBlueRedBack 1-16 Codebook.csv")
``` 
<br>
```{block, type = "danger"}

**DO NOT install packages in the Boyd Orr labs; they are already there and just need called in through `library()`.** 

However, If you are using your own computer and you haven't previously installed the `tidyverse` package before, you will have to install it first, e.g. `install.packages("tidyverse")`.

If you have already installed `tidyverse` but it was a long time ago, it might be worth running some updates on the packages as you may have an old version that works differently. The easiest way to do this is through RStudio using the menu at the top - `Tools >> Check for Package Updates`. You can update packages individually or just run all updates. Tends to be better to just update all packages as many of the packages are linked, unless you specifically don't want to update a certain package.

```
<br>
`r hide("Help my data is not loading?")`
```{block, type = "info"}
The three most common mistakes we see are:

1. Make sure you have spelt the data file name **exactly** as it is shown. Spaces and everything. Do not change the name of the csv file, fix your code instead. The reason being is that if you have a different name for your file than someone else then your code is not reproducible. We would say avoid using spaces in filenames you create, but as this is one created by another researcher and already has them, we will leave it as is and work with them.
2. Remember when uploading data we use `read_csv` which has an underscore, whereas the data file itself will have a dot in its name, `filename.csv`. 
3. Check that the datafile is actually in the folder you have set as your working directory. 
```
`r unhide()`  
<br>

4. Let's have a look at the `pong_data` and see how it is organized. Type `View(pong_data)` or `glimpse(pong_data)` in your Console window. Capital V and little g.

In the dataset you will see that each row (observation) represents one trial per participant and that there were 288 trials for each of the 16 participants. The columns (variables) we have in the dataset are as follows:

| Variable       |       Type         |           Description               |
|:--------------:|:-------------------|:------------------------------------|
| Participant        | integer            | participant number                  |
| JudgedSpeed   | integer            | speed judgement (1 = fast, 0 = slow)    |
| PaddleLength         | integer            | paddle length (pixels)              |
| BallSpeed          | integer            | ball speed (2 pixels/4ms)          |
| TrialNumber         | integer            | trial number                        |
| BackgroundColor      | character          | background display colour           |
| HitOrMiss         | integer            | hit ball = 1, missed ball = 0       |
| BlockNumber  | integer            | block number (out of 12 blocks)     |

We will use this data to master our skills of the Wickham Six verbs, taking each verb in turn and looking at it briefly. You should develop your skills by setting yourself new challenges based on the ones we set. There are **6 verbs to work through** and then after that we will briefly recap on two other functions before finishing with a quick look at pipes. Try everything out and let us know anything you can't quite get.

### The **`select()`** Function - to keep only specific columns {#Ch2PreClassQueT1}

The `select()` function lets us pick out the variables within a dataset that we want to work with. For example, say in `pong_data` we wanted to only keep the columns `Participant`, `JudgedSpeed`, `PaddleLength`, `BallSpeed`, `TrialNumber`, and `HitOrMiss` but we don't need `BackgroundColor` or `BlockNumber`. We can do this in two ways:

1. We can tell the function what variables we want to include 

``` {r selectdata1, eval = FALSE}
select(pong_data, Participant, JudgedSpeed, PaddleLength, BallSpeed, TrialNumber, HitOrMiss)
```

2. Or we can do it the opposite way by excluding columns through `-ColumnName` approach (i.e. minus the ColumnName)

``` {r selectdata2, eval = FALSE}
select(pong_data, -BackgroundColor, -BlockNumber)
```


In this latter example, `-BackgroundColor` means 'not BackgroundColor', so here you are saying all columns except `BackgroundColor` and `BlockNumber`. The minus sign is the crucial part!
<br>

**Task 1: Using the `select()` function**

1. Either by inclusion or exclusion, select only the columns `Participant`, `PaddleLength`, `TrialNumber`, `BackgroundColor` and `HitOrMiss` from `pong_data`.  

Did you know `select()` can also be used to reorder columns? 

2. Use `select()` to keep only the columns `Participant`, `JudgedSpeed`, `BallSpeed`, `TrialNumber`, and `HitOrMiss` but have them display in alphabetical order, left to right.

`r hide("Helpful Hint - selecting")`
```{block, type = "info"}

1. Have you remembered to include the dataset `pong_data`? Pay attention to upper/lower case letters and spelling!

2. Think about how you first entered the column names as they appeared. But what happens if you change the order that you enter the column names? 
```
`r unhide()`  

### The **`arrange()`** Function - to sort and arrange columns {#Ch2PreClassQueT2}

The `arrange()` function sorts the rows in the tibble according to what column you tell it to sort by. 

* In this example we show how to the data arrange by one column e.g. by `BallSpeed`

```{r arrangedata-1, eval = FALSE}
arrange(pong_data, BallSpeed)
```

* Or by multiple columns e.g. by `BallSpeed` (fastest first) and `BackgroundColor`

```{r arrangedata-2, eval = FALSE}
arrange(pong_data, desc(BallSpeed), BackgroundColor)
```

`r hide("Explain this - where did desc come from?")`
```{block, type = "info"}

* What does `desc()` do? 
    * `desc()` is how to sort by largest to smallest - i.e. descending order.
    * Compare the output of the two lines above on the `BallSpeed` column. 
    * Does `desc()` also work for `BackgroundColor`?
```
`r unhide()`  
<br>

**Task 2: Arranging Data with the `arrange()` function**

1. Arrange the data in `pong_data` by two variables: `HitOrMiss` (putting hits - 1 - first), and `JudgedSpeed` (fast judgement - 1 - first).  

### The **`filter()`** Function - to keep only parts of the data {#Ch2PreClassQueT3}

The `filter()` function lets us parse out a subset of the data, meaning we keep only parts of the data.

* For example, we might want to only keep the red `BackgroundColor`

```{r filterdata1-1, eval= FALSE}  
filter(pong_data, BackgroundColor == "red")
```

* or only keep `BallSpeed` above 4 pixels

```{r filterdata1-2, eval= FALSE}  
filter(pong_data, BallSpeed > 4)
```

* or only keep trials that match both the red `BackgroundColor` and `BallSpeed` above 4 pixels. Any trial that is not red background color or slower than 5 pixels will be removed.

```{r filterdata1-3, eval= FALSE}  
filter(pong_data, BackgroundColor == "red", BallSpeed > 4)
```

* This last example can also be written as follows. Two arguements or requirements separated by a comma is equivalent to an & (ampersand - meaning "and").

```{r filterdata1-4, eval= FALSE}  
filter(pong_data, BackgroundColor == "red" & BallSpeed > 4)
```

* Or say you want to keep specific Participant IDs. Say we want just the data from Participants 1, 3, 10, 14 and 16. We would write it as follows.
    * The `%in%` is called `group membership` and means keep each of these Participants
    * The `c()` creates a little container of items called a vector. 
    
```{r filterdata1-5, eval= FALSE}  
filter(pong_data, Participant %in% c("1", "3", "10", "14", "16")) 
```

* And finally, say you wanted to keep all Participants except Participant 7. Say the experiment didn't work for them and you want to remove them. You would write:
    * you can read `!=` (exclamation mark followed by equals) as 'does not equal'. So `Participant != "7"` means keep all Participants where the values in `Participant` column are not 7. 
    * The exclamation mark can sometimes be used to negate the function that follows it.

```{r filterdata1-6, eval= FALSE}  
filter(pong_data, Participant != "7")
```  

**Task 3: Using the `filter()` Function**

1. Use `filter()` to extract all Participants that had a fast speed judgement, for speeds 2, 4, 5, and 7, but missed the ball. Store this remaining data in a variable called `pong_fast_miss`

`r hide("Helpful Hint")`
```{block, type = "info"}
There are three parts to this filter so it is best to think about them individually and then combine them.

1. Filter all fast speed judgements (`JudgedSpeed`)

2. Filter for the speeds 2, 4, 5 and 7 (`BallSpeed`)

3. Filter for all Misses (`HitOrMiss`)

You could do this in three filters where each one uses the output of the preceeding one, or remember that filter functions can take more than one arguement - see the example above. Also, because the `JudgedSpeed` and `HitOrMiss` are Integer you will need `==` instead of just `=`.
```
`r unhide()`
<br>

* **And not Or. Mistakes with `filter()`**

The filter function is very useful but if used wrongly can give you very misleading findings. This is why it is very important to always check your data after you perform an action. Let's say you are working in comparative psychology and have run a study looking at how cats, dogs and horses perceive emotion. Let's say the data is all stored in the tibble `animal_data` and there is a column called `animals` that tells you what type of animal your participant was. Something like this:

|Participant ID|animals|Perceived Emotion Accuracy (%)|
|:------------:|:-----:|:----------------------------:|
|1             |dog    |80                            |
|2             |dog    |90                            | 
|3             |cat    |10                            |
|4             |dog    |85                            |
|5             |horse  |100                           |
|6             |cat    |6                             |

Ok, so imagine you wanted all the data from just cats

`filter(animal_data, animals == "cat")`

Exactly! But what if you wanted cats and dogs?

`filter(animal_data, animals == "cat", animals == "dog")` 

Right? Wrong! This actually says "give me everything that is a cat and a dog". But nothing is a cat and a dog, that would be weird - like a dat or a cog! What you actually want is everything that is either a cat **or** a dog, which is stated as:

`filter(animal_data, animals == "cat" | animals == "dog")` 

The vertical line `|` is the symbol for **or**, just as `&` is the symbol for **and**. 

**TOP TIP:** Always pay attention to what you want and most importantly to what your code produces.

### The **`mutate()`** Function - for adding new columns {#Ch2PreClassQueT4}

The `mutate()` function lets us create a new variable in our dataset. For example, let's add a new column to `pong_data` in which the background color is represented by numbers, where `red` will be represented as 1, and `blue` will be represented as 2.

``` {r mutatedata, eval = FALSE}
pong_data <- mutate(pong_data, 
                    BackgroundColorNumeric = recode(BackgroundColor, 
                                                    "red" = 1, 
                                                    "blue" = 2))
```

The code here is is a bit complicated but:

* `BackgroundColorNumeric` is the name of the new column you are adding to the tibble, 
* `BackgroundColor` is the name of the original column in the tibble and the one to take information from,
* and 1 and 2 are the new codings of red and blue respectively.

The `mutate()` function is also handy for making some calculations on or across columns in your data. For example, say you realise you made a mistake in your experiment where your participant numbers should be 1 higher for every participant, i.e. Participant 1 should actually be numbered as Participant 2, etc. You would do something like:

``` {r mutatedata2, eval = FALSE}
mutate(pong_data, Participant = Participant + 1)
```

Note here that the "new column" has the same name as the old column, i.e. `Participant`. In the resulting table, the `Participant` column will have the new values which will differ from the values in the original `pong_data` table. While it may seem like you have overwritten these values, in reality you have created a copy of the table with altered values, but you have not lost anything: the original values are still there in `pong_data` because you didn't store (assign) this action to `pong_data`. You didn't save the change basically. 

In general however it is good practice not to overwrite `pong_data` with a new version of `pong_data`, but to store the altered table in a new tibble, e.g., `pong_data2`, like this:

``` {r mutatedata3, eval = FALSE}
pong_data_mutated <- mutate(pong_data, Participant = Participant + 1)
```

**Task 4: Mutating Variables with mutate()**

* You realise another mistake in that all your trial numbers are wrong. The first trial (trial number 1) was a practice so should be excluded. And your experiment actually started on trial 2. Tidy this up by:

1. Creating a new tibble called `pong_data_filt` and in it store data from `pong_data` after filtering out all trials with the number 1 (`TrialNumber` column). 
2. Now use the `mutate()` function to renumber all the remaining trial numbers, in `pong_data_filt`, starting them at one again instead of two. Store this output in a new tibble called `pong_data2`.

`r hide("Helpful Hint")`
```{block, type = "info"}
Step 1: 

* filter(`TrialNumber` does not equal 1). 
* remember to store this output in a tibble called `pong_data_filt`

Step 2: 

* mutate(`TrialNumber` = TrialNumber minus 1)
* exclamation mark, equals
```
`r unhide()`  

### The **`group_by()`** Function - to group parts of data altogether {#Ch2PreClassQueT5}

The `group_by()` function groups the rows in a dataset according to a category you specify, e.g. in the animals example above, grouping all cat data together and all dog data together, and all horse data together.

Looking at the data within `pong_data2`, say you wanted to eventually creating means, etc, for the different background color conditions. You would start by grouping trials by `BackgroundColor`, grouping the data into red background data and blue background data, as such: 

``` {r groupeddata-1, eval = FALSE}
group_by(pong_data2, BackgroundColor)
```

* Or you can add numerous grouping variables depending on how you want to split up the data. Here we group by Hit Or Miss (in `HitOrMiss` column), and background color (Red or Blue). This gives four grousp - Hit Red, Miss Red, Hit Blue, Miss Blue.

```{r groupeddata-2, eval = FALSE}
group_by(pong_data2, HitOrMiss, BackgroundColor)
```

**Note:** Nothing actually appears to change in the data, unlike with the other functions, but a big operation has taken place. Look at the output in your console when you run `group_by(pong_data2, BackgroundColor)`. At the top of the output notice that the 2^nd^ line of the output tells us the grouping criteria and how many groups now exist: see the line `Groups: BackgroundColor [2]`: we grouped by `BackgroundColor` and there are `[2]` groups - one for red and one for blue.  


**Task 5: Grouping Data with `group_by()`**

* Group the data by `BlockNumber` and by `BackgroundColor`, in that order, and then enter the number of groups (i.e. a number) you get as a result: `r fitb("24")`

`r hide("Helpful Hint")`
```{block, type = "info"}
It is the same procedure as this but with different column names:

`group_by(pong_data2, HitOrMiss, BackgroundColor)`

The number of groups should be between the sum (i.e. multiplication) of the number of background colors (red and blue) and the number of blocks (12).
```
`r unhide()`  
<br>

`group_by()` is incredibly useful as, once the data is organised into groups, you can then apply other functions (`filter`, `arrange`, `mutate`...etc.) to the groups within your data that you are interested in, instead of to the entire dataset. For instance, a common second step after `group_by` might be to `summarise` the data...

### The **`summarise()`** Function - to do some calculations on the data {#Ch2PreClassQueT6}

The `summarise()` function lets you calculate some descriptive statistics on your data. For example, say you want to count the number of hits there were for different paddle lengths, or number of hits there were when the background color was red or blue.

* First we group the data accordingly, storing it in `pong_data2_group`
```{r datasummary-1, eval = FALSE}
pong_data2_group <- group_by(pong_data2, BackgroundColor, PaddleLength)
```

* And then we summarise it, storing the answer in `total_hits`
```{r datasummary-2, eval = FALSE}
pong_data2_hits <- summarise(pong_data2_group, total_hits = sum(HitOrMiss))
```

* And then for fun we can filter just the red, small paddle hits from the summarised data.
```{r datasummary-3, eval = FALSE}
pong_data2_hits_red_small <- filter(pong_data2_hits, BackgroundColor == "red", PaddleLength == 50)
```

```{r lab2-preclass-hidden-1, echo=FALSE}

pong_data2 <- filter(pong_data, TrialNumber >= 2) %>%
  mutate(TrialNumber = TrialNumber - 1) %>%
  mutate(Participant = Participant + 1)

# First we group the data accordingly, storing it in `pong_data2_group`
pong_data2_group <- group_by(pong_data2, BackgroundColor, PaddleLength)

# And then we summarise it, storing the answer in `total_hits`
pong_data2_hits <- summarise(pong_data2_group, total_hits = sum(HitOrMiss))
pong_data2_hits_m <- summarise(pong_data2_group, mean_hits = mean(HitOrMiss))

# And then for fun we can filter just the red, small paddle hits
pong_data2_hits_red_small <- filter(pong_data2_hits, BackgroundColor == "red", PaddleLength == 50)
pong_data2_hits_red_small_m <- filter(pong_data2_hits_m, BackgroundColor == "red", PaddleLength == 50)
```

Which would leave us with:

```{r lab2-preclass-hidden-1-table, echo=FALSE}
knitr::kable(pong_data2_hits_red_small, align = "c", caption = "Summarising with group_by() and summarise()")
```
<br>

* The name of the column within `pong_data2_hits_red_small` that has the summarised data is `total_hits`; this is what you called it when creating `pong_data2_hits`. You could have called it anything you wanted but always try to use something sensible. Make sure to call your variables something you (and anyone looking at your code) will understand and recognize later (i.e. not variable1, variable2, variable3. etc.), and avoid spaces (use_underscores_never_spaces).

`summarise()` has a range of internal functions that make life really easy, e.g. `mean()`, `median()`, `n()`, `sum()`, `max`, `min`, etc. Some common ones are shown below but see the `dplyr` cheatsheets for more examples.

|function|example|purpose|
|:------:|:------|:------|
|n()     |N = n()|number of values| 
|mean()  |m = mean(X)|mean of values in stated column - e.g. column X|
|median()|mdn = median(X)|median of values in stated column - e.g. column X|
|sum()  |sm = sum(X)|sum of values in stated column - e.g. column X|
|max()  |mx = max(X)|max of values in stated column - e.g. column X|
|min()  |mn = min(X)|min of values in stated column - e.g. column X|
|sd()   |stdev = sd(X)|standard deviation of values in stated column - e.g. column X|


**Task 6: Summarising Data with summarise()**

* Use the lines of code above to calculate the mean number of hits made with the small paddle (50) and the red color background. Enter that value in this box to two decimal places - (e.g. 0.12): `r fitb(pong_data2_hits_red_small_m %>% pull(mean_hits) %>% round(2), num = TRUE)`

**A quick point on the `ungroup()` function**

The `ungroup()` undoes the action of the `group_by()` function. 

After grouping data together using the `group_by()` function and then peforming a task on it, e.g. `filter()`, `summarise()`, it can be very good practice to ungroup the data before performing another function. Forgetting to ungroup the dataset won't always affect further processing but sometimes it can really mess up other things. 

Again just a good reminder to always check the data you are getting out of a function a) makes sense and b) is what you expect.

<span style="font-size: 22px; font-weight: bold; color: var(--green);">Quickfire Questions</span>

* Which of the Wickham Six would I use to sort columns from smallest to largest: `r mcq(c("select","filter","mutate",answer ="arrange","group_by","summarise"))`

* Which of the Wickham Six would I use to calculate the mean of a column: `r mcq(c("select","filter","mutate","arrange","group_by",answer ="summarise"))`

* Which of the Wickham Six would I use to remove certain observations - e.g. remove all males: `r mcq(c("select",answer = "filter","mutate","arrange","group_by","summarise"))` 

### Two Other Useful Functions

The Wickham Six verbs let you to do a lot of things with data however there are thousands of other functions at your disposal. If you want to do something with your data that you are not sure how to do using these functions, do a Google search for an alternative function - chances are someone else has had the same problem and has a help guide. For example, two other functions to note are the `bind_rows()` function and the `count()` function. We will breidly show you these here.

**Binding columns with bind_rows()**

The `bind_rows()` function is useful if you want to combine two tibbles together into one larger tibble that have the same column structure - i.e. the have exactly the same columns and you want to combine them by attaching one to the bottom of the other. For example:    

* Say you had on tibble with data for ball speeds 1 and 2

```{r bindexample-1, eval = FALSE}
slow_ball<- filter(pong_data2, BallSpeed < 3) 
```

* And another tibble with data for ball speeds 6 and 7

```{r bindexample-2, eval = FALSE}
fast_ball <- filter(pong_data2, BallSpeed >= 6) 
```

* And you wanted to combine those tibbles together into one big tibble containing these extreme ball speeds.

```{r bindexample-3, eval = FALSE}
extreme_balls <- bind_rows(slow_ball, fast_ball) 
```

We are going to use `bind_rows()` throughout the labs so do keep it in mind!

**Quick counts with the `count()` function**

Finally, the `count()` function is a shortcut that can sometimes be used to count up the number of rows you have for groups in your data, without having to use the `group_by()` and `summarise()` functions. It is a tally basically. It doesn't sum up values. It just counts how many observations you have. 

For example, in Task 6 we combined `group_by()` and `summarise()` to calculate how many hits there were based on background color and paddle length. Alternatively we could have done:

``` {r countexample1, eval = FALSE}
count(pong_data2, BackgroundColor, PaddleLength, HitOrMiss)
```

The results are the same, just that in the `count()` version we get all the information, including misses, because we are just counting rows. In the `summarise()` method we only got hits because that was the effect of what we summed. So two different methods give similar answers - coding can be individualised and get the same result!

Again, we will use `count()` at various times in the labs so again it is handy to make a note of.

### Last but not least - Pipes (**`%>%`**) to make your code efficient

By now you'll have noticed that`tidyverse` functions generally take the following grammatical structure (called **syntax**): `function_name(dataset, arg1, arg2,..., argN)` where the dataset is the entire tibble of data you are using, and each argument (`arg`) is some operation on a particular column or variable, or the column name you want to work with. For example:   

```{r syntax-1, eval = FALSE}
filter(pong_data2, PaddleLength == "50", BallSpeed > 4)
```

```{r syntax-2, eval = FALSE}
group_by(pong_data2, BallSpeed, Participant)
```

Both of these examples follow the structure of `function_name(dataset, arg1, arg2, ....)`

In the first example, we are filtering (function) the whole `pong_data2` dataset by a particular paddle length, then by particular speeds (arguments). In the second, we are grouping by `BallSpeed` and then by `Participant`. Note that the order of arguments is specific as it performs argument1 then argument2, etc. Changing the order of arguments may give a different output. So the order you work in is important, and this is called your **pipeline**. For example, here is a pipeline we used above to find how many hits there were with the small paddle length and the red background.

* First we group the data accordingly, storing it in `pong_data2_group`
* And then we summarise it, storing the answer in `total_hits`
* And filter just the red, small paddle hits

```{r datasummary-nopipe, eval = FALSE}
pong_data2_group <- group_by(pong_data, BackgroundColor, PaddleLength)
pong_data2_hits <- summarise(pong_data2_group, total_hits = sum(HitOrMiss))
pong_data2_hits_red_small <- filter(pong_data2_hits, BackgroundColor == "red", PaddleLength == 50)
```

Pipelines allow us to quickly and reproducibly, perform an action that would take much longer manually. However, we can make our code even more efficient, using less code, by stringing our sequence of functions together using '**pipes**', written as `%>%`. Changing the above code into one using pipes would give us:

```{r datasummary-pipes, eval = FALSE}
pong_data_hits_red_small <- pong_data2 %>% 
  group_by(BackgroundColor, PaddleLength) %>% 
  summarise(total_hits = sum(HitOrMiss)) %>%
  filter(BackgroundColor == "red", PaddleLength == 50)
```

Both these chunks show exactly the same procedure, but adding pipes can make code easier to read and follow once you understand piping. 

Code without a pipe would look like 

* `function_name(dataset, arg1, arg2,...,argN)`

but a pipe version would look like 

* `dataset %>% function_name(arg1, arg2,...,argN)`

The premise is that you can pipe (`%>%`) between functions when the **input** of a function is the **output of the previous function**. Alternatively, you can use a pipe to put the data into the first function, as shown directly above.

You can think of the pipe (`%>%`) as saying '**and then**' or '**goes into**'. E.g. the data goes into this function and then into this function and then into this function. We will expand on this in the lab where you can ask more questions, but try comparing the two chunks of code above and see if you can match them up.

One last point on pipes is that they can be written in a single line of code but it's much easier to see what the pipe is doing if each function takes its own line. Every time you add a function to the pipeline, remember to add a `%>%` first and **note that when using separate lines for each function, the `%>%` must appear at the end of the line and not the start of the next line**. Compare the two examples below. The first won't work but the second will because the second puts the pipes at the end of the line where they need to be!

* Example 1: **won't work** because the pipes (`%>%`) are in the **wrong** place.

``` {r pipes3-1, eval = FALSE}
data_arrange <- pong_data2 
                %>% filter(PaddleLength == "50")
                %>% arrange(BallSpeed) 
```

* Example 2: **will work** because the pipes (`%>%`) are in the **correct** place.

``` {r pipes3-2, eval = FALSE}
data_arrange <- pong_data2 %>%
                filter(PaddleLength == "50") %>%
                arrange(BallSpeed) 
```


`r hide("Portfolio Point - Pipes are good for the Environment")`
```{block, type = "info"}
Where piping becomes most useful is when we **string a series of functions together**, rather than using them as separate steps and having to save the data each time under a new tibble name and getting ourselves all confused. In the non-piped version we have to create a new tibble each time, for example, `data`, `data_filtered`, `data_arranged`, `data_grouped`, `data_summarised` just to get to the final one we actually want, which was `data_summarised`.  This creates a lot of tibbles in our environment and can make everything unclear and eventually slow down our computer. The piped version however uses one tibble name, saving space in the environment, and is clear and easy to read. With pipes, we skip unnecessary steps and avoid cluttering our environment.
```
`r unhide()`  
<br> 

<span style="font-size: 22px; font-weight: bold; color: var(--green);">Quickfire Questions</span>

* What does this line of code say? `data %>% filter() %>% group_by() %>% summarise()`: `r mcq(c("take the data and group it and then filter it and then summarise it", answer = "take the data and filter it and then group it and then summarise it", "take the data and summarise it and then filter it and then group it","take the data and group it and then summarise it and then filter it"))`  

<span style="font-size: 22px; font-weight: bold; color: var(--blue);">Job Done - Activity Complete!</span>

We have now recapped a number of functions and verbs that you will need as the semester goes on.  You will use them in upcoming labs and chapters so be sure to go over these and try them out to make yourself more comfortable with them. Remember to also start looking back at the <a href="https://psyteachr.github.io/" target = "_blank">Grassroots book</a> and remembering some of the work you did there.  If you have any questions please post them on the forums. Finally, don't forget to add any useful information to your Portfolio before you leave it too long and forget. **Happy Wrangling!**
