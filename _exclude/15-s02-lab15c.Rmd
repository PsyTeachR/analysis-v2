## InClass Activity

```{r lab15-inclass-setup, echo = FALSE, message=FALSE, warning=FALSE}
pinfo <- read_csv("data/15-s02/inclass/participant_info.csv")
wellbeing <- read_csv("data/15-s02/inclass/wellbeing.csv")
screen <- read_csv("data/15-s02/inclass/screen_time.csv")

wemwbs <- wellbeing %>%
  pivot_longer(names_to = "var", values_to = "score", cols = -Serial) %>%
  group_by(Serial) %>%
  summarise(tot_wellbeing = sum(score))

screen_long <- screen %>%
  pivot_longer(names_to = "var", values_to = "hours", cols = -Serial) %>%
  separate(var, c("variable", "day"), "_")


screen2 <- screen_long %>%
  mutate(variable = recode(variable,
			   "Watch" = "Watching TV",
			   "Comp" = "Playing Video Games",
			   "Comph" = "Using Computers",
			   "Smart" = "Using Smartphone"),
	 day = recode(day,
		      "wk" = "Weekday",
		      "we" = "Weekend"))
```

**Continued: Smartphone screen time and wellbeing**

We are going to jump straight into this as you will have already started the analysis in the PreClass activity but as a quick recap, there is currently much debate surrounding smartphones and their effects on well-being, especially with regard to children and teenagers. In the PreClass, and continuing today, we have been looking at data from this recent study of English adolescents:

> Przybylski, A. & Weinstein, N. (2017). A Large-Scale Test of the Goldilocks Hypothesis. *Psychological Science*, *28*, 204--215.

This was a large-scale study that found support for the "Goldilocks" hypothesis among adolescents: that there is a "just right" amount of screen time, such that any amount more or less than this amount is associated with lower well-being. The dependent measure used in the study was the <a href="https://warwick.ac.uk/fac/med/research/platform/wemwbs/" target = "_blank">Warwick-Edinburgh Mental Well-Being Scale (WEMWBS)</a>. This is a 14-item scale with 5 response categories, summed together to form a single score ranging from 14-70, and we have been working with a version of some of the available data which can be found in the accompanying zip file on Moodle or <a href = "data/15-s02/inclass/ch15-preclass-inclass-data.zip" target = "_blank">download from here</a>

Przybylski and Weinstein looked at multiple measures of screen time, but again for the interests of this exercise we will be focusing on smartphone use only, but do feel free to expand your skills after by looking at different definitions of screen time. Overall, Przybylski and Weinstein suggested that decrements in wellbeing started to appear when respondents reported more than one hour of daily smartphone use. So, bringing it back to our additional variable of sex, our question is now, does the negative association between hours of use and wellbeing (beyond the one-hour point) differ for boys and girls?

Let's think about this in terms of the variables. We have:

- a continuous DV, well-being;

- a continuous predictor, screen time;

- a categorical predictor, sex.

And to recap in terms of analysis, what we are effectively trying to do is to estimate **two slopes** relating screen time to well-being, one for girls and one for boys, and then statistically compare these slopes. Again, as we have seen building up to this lab, **an independent groups t-test is just a special case of ordinary regression with a single categorical predictor; ANOVA is just a special case of regression where all predictors are categorical.** But remember, although we can express any ANOVA design using regression, the converse is not true: we cannot express every regression design in ANOVA. As such people like regression, and the general linear model, as it allows us to have any combination of continuous and categorical predictors in the model. The only inconvenience with running ANOVA models as regression models is that you have to take care of how you numerically code the **categorical predictors**. We will use an approach called **deviation coding** which we will look at today later in this lab.

**Let's Begin!**

### Smartphone and well-being for boys and girls {#Ch15InClassQueT1}

Continuing from where we left on in the PreClass, so far we have been matching what the original authors suggested we would find in the data, this drop off in self-reported well-being for longer exposures of smart-phone use (i.e. >1 hour). However, we said we wanted to look at this in terms of males and females, or boys and girls really, so we need to do a bit more wrangling. Also, as above we said there seemed to be only a small difference between Weekday and Weekends so, we will collapse weekday and weekend usage in smartphones.

1. Create a new table, `smarttot`, that takes the information in `screen2` and keeps only the smarthphone usage.
2. Now, create an average smartphone usage for each participant, called `tothours`, using a group_by and summarise, regardless of whether or not it is the weekend or weekday, i.e. the mean number of hours per day of smartphone use (averaged over weekends/weekdays) for that participant.
3. Now, create a new tibble `smart_wb` that only includes participants from `smarttot` who used a smartphone for more than one hour per day each week, and then combine this tibble with the information in the `wemwbs` tibble and the `pinfo` tibble.

The finished table should look something like this (we are only showing the first 5 rows here):

```{r bringtogether, echo=FALSE}
smart_wb3 <- screen2 %>%
  filter(variable == "Using Smartphone") %>%
  group_by(Serial) %>%
  summarise(tothours = mean(hours)) %>%
  filter(tothours > 1) %>%
  inner_join(wemwbs, "Serial") %>%
  inner_join(pinfo, "Serial") 

knitr::kable(smart_wb3[1:5,], align = "c")
```

`r hide("Hints for Wrangling Steps")`
```{block, type ="info"}

**Step 1**

- `filter("Using Smartphone")` to keep only smartphone use

**Step 2**

- group_by(Participant) %>% summarise(tothours = mean())

**Step 3**

- `filter()`, `inner_join()`
- hours greater than 1
- what is the common column to join each time by? Participant?
```
`r unhide()`

```{r calculate_mean, echo=FALSE}
## get rid of people who used smartphone less than or equal to 1 hour total per week
smarttot <- screen2 %>%
  filter(variable == "Using Smartphone") %>%
  group_by(Serial) %>%
  summarise(tothours = mean(hours))
```

```{r combine2, echo=FALSE}
smart_wb <- smarttot %>%
  filter(tothours > 1) %>%
  inner_join(wemwbs, "Serial") %>%
  inner_join(pinfo, "Serial") 
```

### Visualising and Interpreting the relationship between smartphone use and wellbeing by sex {#Ch15InClassQueT2}

Excellent! Lots of visualisation and wrangling in the PreClass and today but that is what we have been working on and building our skills on up to this point so, we are coping fine! Just a couple more visualisation and wrangles to go before we run the analysis (the easy part!)

* Using the data in `smart_wb` create the following figure. You will need to first calculate the mean wellbeing scores for each combination of `sex` and `tothours`, and then create a plot that includes separate regression lines for each sex.
* Next, or if you just want to look at the figure and not create it, make a brief interpretation of the figure. Think about it in terms of who has the overall lower mean wellbeing score and also are both the slopes the same or is one more negative, one more positive, etc.

```{r last-fig-hide, echo=FALSE, fig.cap='Scatterplot and slopes for relationships between total hours and mean wellbeing score for boys (cyan) and girls (red)'}
smart_wb_gen <- smart_wb %>%
  group_by(tothours, sex) %>%
  summarise(mean_wellbeing = mean(tot_wellbeing))

ggplot(smart_wb_gen, aes(tothours, mean_wellbeing, color = factor(sex))) +
  geom_point() +
  geom_smooth(method = "lm")
```

### A side point on mean centering and deviation coding

Last bit of wrangling, I promise, before the analysis. Here, we will introduce something that is worth doing to help with our interpretation. You can read up more on this later, and we will cover it in later years more in-depth, but when you have continuous variables in a regression, it is often sensible to transform them by **mean centering** them which has two very useful outcomes:

1. the intercept of the model now shows the predicted value of $Y$ for the mean value of the predictor variable rather than the predicted value of $Y$ at the zero value of the unscaled variable as it normally would;

2. if there are interactions in the model, any lower-order effects (e.g. main effects) can be interpreted as they would have been, had it been simply an ANOVA.

These steps seem rather worthwhile in terms of interpretation and the process is really straightforward. You can **mean center a continuous predictor**, for example `X`, simply by subtracting the mean from each value of the predictor: i.e.`X_centered = X - mean(X)`.

A second very useful thing to do that aids the interpretation is to convert your categorical variables into what is called **deviation coding**. Again, we are going to focus more on this in L3 but it is good to hear the term in advance as you will see it from time to time. Again, all this does is to allow you to interpret the categorical predictors as if it were an ANOVA.

We are going to do both of these steps, **mean centering of our continuous variable** and **deviation coding of our categorical variable**. Here is the code to do it. Copy it and run it but be sure that you understand what it is doing.  

* totothours_c is the mean centered values of tothours
* sex_c is the deviation coding of the sex column (sex) where male, which was coded as 1, is now coded as .5, and female is now coded as -.5 instead of 0. The `ifelse()` basically says, if that column you want me to look at, says this (e.g. sex == 1), then I will put a .5, otherwise (or else) I will put a -.5.

```{r centering}
smart_wb <- smart_wb %>%
  mutate(tothours_c = tothours - mean(tothours),
         sex_c = ifelse(sex == 1, .5, -.5)) %>%
  select(-tothours, -sex)
```

### Estimating model parameters {#Ch15InClassQueT3}

Superb! And now finally, after all that wrangling and visualisation, the models. Finally, we are going to see if there is statistical support for our above interpretation of the Figure 15.3, where we saw that overall, girls have lower well-being and that they are affected more by prolonged smartphone usage than boys are. Just to recap, the previous authors have already looked at smartphone usage and wellbeing but, we want to look at whether it has more of an impact in girls than boys, or boys than girls, or about the same.

The multiple regression model, from the general linear model, for this analysis would be written as:

$Y_i = \beta_0 + \beta_1 X_{1i}  + \beta_2 X_{2i}  + \beta_3 X_{3i} + e_i$

where:

- $Y_i$ is the wellbeing score for participant $i$;
- $X_{1i}$ is the mean-centered smartphone use predictor variable for participant $i$;
- $X_{2i}$ is gender, where we used deviation coding (-.5 = female, .5 = male);
- $X_{3i}$ is the interaction between smartphone use and gender ($= X_{1i} \times X_{2i}$)

You have seen multiple regression models before in R and they usually take a format something like, `y ~ a + b`. The one for this analysis is very similar but with one difference, we need to add the interaction.  To do that, instead of saying `a + b` we do `a * b`. This will return us the effects of a and b by themselves as well as the interaction of a and b. Just like you would in an ANOVA but here one of the variables is continuous and one is categorical. 

* With that in mind, using the data in `smart_wb`, use the `lm()` function to estimate the model for this analysis where we predict `tot_wellbeing` from mean centered smartphone usage (tothours_c) and the deviation coded sex (sex_c)

`r hide("Hints on model")`
```{block, type ="info"}
- R formulas look like this: `y ~ a + b + a:b` where `a:b` means interaction
- This can be written in short form of `y ~ a * b`
```
`r unhide()`


* Next, use the `summary()` function on your model output to view it. The ouput should look as follows:


```{r mod, echo = FALSE}
mod <- lm(tot_wellbeing ~ tothours_c * sex_c, smart_wb)

# alternatively: 
# mod <- lm(tot_wellbeing ~ tothours_c + sex_c + tothours_c:sex_c, smart_wb)

summary(mod)
```

### Final Interpretations {#Ch15InClassQueT4}

Finally, just some quick interpretation questions to round off all our work! To help you, here is some info:

```{r hidden, include = FALSE}
male_intercept <- coef(mod)["(Intercept)"] + coef(mod)["sex_c"] * .5
male_slope <- coef(mod)["tothours_c"] + coef(mod)["tothours_c:sex_c"] * .5
female_intercept <- coef(mod)["(Intercept)"] + coef(mod)["sex_c"] * -.5
female_slope <- coef(mod)["tothours_c"] + coef(mod)["tothours_c:sex_c"] * -.5
```

* The intercept for the male regression line can be calculated by: the Intercept + (the beta of sex_c * .5)
* The slope of the male regression line can be calculated by: the beta of the tothours_c + (the beta of interaction * .5)
* The intercept for the female regression line can be calculated by: the Intercept + (the beta of sex_c * -.5)
* The slope of the female regression line can be calculated by: the beta of the tothours_c + (the beta of interaction * -.5)

Look at your model output in the `summary()` and try to answer the following questions. The solutions are below.

* The interaction between smartphone use and gender is shown by the variable `r mcq(c("tothours_c", "sex_c", answer = "tothours_c:sex_c"))`, and this interaction was `r mcq(c(answer = "significant", "nonsignificant"))` at the $\alpha = .05$ level.

* To two decimal places, the intercept for male participants is: `r fitb(round2(male_intercept, 2), 5, num = TRUE)`

* To two decimal places, the slope for male participants is: `r fitb(round2(male_slope, 2), 5, num = TRUE)`

* To two decimal places, the intercept for female participants is: `r fitb(round2(female_intercept, 2), 5, num = TRUE)`

* To two decimal places, the slope for female participants is: `r fitb(round2(female_slope, 2), 5, num = TRUE)`

As such, given the model of `Y = intercept + (slope * X)`  where Y is wellbeing and X is total hours on smartphone, what would be the predicted wellbeing score for a male and a female who use their smartphones for 8 hours. Give your answer to two decimal places:

* Male: `r fitb(round2(male_intercept, 2) + round2(male_slope, 2) * 8, 5, num = TRUE)`
* Female: `r fitb(round2(female_intercept, 2) + round2(female_slope, 2) * 8, 5, num = TRUE)`

And finally, what is the most reasonable interpretation of these results? `r mcq(c("smartphone use harms girls more than boys", "smartphone use harms boys more than girls", "there is no evidence for gender differences in the relationship between smartphone use and well-being", answer = "smartphone use was more negatively associated with wellbeing for girls than for boys"))`
  
<span style="font-size: 22px; font-weight: bold; color: var(--blue);">Job Done - Activity Complete!</span>

**One last thing:**

Before ending this section, if you have any questions, please post them on the available forums or speak to a member of the team. Finally, don't forget to add any useful information to your Portfolio before you leave it too long and forget. Remember the more you work with knowledge and skills the easier they become.

