## Additional Material

Below is some additional material that might help you understand the tests in this Chapter a bit more as well as some additional ideas.

```{r ch6-additional-blog, echo = FALSE, message=FALSE, warning=FALSE, results='asis'}
# all data in here to make inline code work 
# solutions are shown for students at the bottom
# key values
n_new <- 22
orig_mean <- 590
orig_sd <- 94
#Task 1
ns_data <- tibble(participant = 1:n_new,
                  valid_rt = c(631.2,800.8,595.4,502.6,604.5,
                               516.9,658.0,502.0,496.7,600.3,
                               714.6,623.7,634.5,724.9,815.7,
                               456.9,703.4,647.5,657.9,613.2,
                               585.4,674.1))

#Task 2
woods_mean <- 590
n_participants <- ns_data %>%
  filter(valid_rt > woods_mean) %>%
  nrow()
#Task 3
pval_dbinom <- sum(dbinom(n_participants:nrow(ns_data), nrow(ns_data), .5))
#Task 4
ns_data_mean <- ns_data %>% summarise(m = mean(valid_rt)) %>% pull(m)  
ns_data_sd <- ns_data %>% summarise(sd = sd(valid_rt)) %>% pull(sd) 
#Task 5
t_obs <- (ns_data_mean - woods_mean) / (ns_data_sd / sqrt(nrow(ns_data)))
#Task 6
pval <- pt(abs(t_obs), nrow(ns_data) - 1L, lower.tail = FALSE) * 2L
#Task 7
ttest <- t.test(pull(ns_data, valid_rt), mu = woods_mean)
```

### More on `t.test()` - vectors vs. formula {-}

A quick note on running the t-test in two different ways. In the lab we showed you how to run a t-test on a between-subjects design. This is the Welch's t-test version of the code from the lab:

```{r chpt6-additional-1, echo=FALSE, message=FALSE, warning=FALSE}
crt <- read_csv("data/06-s01/homework/CRT_Data.csv")
crt2 <- select(crt, ID, Treatment, CorrectAnswers)
```

```{r chpt6-additional-2}
t_table <- t.test(crt2 %>% filter(Treatment == 0) %>% pull(CorrectAnswers),
                  crt2 %>% filter(Treatment == 1) %>% pull(CorrectAnswers),
                  var.equal = FALSE) %>%
  tidy()
```

This is sometimes referred to as the vector approach, and what the code is doing is taking each groups' data as a vector input.  For example, if you were to just look at the data for the Treatment 0 group then that line of code:

```{r chpt6-additional-3, eval = FALSE}
crt2 %>% filter(Treatment == 0) %>% pull(CorrectAnswers)
```

shows just these values:

```{r chpt6-additional-4, echo = FALSE}
crt2 %>% filter(Treatment == 0) %>% pull(CorrectAnswers)
```

And likewise the Treatment 1 line of code just gives these values:

```{r chpt6-additional-5, echo = FALSE}
crt2 %>% filter(Treatment == 1) %>% pull(CorrectAnswers)
```

And the `t.test()` function is just saying this is group 1's data, this is group 2's data, and I am comparing them. However the eagle-eyed of you will have seen in the solution an alternative code, that looks like:

```{r chpt6-additional-6}
t_table <- t.test(CorrectAnswers ~ Treatment, data = crt2, var.equal = FALSE) %>% tidy()
```

This is the formula method and if you look at the structure of `crt2` (the first 6 rows are shown below) you get an idea of how the formula approach works:

```{r chpt6-additional-7, echo=FALSE, warning=FALSE}
head(crt2)
```

The formula approach works as `t.test(DV ~ IV, data = my_data)` where:

* DV is the name of the column with your responses (e.g. mean reaction time)
* IV is the name of the column with your groups (in categorical form - e.g. 1 vs 0)
* `~` means "by" or "based on" or "split up by". So test the DV based on the IV grouping
* and my_data is the name of your tibble.

Whichever approach you use, the observed t-value, p-value, and df (parameter) should be the same! What might change is what the t-test considers as group 1 and what it considers group 2. And from your knowledge of the t-test formula, this will affect whether your t-test is positive or negative.  For example:

```{r chpt6-additional-8}
t_table <- t.test(crt2 %>% filter(Treatment == 0) %>% pull(CorrectAnswers),
                  crt2 %>% filter(Treatment == 1) %>% pull(CorrectAnswers),
                  var.equal = FALSE) %>%
  tidy()
```

Gives the t-value of t = `r t_table$statistic %>% round(2)`, whereas if you switch the order of inputting the Treatment groups as such:

```{r chpt6-additional-9}
t_table <- t.test(crt2 %>% filter(Treatment == 1) %>% pull(CorrectAnswers),
                  crt2 %>% filter(Treatment == 0) %>% pull(CorrectAnswers),
                  var.equal = FALSE) %>%
  tidy()
```

You get a t-value of t = `r t_table$statistic %>% round(2)`. Same value (or magnitude) just one is positive and the other is negative, because the order of who is Group 1 and who is group 2 is switched.  And just for comparion, the formula approach:

```{r chpt6-additional-10}
t_table <- t.test(CorrectAnswers ~ Treatment, data = crt2, var.equal = FALSE) %>% tidy()
```

Gives a t-value of t = `r t_table$statistic %>% round(2)`. So again the same magnitude but you are not controlling who is Group 1 and who is Group 2.

Long story short is that both methods, if used appropriately, run the same analysis. The benefit of the vector approach is that you can dictate in your analysis who is Group 1 and who is Group 2. And that is really the only difference.

### Misleading and Appropriate Barplots {-}

**Misleading Barplots**

The data used in the PreClass activities allows us to show you something that you might find interesting. As we mentioned back in Chapter 3 on visualisation, the barplot is becoming less frequently used, as summarised in this blog: <a href="https://garstats.wordpress.com/2016/03/09/one-simple-step-to-improve-statistical-inferences/" target = "_blank">One simple step to improve statistical inferences</a>. The data we have used today demonstrate the point that a simple barplot can actually be somewhat misleading about the data. Have a look at the figure below. Both bars represent the data from our `r n_new` Normal Sleep participants. The column on the left, `hide_data`, is a standard representation (albeit without error bars) whereas the column on the right, `show_data`, demonstrates the issue. Looking at the column on the left, the assumption is that all the data is around the peak of the column. However, looking at the column on the right, we can see that this is not the case and there are participants both above and below the mean by approximately 100 ms. This misleading perception, when the data is hidden, was tested and shown to exist in participants viewing these figures by <a href="https://link.springer.com/article/10.3758/s13423-012-0247-5" target = "_blank">Newman and Scholl (2012)</a> which you can read up on if you like. 

```{r ch6-preclass-blog-figure, echo = FALSE, warning=FALSE, message = FALSE, fig.cap='How representative are barplots of the actual spread of the data!'}
ns_data$group <- "show_data"
ns_old <- tibble(participant <- 1:22, valid_rt = 590, group = "hide_data")
ns_old1 <- tibble(participant <- 1:22, valid_rt = NA, group = "hide_data")

dat <- bind_rows(ns_old, ns_data)
dat1 <- bind_rows(ns_data, ns_old1)

dat %>%
  group_by(group) %>%
  summarise(mean_RT = mean(valid_rt)) %>%
  ggplot(aes(x = group, y = mean_RT)) +
  geom_col(alpha = .4, width = .3) +
  geom_jitter(data = dat1, aes(y = valid_rt), width = .1) +
  theme_bw()
```

The function we use to show the data points is `geom_jitter()` and it gets added to a visualisation pipeline just like other `geom_?()`s that we have used; your code will look like something like this:

```{r, eval = FALSE}
ggplot(my_data, aes(x = my_x_variable, y = my_y_variable)) +
  geom_col() +
  geom_jitter(width = .1)
```

Look out for it in the coming chapters but the main thing to keep in mind is that barplots can be misleading and displaying the individual data may be more informative - particularly when the response measured creates a spread of data.

**Appropriate Barplots**

That said, barplots do have their place in data analysis and research methods. The best time to use a barplot is when the value is a count - i.e. when the value had no variability in it.  A great example of this is in observational research using categorical data. Think about the table we simulated for the chi-squre data as part of the Additional Materials in Chapter 5. Here is that table again:

```{r lab6-additional-chi-data, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}
chi_table <- read_csv("./data/05-s01/additional/my_chi_data.csv") %>%
  group_by(Groups, Responses) %>% 
  count() %>% 
  pivot_wider(names_from = "Responses", values_from = "n") %>%
  mutate(Total = No + Unsure + Yes)
``` 

```{r lab6-additional-chi-table, echo=FALSE}
knitr::kable(chi_table, align = "c", caption = "Cross-Tabulation Table of Simulated Data from Chapter 5 Additional Materials")
```

We have two groups with three possible responses and each participants can only give one response. What that means, for example, is that there is no variation in the number of people who in Group A said No - it is exactly `r chi_table %>% filter(Groups == "A") %>% pull(No)` people. Likewise, exactly `r chi_table %>% filter(Groups == "B") %>% pull(Unsure)` people in Group B said unsure. So here a barplot actually makes sense to use as it accurately reflects the value in that group/condition and no data is hidden. The plot for the above table might look like this:

```{r lab6-additional-figure, echo=FALSE, fig.cap="A barplot works well with categorical data"}
chi_table %>% 
    select(-Total) %>%
    pivot_longer(cols = No:Yes, 
                 names_to = "Responses",
                 values_to = "n") %>%
  ggplot(aes(x = Responses, y = n, fill = Groups)) +
  geom_col(position = position_dodge(.9)) +
  scale_fill_manual(values = psyteachr_colours()) +
  labs(x = "Response Options", y = "Count") +
  theme_classic()
```

In short, the main message about any visualisation is about accurately and clearly conveying that information to your reader. If there is a spread of data within a variable then try to show that more clearly with error bars and data points, perhaps even using a violin plot instead of a barplot. If however there is no spread of data within a variable then a barplot works well.

### Analysing chi-squares {-}

Finally, to round of this additional material, we thought it might be handy to show how to run a chi-square analysis. We cover the chi-square more in lectures but adding it here might help some people. We won't really look at the hand calculations, but you will know that the formula for the chi-square is:

$x_c^2 = \sum\frac{(O_i - E_i)^2}{E_i}$

* where $x_c^2$ is the chi-square symbol - often simplified to $x_2$
* $O_i$ is the observed value of group {i} and
* $E_i$ is the expected value of group {i}

And we can use the data from above to show how to quickly run the chi-square analysis on the table. First we need to tidy up the table to get rid of the `Groups` and `Total` columns, leaving us with a tibble called `chi_table` that has this structure:

```{r lab6-additional-chi-data-red, echo = FALSE, eval = TRUE}
chi_table <- chi_table %>% 
  ungroup() %>%
  select(-Total, -Groups)
``` 

```{r lab6-additional-chi-table-2, echo=FALSE}
knitr::kable(chi_table, align = "c", caption = "Cross-Tabulation Table Data for analysis")
```

Now to analyse the data we use the `chisq.test()` function. There are really only two arguments you need to think about:

* your data - for us stored in `chi_table`
* and whether to set `correct` as **TRUE** or **FALSE**. This is Yates' Continuity Correction. The default is set as TRUE but a lot of people set it as FALSE so we will select that today.

And we run the analysis as such:

```{r lab6-additional-chi-result}
chisq_result <- chisq.test(chi_table, correct = FALSE) %>% tidy()
```

Giving the following result:

```{r lab6-additional-chi-table-red, echo=FALSE}
knitr::kable(chisq_result, align = "c", caption = "Chi-Square Result")
```

And could be written up as $x_c^2$(df = `r chisq_result$parameter`, N = `r chi_table %>% sum()`) = `r chisq_result$statistic %>% round(2)`, p = `r chisq_result$p.value %>% round(2)`. And if you wanted to check the output and calculate the data by hand, or needed to do further analysis, you can see the expected values by doing the analysis but not tidying it, as follows:

```{r lab6-additional-chi-result-expected}
chisq_untidy <- chisq.test(chi_table, correct = FALSE)

chisq_untidy$expected
```

And if you wanted the expected values for just one of the groups - say the second group, Group B:

```{r lab6-additional-chi-result-expected2}
chisq_untidy$expected[2,]
```

Or even just the observed values to check you entered the data correctly:

```{r lab6-additional-chi-result-observed}
chisq_untidy$observed
```

We will leave that there but hopefully this gives you some additional insight into how to analyse a chi-square test.

<span style="font-size: 22px; font-weight: bold; color: var(--purple);">End of Additional Material!</span>