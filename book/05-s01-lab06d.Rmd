## Solutions to Questions

```{r lab6-solutions-setup, echo=FALSE, message=FALSE, warning=FALSE}

```

Below you will find the solutions to the questions for the Activities for this chapter. Only look at them after giving the questions a good try and speaking to the tutor about any issues.

### The Binomial Test

#### Task 1
```{r ns_data_temp, eval  = TRUE}
ns_data <- tibble(participant = 1:22,
                  valid_rt = c(631.2,800.8,595.4,502.6,604.5,
                               516.9,658.0,502.0,496.7,600.3,
                               714.6,623.7,634.5,724.9,815.7,
                               456.9,703.4,647.5,657.9,613.2,
                               585.4,674.1))
```

[Return to Task](#Ch6PreClassQueT1)

#### Task 2
```{r count_years, eval  = TRUE}
woods_mean <- 590

n_participants <- ns_data %>%
  filter(valid_rt > woods_mean) %>%
  nrow()
```

* Giving an n_participants value of `r n_participants`

[Return to Task](#Ch6PreClassQueT2)

#### Task 3

* You can use the density function:
```{r Ch6PreClassQueT3-1, eval  = TRUE}
sum(dbinom(n_participants:nrow(ns_data), nrow(ns_data), .5))
```

* Or, the cumulative probability function:
```{r Ch6PreClassQueT3-2, eval  = TRUE}
pbinom(n_participants - 1L, nrow(ns_data), .5, lower.tail = FALSE)
```

* Or, If you were to plug in the numbers directly into the code:
```{r Ch6PreClassQueT3-3, eval  = TRUE}
sum(dbinom(16:22,22, .5))
```

* Or, finally, remembering we need to specify a value lower than our minimum participant number as `lower.tail = FALSE`.
```{r Ch6PreClassQueT3-4, eval  = TRUE}
pbinom(15, 22, .5, lower.tail = FALSE)
```

It is better practice to use the first two solutions, which pull the values straight from ns_data, as you run the risk of entering an error into your code if you plug in the values manually.

[Return to Task](#Ch6PreClassQueT3)

### The One-Sample t-test

#### Task 4

* For `ns_data_mean` use `summarise()` to calculate the mean and then `pull()` the value.
* For `ns_data_sd` use `summarise()` to calculate the sd and then `pull()` the value.
```{r mean_sd, eval  = TRUE}
# the mean
ns_data_mean <- ns_data %>%
  summarise(m = mean(valid_rt)) %>%
  pull(m)  

# the sd
ns_data_sd <- ns_data %>%
  summarise(sd = sd(valid_rt)) %>%
  pull(sd)
```

**NOTE:** You could print them out on the screen if you wanted to "\\n" is the end of line symbol so that they print on different lines

```{r printing-ouput}
cat("The mean number of hours was", ns_data_mean, "\n")
cat("The standard deviation was", ns_data_sd, "\n")
```

[Return to Task](#Ch6PreClassQueT4)

#### Task 5
```{r t_obs, eval  = TRUE}
t_obs <- (ns_data_mean - woods_mean) / (ns_data_sd / sqrt(nrow(ns_data)))
```

* Giving a t_obs value of `r t_obs`

[Return to Task](#Ch6PreClassQueT5)

#### Task 6

If using values straight from ns_data, and multiplying by 2 for a two-tailed test, you would do the following:
```{r p_value1, eval  = TRUE}
pval <- pt(abs(t_obs), nrow(ns_data) - 1L, lower.tail = FALSE) * 2L
```

* Giving a pval of `r pval`

But you can also get the same answer by plugging the values in yourself - though this method runs the risk of error and you are better off using the first calculation as those values come straight from ns_data. :
```{r p_value2, eval  = TRUE}
pval2 <- pt(t_obs, 21, lower.tail = FALSE) * 2
```

* Giving a pval of `r pval2`

[Return to Task](#Ch6PreClassQueT6)

#### Task 7

The t-test would be run as follows, with the output shown below:

```{r t-test, eval  = TRUE}
t.test(pull(ns_data, valid_rt), mu = woods_mean)
```

[Return to Task](#Ch6PreClassQueT7)

#### Task 8

According to the one-sample t-test these participants are responding in a similar manner as the participants from the original study, and as such, we may be inclined to assume that the recruitment process of our pilot experiment is working well.

However, according to the binomial test the participants are responding differently from the original sample. So which test result should you take as the finding? 

Keep in mind that the binomial test is very rough and categorises participants into yes or no. The one-sample t-test uses much more of the available data and to some degree would give a more accurate answer. However, the fact that two tests give really different answers may give you reason to question whether or not the results are stable and potentially you should look to gather a larger sample to get a more accurate representation of the population.

[Return to Task](#Ch6PreClassQueT8)


### Practice Your Skills

#### Load in the data

```{r T0, eval = FALSE}
library("tidyverse")

melodydata <- read_csv("socialmelodies_exp1.csv")
```

[Return to Task](#Ch5PracticeSkillsT0)

#### Task 1 - Filter data

```{r T1, eval = FALSE}
melodydata_exp1 <- melodydata %>%
  filter(exp1 == 1)
```

[Return to Task](#Ch5PracticeSkillsT1)

#### Task 2 - Select data

```{r T2, eval = FALSE}
melodydata_exp1_reduced <- melodydata_exp1 %>%
  select(id, Baseline_Proportion_Gaze_to_Singer, Test_Proportion_Gaze_to_Singer)
```

[Return to Task](#Ch5PracticeSkillsT2)

#### Task 3 - Testing baseline gazing proportion

```{r T3, eval = FALSE}
t.test(pull(melodydata_exp1_reduced, Baseline_Proportion_Gaze_to_Singer), mu = 0.5)
```

[Return to Task](#Ch5PracticeSkillsT3)

#### Task 4 - Testing test trial gazing proportion

```{r T4, eval = FALSE}
t.test(pull(melodydata_exp1_reduced, Test_Proportion_Gaze_to_Singer), mu = 0.5)
```

[Return to Task](#Ch5PracticeSkillsT4)

#### Task 5 - Gathering data into a different format

```{r T5, eval = FALSE}
melodydata_exp1_wide <- melodydata_exp1_reduced %>% 
  pivot_longer(cols = Baseline_Proportion_Gaze_to_Singer:Test_Proportion_Gaze_to_Singer,
               names_to = "TrialType",
               values_to = "Proportion")
```

[Return to Task](#Ch5PracticeSkillsT5)

#### Task 6 - Visualise baseline and test trial data


```{r T6, eval = FALSE}
ggplot(data = melodydata_exp1_wide, 
       aes(x = TrialType, 
           y = Proportion, 
           fill = TrialType)) + 
  geom_boxplot() +
  guides(fill = FALSE)
```

[Return to Task](#Ch5PracticeSkillsT6)

#### Task 7 - Compare your analyses with the analyses reported in the published paper

When looking at the results section you should see that the two reported one-sample t-tests in the published paper and are the same that you have produced as part of this exercise. In addition, Fig 2a in the published paper should resemble yours. Well done!

[Return to Task](#Ch5PracticeSkillsT7)

