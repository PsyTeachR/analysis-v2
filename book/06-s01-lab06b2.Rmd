
```{r ch6-preclass-setup, echo = FALSE, message=FALSE, warning=FALSE, results='asis'}
# all data in here to make inline code work 
# solutions are shown for students at the bottom
# key values
n_new <- 22
orig_mean <- 590
orig_sd <- 94
#Task 1
ns_data <- tibble(participant = 1:n_new,
                  valid_rt = c(631.2,800.8,595.4,502.6,604.5,
                               516.9,658.0,502.0,496.7,600.3,
                               714.6,623.7,634.5,724.9,815.7,
                               456.9,703.4,647.5,657.9,613.2,
                               585.4,674.1))

#Task 2
woods_mean <- 590
n_participants <- ns_data %>%
  filter(valid_rt > woods_mean) %>%
  nrow()
#Task 3
pval_dbinom <- sum(dbinom(n_participants:nrow(ns_data), nrow(ns_data), .5))
#Task 4
ns_data_mean <- ns_data %>% summarise(m = mean(valid_rt)) %>% pull(m)  
ns_data_sd <- ns_data %>% summarise(sd = sd(valid_rt)) %>% pull(sd) 
#Task 5
t_obs <- (ns_data_mean - woods_mean) / (ns_data_sd / sqrt(nrow(ns_data)))
#Task 6
pval <- pt(abs(t_obs), nrow(ns_data) - 1L, lower.tail = FALSE) * 2L
#Task 7
ttest <- t.test(pull(ns_data, valid_rt), mu = woods_mean)
```


## The Binomial Test

The Binomial test is one of the most "basic tests" in null hypothesis testing in that it uses very little information. The binomial test is used when a study has two possible outcomes (success or failure) and you have an idea about what the probability of success is. This will sound familiar from the work we did in Chapter 4 and the Binomial distribution. 

A Binomial test tests if an observed result is different from what was expected. For example, is the number of heads in a series of coin flips different from what was expected. Or in our case for this chapter, we want to test whether our normal sleepers are giving reaction times that are the same or different from those measured by Woods et al. The following tasks will take you through the process.

### Task 1: Creating a Dataframe {#Ch6PreClassQueT1}

First we need to create a tibble with our data so that we can work with it.

* Enter the data for the `r n_new` participants displayed above into a tibble and store it in `ns_data`.  Have one column showing the participant number (called `participant`) and another column showing the mean reaction time (called `valid_rt`).

`ns_data <- tibble(participant = c(NULL,NULL,...), valid_rt = c(NULL,NULL,...))`

* You could type each value out or copy and paste them from the hint below.

`r hide("Helpful Hint")`
```{block, type ="info"}
You can use this code structure and replace the NULL values:

`ns_data <- tibble(participant = c(NULL,NULL,...), valid_rt = c(NULL,NULL,...))`

The values are: 631.2, 800.8, 595.4, 502.6, 604.5, 516.9, 658.0, 502.0, 496.7, 600.3, 714.6, 623.7, 634.5, 724.9, 815.7, 456.9, 703.4, 647.5, 657.9, 613.2, 585.4, 674.1
```
`r unhide()`
<br>

### Task 2: Comparing Original and New Sample Reaction Times {#Ch6PreClassQueT2}

Our next step is to establish how many participants from our pilot study are above the mean in the original study by Woods et al.  

* In the original study the mean reaction time for valid trials was `r orig_mean` ms. Store this value in `woods_mean`.  
* Now write code to calculate the number of participants in the new sample (`ns_data` created in Task 1) that had a mean reaction time greater than the original paper's mean. Store this **single value** in `n_participants`. 
* The function `nrow()` may help here.
* `nrow()` is similar to `count()` or `n()`, but `nrow()` returns the number as a single value and not in a tibble. 
* Be sure whatever method you use you end up with a single value, not a tibble. You may need to use `pull()` or `pluck()`.

`r hide("Helpful Hint")`
```{block, type ="info"}

**Part 1**

`woods_mean <- value`

**Part 2**

* A few ways to achieve this. Here are a couple you could try

`ns_data %>% filter(x ? y) %>% count() %>% pull(?)`

or

`ns_data %>% filter(x ? y) %>% summarise(n = ?) %>% pull(?)`

or

`ns_data %>% filter(x ? y) %>% nrow()`

or

`dim[] %>% pluck()`

```
`r unhide()`

<br>
<span style="font-size: 22px; font-weight: bold; color: var(--green);">Quickfire Questions</span>  

* The number of participants that have a mean reaction time for valid trials greater than that of the original paper is: `r mcq(c("6","10",answer = n_participants, "16"))`


### Task 3: Calculating Probability {#Ch6PreClassQueT3}

Our final step for the binomial test is to compare our value from Task 2, `r n_participants` participants, to our hypothetical cut-off. We will work under the assumption that the mean reaction time from the original paper, i.e. `r orig_mean` ms, is a good estimate for the population of good sleepers (NS). If that is true then each new participant that we have tested should have a .5 chance of being above this mean reaction time ($p = .5$ for each participant).  

To phrase this another way, the expected number of participants above the cut-off would be $.5 \times N$, where $N$ is the number of participants, or $.5 \times 22$ = `r .5 * nrow(ns_data)` participants. 
* Calculate what would be the probability of observing at least `r n_participants` participants out of your `r nrow(ns_data)` participants that had a `valid_rt` greater than the Woods et al (2009) mean value.  
* **hint:** We looked at very similar questions in Chapter 4 using `dbinom()` and `pbinom()` 
* **hint:** The key thing is that you are asking about obtaining **X or more** successes. You will need to think back about cut-offs and `lower.tails`. 

`r hide("Helpful Hint")`
```{block, type ="info"}
Think back to Chapter 4 where we used the binomial distribution. This question can be phrased as, what is the probability of obtaining X or more successes out of Y trials, given the expected probability of Z.

* How many Xs? (see question)
* How many Ys? (see question)
* What is the probability of being either above or below the mean/cut-off? (see question)
* You can use a dbinom() %>% sum() for this or maybe a `pbinom()`
```
`r unhide()`

<br>
<span style="font-size: 22px; font-weight: bold; color: var(--green);">Quickfire Questions</span>  

* Using the Psychology standard $\alpha = .05$, do you think these NS participants are responding in a similar fashion as the participants in the original paper? Select the appropriate answer: `r mcq(c(answer = "No", "Yes"))`
* According to the Binomial test would you accept or reject the null hypothesis that we set at the start of this test? `r mcq(c(answer = "Reject", "Accept"))`

`r hide("Explain This - I don't get this answer")`
```{block, type ="info"}
The probability of obtaining 16 participants with a mean reaction time greater than the cut-off of 590 ms is p = .026. This is smaller than the field norm of p = .05. As such we can say that, using the binomial test, the new sample appears to be significantly different from the old sample as there is a significantly larger number of participants above the cut-off (M = 590ms) than would be expected if the new sample and the old sample were responding in a similar fashion. We would therefore reject our null hypothesis!
```
`r unhide()`
