## Additional Material

Below is some additional material that might help you understand ANOVAs a bit more and some additional ideas.

```{r lab12-solutions-setup, echo = FALSE, message=FALSE, warning=FALSE}
dmx <- tibble(sub_id = 1:9,
              i = rep(1:3, each = 3),
              j = rep(1:3, times = 3),
              typos = c(111, 102, 111, 
                    89, 127, 90,
                    97, 85, 88),
              sound = rep(c("cafe", "jazz", "silence"), each = 3)) %>%
  mutate(mu = mean(typos)) %>%
  group_by(i) %>%
  mutate(Ai = mean(typos) - mu) %>%
  ungroup() %>%
  mutate(err = typos - (mu + Ai))

dat_ss <- dmx %>% 
  summarise(total = sum(typos^2),
            ss_mu = sum(mu^2),
            ss_sound = sum(Ai^2),
            ss_err = sum(err^2))
```

### Levene's Test of Homogeneity

From previous chapters and from your lectures you will know that every test has a series of assumptions that are required to be held in order for your conclusions to be valid, and the ANOVA is no exception. As always the specific assumptions change depending on the design of the study, but in the instance of the experiment in this chapter - a between-subjects design - the assumptions are as follows:

* Data should be interval/ratio 
* Data in each condition should be normally distributed
* Data is independent from each other
* There is homogeneity of variance across different conditions (i.e. different conditions have equal variances). 

You will spot that these are actually very similar to a between-subjects t-test and that again just shows that the two tests are highly related. 

Now we know various ways to check things like normality and variance, with visual inspection being one of them, but a common test that people tend to use is what is called **Levene's Test of Homogeneity**. In fact, if you think back to Chapter 7, when you run a t-test and set the variance as `var.equal = FALSE`, if you really wanted to run the test as `var.equal = TRUE` then it would be Levene's test you should run first to confirm that variance is actually equal.  However, the issue with the ANOVA is that it actually assumes variance is equal, so it is best to run a Levene's test whenever you run an ANOVA that has at least one between-subjects condition. That is what we are going to show you here as well as how to interpret it and a little bit of discussion after. The main thing to note about Levene's Test of Homogeniety is that the null hypothesis for this test states that there is no significant difference in variance between conditions:

$$H_{0}: \sigma_{1}^2 = \sigma_{2}^2 $$
Conversely, the alternative hypothesis states that there is a difference in variance between conditions:

$$H_{1}: \sigma_{1}^2 \ne \sigma_{2}^2 $$

So a non-significant finding in Levene’s test would suggests equal variance across conditions as required by the assumptions of the ANOVA, whereas a significant finding for Levene's Test would suggest unequal variance and you may need to think about the assumptions of your data. 

**Running the test**

So here is our data again from the main activities, which we have stored in a tibble called `dmx`:
<br>
<br>
```{r dmx-show, echo = FALSE, results='asis'}
knitr::kable(dmx, 
             align = "c",
             digits = 3,
             caption = "Decomposition Matrix for Typos Example") %>%
  kable_styling() %>%
  scroll_box(width = "100%", box_css = "border: 0px;")
```
<br>

Let's run a quick visual inspection of the variance in each condition using a boxplot as such:
<br>
```{r boxplot-hide, echo=FALSE, fig.cap="A boxplot of our data to check for homogeneity of variance"}
dmx %>% ggplot(aes(x = sound, y = typos)) + 
  geom_boxplot() + 
  theme_bw() +
  coord_cartesian(ylim = c(0,150))
```

<br>
And as you can see it does not look like there is equal variance.  However, maybe we don't really trust our eyes and as such we want to run the Levene's Test.  To do that we use the below code:

```{r car-LTest, results='hide'}
car::leveneTest(typos ~ sound, data = dmx, center = median)
```

Where we are: 

* using the `leveneTest()` function from the **`car`** package. 
* using the **formula** approach that we saw in t-test where we are saying effectively DV "by" IV - typos ~ sound, where `~` stands for "by".  
* saying the data is in the tibble `dmx`
* and we are telling the code to run based on the medians of the distribution. This is a bit of a judgement call and you could use the mean instead of the median, but this paper would seem to suggest the median is optimal: [Carroll & Schnieder (1985) A note on levene's tests for equality of variances](https://www.sciencedirect.com/science/article/abs/pii/0167715285900161){target="_blank"} 

If we run the `leveneTest()` code we get the following output:

```{r car-LTest-hide, echo=FALSE}
car::leveneTest(typos ~ sound, data = dmx, center = median)
```

And now with your knowledge of understanding F-values and ANOVA tables (see Levene's is really just a sort of ANOVA) you can determine that, F(2, 6) = 0.517, p = .621. This tells us that there is no significant difference between the variance across the different conditions. Which, if you look at the boxplot, is completely the opposite of what we expected! Why is that? Most likely, that is because we have such small numbers of participants in our samples and you will remember from Chapter 8, small samples mean low power and unreliable findings. This is actually a good example why people often use visual inspection as well as some analytical tests to make checks on assumptions and they pull information together to make a judgement. The boxplot would say that variance is unequal. Levene's test would say variance is equal. Here, I would probably suggest taking a cautious approach and run a lot more participants before I consider running my analysis.

**Using `afex` to run Levene's**

One issue with the above example is that it requires another package - **`car`**. This isn't a major problem but say you only had the **`afex`** package to use. Well fortunately that package also has a function that can check Levene's Test - `afex::test_levene()`. And it works as follows:

1. First run the ANOVA as shown in the chapter and store the output

```{r afex-run, warning = FALSE}
results <- afex::aov_ez(data = dmx,
                         dv = "typos",
                         id = "sub_id",
                         type = 3,
                         between = "sound")
```

2. Now use the output of the ANOVA, in this instance `results`, as the input for the Levene's Test, and again center on the median

```{r afex-levene-run, echo=TRUE}
afex::test_levene(results, center = median)
```

And if we look at that output we see the exact same finding as we did using `car::leveneTest()`- F(2, 6) = 0.517, p = .621. So the positives of this approach is that you only use one package and it gives the same results as using two packages. The downside is that you have to run the ANOVA first - see how we use the ANOVA output as an input for `test_levene()` - which is a bit of an odd way of treating this assumption. Normally you would run the assumption check first and then the test. 

**Help I have unequal variance!**

Right, so you have found that your variance is not equal and you are now worried about what to do in regards your assumptions. Well, there is much debate on how robust the ANOVA is, where robust would mean that your False Positive rate does not necessarily inflate if the assumptions are not held. Some say that the ANOVA is not robust and you should use a non-parametric style of analysis instead in this instance, or break the ANOVA down into a series of Welch's t-tests (assuming unequal variance) and control the False Positive rate through Bonferroni corrections. Some however say that the ANOVA is actually pretty robust. We would recommend reading this paper [Blanca et al. (2018) Effect of variance ratio on ANOVA robustness: Might 1.5 be the limit?](https://link.springer.com/article/10.3758/s13428-017-0918-2){target="_blank"} which suggests that some degree of unequal variance is acceptable.  Alternatively, just as there is a Welch's t-test that does not assume equal variance there is also a Welch's ANOVA that does not assume equal variance. This paper [Delacre et al., (preprint) Taking Parametric Assumptions Seriously Arguments for the Use of Welch’s F-test instead of the Classical F-test in One-way ANOVA](https://psyarxiv.com/wnezg/){target="_blank"} goes into great detail about why using Welch's ANOVA is always advisable. You may be wondering how do you run a Welch's ANOVA in R, yeah? That is a very good question that you should ask Phil to write about one day after he figures it out himself.

<span style="font-size: 22px; font-weight: bold; color: var(--purple);">End of Additional Material!</span>
