## Additional Material

Below is some additional material that might help you understand permutations a bit more and some additional ideas.

```{r lab5-solutions-data, eval = TRUE, echo = FALSE, message = FALSE, warning = FALSE}
set.seed(1409)
dat <- read_csv("./data/05-s01/inclass/perm_data.csv") %>% 
  mutate(subj_id = row_number())
``` 

### More on `pivot_wider()` {-}

Much in the same way that `pivot_longer()` has become the new go-to function for gathering data, replacing the `gather()` function that many struggled with, `pivot_wider()` is likewise a new kid on the block.

Prior to using `pivot_wider()`, this book used the very confusing `spread()` function to change data from long format to wide format - i.e. splitting low columns into more shorter columns. `spread()` was an interesting function that somehow always managed to confuse people and it seemed that getting it to work was largely chance - `pivot_wider()` was introduced to reduce these issues and as you saw inclass it works similar to `pivot_longer()` in that it requires clear statement of `names_from` and `values_from`.

`pivot_wider()` should make spreading data wider a lot easier and as such we have aimed to replace every occurrence of it in this book. However, as before, we are still human and mistakes happen. Also, you will still see it being used in codes that you find on things like StackOverflow etc, so below is a very brief example that mimics the InClass activity, showing how `spread()` works. For ease, we would always recommend using `pivot_wider()`.

**The `spread()` function**

This example mimics Skill 4 (Section 5.2.4) of the Preclass Activity where we are splitting the data in `my_data_means` - shown below:
  
  * Remember the values will be different from the PreClass because we are using a function that creates a set of random numbers each time, `rnorm()`

```{r ch5-additional-data, echo = FALSE, warning = FALSE}
my_data <- tibble(group = rep(c("A", "B"), c(20, 20)),
                  Y = c(rnorm(20,  20, 5), rnorm(20, -20, 5)))

my_data_means <- my_data %>%
  group_by(group) %>%
  summarise(m = mean(Y))

my_data_means
```  

In order to split the table so that we have one column for Group A and another columns for Group B, we would use the below code. The spread function (`?spread`) splits the data in column `m` by the information, i.e. labels, in column `group` and puts the data into separate columns.

```{r ch5-additional-spread, warning = FALSE}
my_data_means %>%
  spread(group, m)
```

So the `spread()` function is not that different from using `pivot_wider()` but the inclusion of `names_from` and `values_from` really does make using `pivot_wider()` a lot clearer.  

The rest of the actions in that step of the Activity would follow as in the PreClass Activity - adding a `mutate()` as shown below:

```{r ch5-additional-spread-mutate, eval=FALSE}
my_data_means %>%
  spread(group, m) %>%
  mutate(diff = A - B) 
```

### More on simulating your own data {-}

Often we get asked for data to allow people to practice their hand calculations. One of the reasons for this chapter is to show people how to simulate their own data and to give them the functions to do so. We are going to use a chi-square test to show you, in a bit more concrete fashion, how you might go about this. We don't really cover much about chi-squares in this book so it is a nice addition.

So let's say we have run an observation test with two groups (A and B) and we ask them the classic "Huey Lewis & the News" question, "Do you believe in love?", giving them three response options, Yes, No, Unsure.  Let's say that we run 50 people in each group as well.  Putting that altogether we will end up with a cross-tabulation table that is 2 rows by 3 columns, with each row adding up to 50.

Using everything we have learnt in this Chapter here is how we might simulate that data: 

* Going to need at least tidyverse

```{r libraries, warning = FALSE, message=FALSE}
library(tidyverse)
```

* The below code is how we might created a tibble (`my_chi_data`) where you have two columns:
    * `Groups` showing whether participants are in Group A or B
    * `Responses` showing the simulated response for that participant

We won't walk you through this code as you should know enough from Chapters 4 & 5 to follow it and edit it, but if you really struggle, get in touch

```{r data-simulate}
my_chi_data <- tibble(Groups = rep(c("A","B"),        # Names of your Groups
                               times = c(50, 50)),    # Participants per Group
                  Responses = sample(c("Yes",         # Response Options to Sample
                                       "No", 
                                       "Unsure"),     
                                     size = 50 + 50,  # Total number of responses
                                     replace = TRUE)) # with replacement
```

* If you wanted to save your data as a .csv file for later use or to send to a colleague, you could use:

```{r data-save-real, echo=FALSE}
write_csv(my_chi_data, "./data/05-s01/additional/my_chi_data.csv")
```

```{r data-save, eval=FALSE}
write_csv(my_chi_data, "my_data.csv")
```

* Or with a bit of data wrangling, you can convert `my_chi_data` into a cross-tabulation table that would look like as follows:
  * Again this wouldn't use any new functions
  * `group_by() %>% count() %>% pivot_wider()`
  * group by both columns as you want to count how many times each response was used by each group.
  
```{r data-table, echo = FALSE}
chi_table <- my_chi_data %>% 
  group_by(Groups, Responses) %>% 
  count() %>% 
  pivot_wider(names_from = "Responses", values_from = "n") %>%
  mutate(Total = No + Unsure + Yes)
```

```{r, echo=FALSE}
knitr::kable(chi_table, align = "c", caption = "Cross-Tabulation Table of Simulated Data for learning about chi-squares")
```


### More on Permutations - a blog {-}

There is a lot in this chapter and some find all the different components quite tricky. As such, this is a very paired down version of the crux of the chapter to see if removing all the blurb, keeping it to just the essential, helps.

The main concept of Null Hypothesis Significance Testing (NHST) is that you are testing that there is no significant difference between two values - let's say two means for the moment. The null hypothesis states that there is no meaningful difference between the two groups of interest. And as such, any test that you do on the difference between the means of those two groups is trying to determine the probability of finding a difference of the size you found, or larger, in your experiment, if there is actually no real difference between the two groups.

```{r ch5-additionl-perm, echo=FALSE}
calc_diff <- function(x) {
  x %>%
    group_by(group) %>%
    summarise(m = mean(Y)) %>%
    pivot_wider(names_from = "group", values_from = "m") %>%
    mutate(diff = A - B) %>%
    pull(diff)
}

permute <- function(x) {
  x %>%
    mutate(group = sample(group))
}

d_orig <- calc_diff(dat) %>% round(2)

nhd <- replicate(1000, dat %>% permute() %>% calc_diff())
lvec = abs(nhd) >= abs(d_orig)
n_exceeding_orig <- sum(lvec)
p <- n_exceeding_orig / length(nhd)
```

In the InClass activity we have our two groups, A and B, and we calculated the difference between the means of those two groups to be $D_{orig}$ = `r calc_diff(dat) %>% round(2)`.  Putting that in terms of the Null Hypothesis ($H_{0}$) we are asking what is the probability of finding a difference between means of `r calc_diff(dat) %>% round(2)` (or larger) if there is no real difference between our two groups.

In order to test the above question (our null hypothesis) we need to compare our original difference against a distribution of possible differences to see how likely the original difference is in that distribution - remember, for example, extreme values are in the tails of the Normal Distribution. 

As we don't know where our data comes from we don't really know what distribution to check our $D_{orig}$ against. In that situation we can create a distribution based on the values we have already collected using the permutation test we talked about InClass. Basically, in this test, we shuffle which group people belonged to (A or B) and then calculate the difference between these shuffled groups. And we do that 1000 times or more to create a distribution. 

The reason we are allowed to shuffle whether people were in group A or B is because we are deliberately wanting to test if the group people were originally in drives the difference we see. If the original grouping of participants is important then the original difference ($D_{orig}$) will be an extreme value on the distribution we create. If the group people were originally in isn't important, then the original difference ($D_{orig}$) will not be an extreme value in the distribution; it will be a common value.

Here again is the distribution we simulated using the permutation test described InClass and above:

```{r ch5-additionl-perm-plot, fig.cap="The simulated distribution of all possible differences"}
ggplot(tibble(x = nhd), aes(x)) + geom_histogram(binwidth = 1)
```

Now lets highlight the areas in this distribution where the values in the distribution are equal to or larger than our $D_{orig}$ value - these are the red areas. The blue areas are those where the values in the distribution are smaller than our $D_{orig}$ value. We have changed the binwidth of the plot a little from above to help see the different areas clearly.

```{r ch5-additionl-perm-plot-2, echo = FALSE, fig.cap="The simulated distribution of all possible differences. Red areas show values greater than or equal to the original difference. Blue areas show values smaller than the original difference."}

new_dat <- tibble(x = nhd) %>%
  mutate(high_low = case_when(x <= d_orig ~ "A",
                              x >= abs(d_orig) ~ "A",
                              TRUE ~ "B" ))

ggplot(new_dat, aes(x)) + 
  geom_histogram(aes(fill = high_low), binwidth = .3) +
  guides(fill = FALSE)
```

Going back to what we said about Null Hypothesis Significance Testing, the question is what is the probability of finding the original difference ($D_{orig}$) if there is no real effect of being in either Group A or Group B. As you can see from the plot, there are very few areas on the distribution where the values are greater than or equal to the original difference - i.e. $D_{orig}$ is an unlikely difference to obtain if there was really no difference between the two groups. From the InClass you will recall that the probability of finding a difference greater than or equal to $D_{orig}$ if there was no difference between the two groups was p = `r p`. This is below the standard cut-off we use in Psychology, $p <= .05$. As such we would reject our null hypothesis and suggest that there is a significant difference between the two groups.  

Hopefully this gives a bit more insight to the InClass activities but feel free to post any questions on the forums for discussion or ask a member of staff.

<span style="font-size: 22px; font-weight: bold; color: var(--purple);">End of Additional Material!</span>